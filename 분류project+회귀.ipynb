{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "국가 건강검진데이터-'혈압,혈당데이터'\n",
    "[연도] 2013~2014년 일반검진 및 생애전환기 건강검진 데이터 1,000,000건\n",
    "[항목] 연령, 수축기혈압, 이완기혈압, 공복혈당, 성별, 고혈압/당뇨병 진료여부, 체질량지수\n",
    "[변수]\n",
    "- BTH_G : 연령(그룹)   -> age_arrange (1:20~30, 2:31~40, 3:41~50, 4:51~60, 5:61~70, 6:71이상)\n",
    "- SBP : 수축기혈압\n",
    "- DBP : 이완기혈압\n",
    "- FBS : 공복혈당\n",
    "- SEX : 성별(남성:1, 여성:2)\n",
    "- DIS : 고혈압/당뇨병 진료여부      -> (1:1+2+3 진료내역 있음, 0:4 진료내역 없음)\n",
    "        고혈압/당뇨병 진료내역 있음: 1\n",
    "        고혈압 진료내역 있음: 2\n",
    "        당뇨병 진료내역 있음: 3\n",
    "        고혈압/당뇨병 진료내역 없음: 4\n",
    "- BMI : 체질량지수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4    740662\n",
      "2    162826\n",
      "1     53398\n",
      "3     43114\n",
      "Name: DIS, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEX</th>\n",
       "      <th>age_arrange</th>\n",
       "      <th>BTH_G</th>\n",
       "      <th>SBP</th>\n",
       "      <th>DBP</th>\n",
       "      <th>FBS</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DIS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>116</td>\n",
       "      <td>78</td>\n",
       "      <td>94</td>\n",
       "      <td>16.6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>79</td>\n",
       "      <td>22.3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>87</td>\n",
       "      <td>21.9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SEX  age_arrange  BTH_G  SBP  DBP  FBS   BMI  DIS\n",
       "0    1            1      1  116   78   94  16.6    4\n",
       "1    1            1      1  100   60   79  22.3    4\n",
       "2    1            1      1  100   60   87  21.9    4"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,precision_score, recall_score, confusion_matrix, f1_score, roc_auc_score, precision_recall_curve, roc_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "health_df=pd.read_csv('health2.csv')\n",
    "print(health_df['DIS'].value_counts())\n",
    "health_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단일 컬럼 데이터 추출:\n",
      " 0    4\n",
      "1    4\n",
      "2    4\n",
      "Name: DIS, dtype: int64\n",
      "\n",
      "여러 컬럼들의 데이터 추출:\n",
      "    SBP  DIS\n",
      "0  116    4\n",
      "1  100    4\n",
      "2  100    4\n",
      "피처 데이터 shape: (1000000, 7)\n",
      "        SEX  age_arrange  BTH_G  SBP  DBP  FBS   BMI\n",
      "0         1            1      1  116   78   94  16.6\n",
      "1         1            1      1  100   60   79  22.3\n",
      "2         1            1      1  100   60   87  21.9\n",
      "3         1            1      1  111   70   72  20.2\n",
      "4         1            1      1  120   80   98  20.0\n",
      "...     ...          ...    ...  ...  ...  ...   ...\n",
      "999995    2            6     27  120   70   81  23.1\n",
      "999996    2            6     27  110   70  104  27.2\n",
      "999997    2            6     27  115   53  110  25.2\n",
      "999998    2            6     27  120   70   90  19.7\n",
      "999999    2            6     27  116   73   92  17.6\n",
      "\n",
      "[1000000 rows x 7 columns]\n",
      "0         4\n",
      "1         4\n",
      "2         4\n",
      "3         4\n",
      "4         4\n",
      "         ..\n",
      "999995    2\n",
      "999996    2\n",
      "999997    1\n",
      "999998    2\n",
      "999999    4\n",
      "Name: DIS, Length: 1000000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "health_df=pd.read_csv('health2.csv')\n",
    "print('단일 컬럼 데이터 추출:\\n',health_df[  'DIS' ].head(3))\n",
    "print('\\n여러 컬럼들의 데이터 추출:\\n', health_df[ ['SBP','DIS']].head(3))\n",
    "\n",
    "X_features=health_df.iloc[:,:-1]\n",
    "y_labels=health_df.iloc[:,-1]\n",
    "print('피처 데이터 shape: {0}'.format(X_features.shape))\n",
    "print(X_features)\n",
    "print(y_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 전처리: 엑셀\n",
    "1) SBP>=180 , DBP>=110 , DIS=4 삭제 (학습 시, 혈압 높아도 진료내역 없음(4)으로 학습할 수 있기 때문)\n",
    "2) FBS>=126, DIS=4 삭제\n",
    "3) BTH_G -> age_arrange 변경 (1:20~30, 2:31~40, 3:41~50, 4:51~60, 5:61~70, 6:71이상) \n",
    "4) DIS -> 이진분류 변경 (1:1+2+3 진료내역 있음, 0:4 진료내역 없음)\n",
    "건강검진 시 수축기혈압과 이완기혈압, 공복혈당을 보았을때 이전에 고혈압/당뇨병 진료내역이 있는지 확인(높음->진료내역있음)\n",
    "예측모델: 수축기혈압과 이완기혈압, 공복혈당 데이터를 받아서 그 값이 높을 경우 관리의 필요성 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    722604\n",
      "1    259338\n",
      "Name: DIS, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEX</th>\n",
       "      <th>age_arrange</th>\n",
       "      <th>SBP</th>\n",
       "      <th>DBP</th>\n",
       "      <th>FBS</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DIS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>116</td>\n",
       "      <td>78</td>\n",
       "      <td>94</td>\n",
       "      <td>16.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>79</td>\n",
       "      <td>22.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>87</td>\n",
       "      <td>21.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SEX  age_arrange  SBP  DBP  FBS   BMI  DIS\n",
       "0    1            1  116   78   94  16.6    0\n",
       "1    1            1  100   60   79  22.3    0\n",
       "2    1            1  100   60   87  21.9    0"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "health4_df=pd.read_csv('health4.csv')\n",
    "print(health4_df['DIS'].value_counts())\n",
    "health4_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단일 컬럼 데이터 추출:\n",
      " 0    0\n",
      "1    0\n",
      "2    0\n",
      "Name: DIS, dtype: int64\n",
      "\n",
      "여러 컬럼들의 데이터 추출:\n",
      "    SBP  DIS\n",
      "0  116    0\n",
      "1  100    0\n",
      "2  100    0\n",
      "피처 데이터 shape: (981942, 6)\n",
      "        SEX  age_arrange  SBP  DBP  FBS   BMI\n",
      "0         1            1  116   78   94  16.6\n",
      "1         1            1  100   60   79  22.3\n",
      "2         1            1  100   60   87  21.9\n",
      "3         1            1  111   70   72  20.2\n",
      "4         1            1  120   80   98  20.0\n",
      "...     ...          ...  ...  ...  ...   ...\n",
      "981937    2            6  120   70   81  23.1\n",
      "981938    2            6  110   70  104  27.2\n",
      "981939    2            6  115   53  110  25.2\n",
      "981940    2            6  120   70   90  19.7\n",
      "981941    2            6  116   73   92  17.6\n",
      "\n",
      "[981942 rows x 6 columns]\n",
      "0         0\n",
      "1         0\n",
      "2         0\n",
      "3         0\n",
      "4         0\n",
      "         ..\n",
      "981937    1\n",
      "981938    1\n",
      "981939    1\n",
      "981940    1\n",
      "981941    0\n",
      "Name: DIS, Length: 981942, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "health4_df=pd.read_csv('health4.csv')\n",
    "print('단일 컬럼 데이터 추출:\\n',health4_df[  'DIS' ].head(3))\n",
    "print('\\n여러 컬럼들의 데이터 추출:\\n', health4_df[ ['SBP','DIS']].head(3))\n",
    "\n",
    "X=health4_df.iloc[:,:-1]\n",
    "y=health4_df.iloc[:,-1]\n",
    "print('피처 데이터 shape: {0}'.format(X.shape))\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 981942 entries, 0 to 981941\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   SEX          981942 non-null  int64  \n",
      " 1   age_arrange  981942 non-null  int64  \n",
      " 2   SBP          981942 non-null  int64  \n",
      " 3   DBP          981942 non-null  int64  \n",
      " 4   FBS          981942 non-null  int64  \n",
      " 5   BMI          981942 non-null  float64\n",
      " 6   DIS          981942 non-null  int64  \n",
      "dtypes: float64(1), int64(6)\n",
      "memory usage: 52.4 MB\n"
     ]
    }
   ],
   "source": [
    "health4_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도:0.6861\n"
     ]
    }
   ],
   "source": [
    "#health2 DT\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error,r2_score, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_clf=DecisionTreeClassifier()\n",
    "X_train, X_test, y_train, y_test=train_test_split(X_features, y_labels, test_size=0.2, random_state=10)\n",
    "\n",
    "dt_clf.fit(X_train, y_train)\n",
    "pred=dt_clf.predict(X_test)\n",
    "pred_prob=dt_clf.predict_proba(X_test)\n",
    "print('예측 정확도:{0:.4f}'.format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도:0.7714\n"
     ]
    }
   ],
   "source": [
    "#health4 dt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error,r2_score, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt4_clf=DecisionTreeClassifier()\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "dt4_clf.fit(X_train, y_train)\n",
    "pred4=dt4_clf.predict(X_test)\n",
    "print('예측 정확도:{0:.4f}'.format(accuracy_score(y_test, pred4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,precision_score, recall_score, confusion_matrix, f1_score, roc_auc_score, precision_recall_curve, roc_curve\n",
    "\n",
    "def get_clf_eval(y_test,pred=None, pred_proba=None):\n",
    "    confusion=confusion_matrix(y_test,pred)\n",
    "    accuracy=accuracy_score(y_test,pred)\n",
    "    precision=precision_score(y_test,pred)\n",
    "    recall=recall_score(y_test,pred)\n",
    "    f1=f1_score(y_test, pred)\n",
    "    roc_auc=roc_auc_score(y_test,pred_proba)\n",
    "    \n",
    "    print('오차행렬')\n",
    "    print(confusion)\n",
    "    print('정확도:{0:.4f}, 정밀도:{1:.4f},재현율:{2:.4f}, F1:{3:.4f}, AUC:{4:.4f}'.format(accuracy,precision,recall,f1,roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차행렬\n",
      "[[122159  22240]\n",
      " [ 22649  29341]]\n",
      "정확도:0.7714, 정밀도:0.5688,재현율:0.5644, F1:0.5666\n"
     ]
    }
   ],
   "source": [
    "#health4 dt\n",
    "from sklearn.metrics import accuracy_score,precision_score, recall_score, confusion_matrix, f1_score, roc_auc_score, precision_recall_curve, roc_curve\n",
    "\n",
    "def get_clf_eval_dt(y_test,pred=None, pred_proba=None):\n",
    "    confusion=confusion_matrix(y_test,pred)\n",
    "    accuracy=accuracy_score(y_test,pred)\n",
    "    precision=precision_score(y_test,pred)\n",
    "    recall=recall_score(y_test,pred)\n",
    "    f1=f1_score(y_test, pred)\n",
    "\n",
    "    \n",
    "    print('오차행렬')\n",
    "    print(confusion)\n",
    "    print('정확도:{0:.4f}, 정밀도:{1:.4f},재현율:{2:.4f}, F1:{3:.4f}'.format(accuracy,precision,recall,f1))\n",
    "\n",
    "get_clf_eval_dt(y_test, pred4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.538724\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[2]\ttraining's binary_logloss: 0.509487\n",
      "[3]\ttraining's binary_logloss: 0.486199\n",
      "[4]\ttraining's binary_logloss: 0.467097\n",
      "[5]\ttraining's binary_logloss: 0.451297\n",
      "[6]\ttraining's binary_logloss: 0.437881\n",
      "[7]\ttraining's binary_logloss: 0.426563\n",
      "[8]\ttraining's binary_logloss: 0.416808\n",
      "[9]\ttraining's binary_logloss: 0.408474\n",
      "[10]\ttraining's binary_logloss: 0.401255\n",
      "[11]\ttraining's binary_logloss: 0.394969\n",
      "[12]\ttraining's binary_logloss: 0.389464\n",
      "[13]\ttraining's binary_logloss: 0.384685\n",
      "[14]\ttraining's binary_logloss: 0.380488\n",
      "[15]\ttraining's binary_logloss: 0.376811\n",
      "[16]\ttraining's binary_logloss: 0.373558\n",
      "[17]\ttraining's binary_logloss: 0.370693\n",
      "[18]\ttraining's binary_logloss: 0.368225\n",
      "[19]\ttraining's binary_logloss: 0.366037\n",
      "[20]\ttraining's binary_logloss: 0.36411\n",
      "[21]\ttraining's binary_logloss: 0.362372\n",
      "[22]\ttraining's binary_logloss: 0.360808\n",
      "[23]\ttraining's binary_logloss: 0.359424\n",
      "[24]\ttraining's binary_logloss: 0.358201\n",
      "[25]\ttraining's binary_logloss: 0.357103\n",
      "[26]\ttraining's binary_logloss: 0.356115\n",
      "[27]\ttraining's binary_logloss: 0.355253\n",
      "[28]\ttraining's binary_logloss: 0.354463\n",
      "[29]\ttraining's binary_logloss: 0.353769\n",
      "[30]\ttraining's binary_logloss: 0.353139\n",
      "[31]\ttraining's binary_logloss: 0.352583\n",
      "[32]\ttraining's binary_logloss: 0.352081\n",
      "[33]\ttraining's binary_logloss: 0.351633\n",
      "[34]\ttraining's binary_logloss: 0.351234\n",
      "[35]\ttraining's binary_logloss: 0.350846\n",
      "[36]\ttraining's binary_logloss: 0.350492\n",
      "[37]\ttraining's binary_logloss: 0.3502\n",
      "[38]\ttraining's binary_logloss: 0.349934\n",
      "[39]\ttraining's binary_logloss: 0.349692\n",
      "[40]\ttraining's binary_logloss: 0.349479\n",
      "[41]\ttraining's binary_logloss: 0.349268\n",
      "[42]\ttraining's binary_logloss: 0.349096\n",
      "[43]\ttraining's binary_logloss: 0.348919\n",
      "[44]\ttraining's binary_logloss: 0.34877\n",
      "[45]\ttraining's binary_logloss: 0.348634\n",
      "[46]\ttraining's binary_logloss: 0.348491\n",
      "[47]\ttraining's binary_logloss: 0.34837\n",
      "[48]\ttraining's binary_logloss: 0.348263\n",
      "[49]\ttraining's binary_logloss: 0.348146\n",
      "[50]\ttraining's binary_logloss: 0.348057\n",
      "[51]\ttraining's binary_logloss: 0.34797\n",
      "[52]\ttraining's binary_logloss: 0.347893\n",
      "[53]\ttraining's binary_logloss: 0.34782\n",
      "[54]\ttraining's binary_logloss: 0.347757\n",
      "[55]\ttraining's binary_logloss: 0.347691\n",
      "[56]\ttraining's binary_logloss: 0.347624\n",
      "[57]\ttraining's binary_logloss: 0.34756\n",
      "[58]\ttraining's binary_logloss: 0.347511\n",
      "[59]\ttraining's binary_logloss: 0.347464\n",
      "[60]\ttraining's binary_logloss: 0.34742\n",
      "[61]\ttraining's binary_logloss: 0.347382\n",
      "[62]\ttraining's binary_logloss: 0.34733\n",
      "[63]\ttraining's binary_logloss: 0.34729\n",
      "[64]\ttraining's binary_logloss: 0.347253\n",
      "[65]\ttraining's binary_logloss: 0.347208\n",
      "[66]\ttraining's binary_logloss: 0.347175\n",
      "[67]\ttraining's binary_logloss: 0.34714\n",
      "[68]\ttraining's binary_logloss: 0.347113\n",
      "[69]\ttraining's binary_logloss: 0.347086\n",
      "[70]\ttraining's binary_logloss: 0.347038\n",
      "[71]\ttraining's binary_logloss: 0.347006\n",
      "[72]\ttraining's binary_logloss: 0.346972\n",
      "[73]\ttraining's binary_logloss: 0.34695\n",
      "[74]\ttraining's binary_logloss: 0.346925\n",
      "[75]\ttraining's binary_logloss: 0.346904\n",
      "[76]\ttraining's binary_logloss: 0.346876\n",
      "[77]\ttraining's binary_logloss: 0.346851\n",
      "[78]\ttraining's binary_logloss: 0.346815\n",
      "[79]\ttraining's binary_logloss: 0.346792\n",
      "[80]\ttraining's binary_logloss: 0.346768\n",
      "[81]\ttraining's binary_logloss: 0.346749\n",
      "[82]\ttraining's binary_logloss: 0.346728\n",
      "[83]\ttraining's binary_logloss: 0.346698\n",
      "[84]\ttraining's binary_logloss: 0.346677\n",
      "[85]\ttraining's binary_logloss: 0.346658\n",
      "[86]\ttraining's binary_logloss: 0.346637\n",
      "[87]\ttraining's binary_logloss: 0.34662\n",
      "[88]\ttraining's binary_logloss: 0.3466\n",
      "[89]\ttraining's binary_logloss: 0.34658\n",
      "[90]\ttraining's binary_logloss: 0.346556\n",
      "[91]\ttraining's binary_logloss: 0.346542\n",
      "[92]\ttraining's binary_logloss: 0.346511\n",
      "[93]\ttraining's binary_logloss: 0.346482\n",
      "[94]\ttraining's binary_logloss: 0.346469\n",
      "[95]\ttraining's binary_logloss: 0.346451\n",
      "[96]\ttraining's binary_logloss: 0.346426\n",
      "[97]\ttraining's binary_logloss: 0.346407\n",
      "[98]\ttraining's binary_logloss: 0.346386\n",
      "[99]\ttraining's binary_logloss: 0.346359\n",
      "[100]\ttraining's binary_logloss: 0.346341\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.346341\n"
     ]
    }
   ],
   "source": [
    "#health4 LGBM logloss 값이 낮아질수록 더 나은 예측\n",
    "from lightgbm import LGBMClassifier\n",
    "import pandas as pd\n",
    "\n",
    "lgbm_wrapper=LGBMClassifier(n_estimators=100, random_state=0)\n",
    "\n",
    "evals=[(X_train, y_train)]\n",
    "lgbm_wrapper.fit(X_train, y_train, early_stopping_rounds=40, eval_metric='logloss',\n",
    "                eval_set=evals, verbose=True)\n",
    "preds4=lgbm_wrapper.predict(X_test)\n",
    "pred_proba4=lgbm_wrapper.predict_proba(X_test)[:,-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.538724\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\ttraining's binary_logloss: 0.509487\n",
      "[3]\ttraining's binary_logloss: 0.486199\n",
      "[4]\ttraining's binary_logloss: 0.467097\n",
      "[5]\ttraining's binary_logloss: 0.451297\n",
      "[6]\ttraining's binary_logloss: 0.437881\n",
      "[7]\ttraining's binary_logloss: 0.426563\n",
      "[8]\ttraining's binary_logloss: 0.416808\n",
      "[9]\ttraining's binary_logloss: 0.408474\n",
      "[10]\ttraining's binary_logloss: 0.401255\n",
      "[11]\ttraining's binary_logloss: 0.394969\n",
      "[12]\ttraining's binary_logloss: 0.389464\n",
      "[13]\ttraining's binary_logloss: 0.384685\n",
      "[14]\ttraining's binary_logloss: 0.380488\n",
      "[15]\ttraining's binary_logloss: 0.376811\n",
      "[16]\ttraining's binary_logloss: 0.373558\n",
      "[17]\ttraining's binary_logloss: 0.370693\n",
      "[18]\ttraining's binary_logloss: 0.368225\n",
      "[19]\ttraining's binary_logloss: 0.366037\n",
      "[20]\ttraining's binary_logloss: 0.36411\n",
      "[21]\ttraining's binary_logloss: 0.362372\n",
      "[22]\ttraining's binary_logloss: 0.360808\n",
      "[23]\ttraining's binary_logloss: 0.359424\n",
      "[24]\ttraining's binary_logloss: 0.358201\n",
      "[25]\ttraining's binary_logloss: 0.357103\n",
      "[26]\ttraining's binary_logloss: 0.356115\n",
      "[27]\ttraining's binary_logloss: 0.355253\n",
      "[28]\ttraining's binary_logloss: 0.354463\n",
      "[29]\ttraining's binary_logloss: 0.353769\n",
      "[30]\ttraining's binary_logloss: 0.353139\n",
      "[31]\ttraining's binary_logloss: 0.352583\n",
      "[32]\ttraining's binary_logloss: 0.352081\n",
      "[33]\ttraining's binary_logloss: 0.351633\n",
      "[34]\ttraining's binary_logloss: 0.351234\n",
      "[35]\ttraining's binary_logloss: 0.350846\n",
      "[36]\ttraining's binary_logloss: 0.350492\n",
      "[37]\ttraining's binary_logloss: 0.3502\n",
      "[38]\ttraining's binary_logloss: 0.349934\n",
      "[39]\ttraining's binary_logloss: 0.349692\n",
      "[40]\ttraining's binary_logloss: 0.349479\n",
      "[41]\ttraining's binary_logloss: 0.349268\n",
      "[42]\ttraining's binary_logloss: 0.349096\n",
      "[43]\ttraining's binary_logloss: 0.348919\n",
      "[44]\ttraining's binary_logloss: 0.34877\n",
      "[45]\ttraining's binary_logloss: 0.348634\n",
      "[46]\ttraining's binary_logloss: 0.348491\n",
      "[47]\ttraining's binary_logloss: 0.34837\n",
      "[48]\ttraining's binary_logloss: 0.348263\n",
      "[49]\ttraining's binary_logloss: 0.348146\n",
      "[50]\ttraining's binary_logloss: 0.348057\n",
      "[51]\ttraining's binary_logloss: 0.34797\n",
      "[52]\ttraining's binary_logloss: 0.347893\n",
      "[53]\ttraining's binary_logloss: 0.34782\n",
      "[54]\ttraining's binary_logloss: 0.347757\n",
      "[55]\ttraining's binary_logloss: 0.347691\n",
      "[56]\ttraining's binary_logloss: 0.347624\n",
      "[57]\ttraining's binary_logloss: 0.34756\n",
      "[58]\ttraining's binary_logloss: 0.347511\n",
      "[59]\ttraining's binary_logloss: 0.347464\n",
      "[60]\ttraining's binary_logloss: 0.34742\n",
      "[61]\ttraining's binary_logloss: 0.347382\n",
      "[62]\ttraining's binary_logloss: 0.34733\n",
      "[63]\ttraining's binary_logloss: 0.34729\n",
      "[64]\ttraining's binary_logloss: 0.347253\n",
      "[65]\ttraining's binary_logloss: 0.347208\n",
      "[66]\ttraining's binary_logloss: 0.347175\n",
      "[67]\ttraining's binary_logloss: 0.34714\n",
      "[68]\ttraining's binary_logloss: 0.347113\n",
      "[69]\ttraining's binary_logloss: 0.347086\n",
      "[70]\ttraining's binary_logloss: 0.347038\n",
      "[71]\ttraining's binary_logloss: 0.347006\n",
      "[72]\ttraining's binary_logloss: 0.346972\n",
      "[73]\ttraining's binary_logloss: 0.34695\n",
      "[74]\ttraining's binary_logloss: 0.346925\n",
      "[75]\ttraining's binary_logloss: 0.346904\n",
      "[76]\ttraining's binary_logloss: 0.346876\n",
      "[77]\ttraining's binary_logloss: 0.346851\n",
      "[78]\ttraining's binary_logloss: 0.346815\n",
      "[79]\ttraining's binary_logloss: 0.346792\n",
      "[80]\ttraining's binary_logloss: 0.346768\n",
      "[81]\ttraining's binary_logloss: 0.346749\n",
      "[82]\ttraining's binary_logloss: 0.346728\n",
      "[83]\ttraining's binary_logloss: 0.346698\n",
      "[84]\ttraining's binary_logloss: 0.346677\n",
      "[85]\ttraining's binary_logloss: 0.346658\n",
      "[86]\ttraining's binary_logloss: 0.346637\n",
      "[87]\ttraining's binary_logloss: 0.34662\n",
      "[88]\ttraining's binary_logloss: 0.3466\n",
      "[89]\ttraining's binary_logloss: 0.34658\n",
      "[90]\ttraining's binary_logloss: 0.346556\n",
      "[91]\ttraining's binary_logloss: 0.346542\n",
      "[92]\ttraining's binary_logloss: 0.346511\n",
      "[93]\ttraining's binary_logloss: 0.346482\n",
      "[94]\ttraining's binary_logloss: 0.346469\n",
      "[95]\ttraining's binary_logloss: 0.346451\n",
      "[96]\ttraining's binary_logloss: 0.346426\n",
      "[97]\ttraining's binary_logloss: 0.346407\n",
      "[98]\ttraining's binary_logloss: 0.346386\n",
      "[99]\ttraining's binary_logloss: 0.346359\n",
      "[100]\ttraining's binary_logloss: 0.346341\n",
      "[101]\ttraining's binary_logloss: 0.346315\n",
      "[102]\ttraining's binary_logloss: 0.346297\n",
      "[103]\ttraining's binary_logloss: 0.346283\n",
      "[104]\ttraining's binary_logloss: 0.346263\n",
      "[105]\ttraining's binary_logloss: 0.346248\n",
      "[106]\ttraining's binary_logloss: 0.346219\n",
      "[107]\ttraining's binary_logloss: 0.346199\n",
      "[108]\ttraining's binary_logloss: 0.346186\n",
      "[109]\ttraining's binary_logloss: 0.346172\n",
      "[110]\ttraining's binary_logloss: 0.346154\n",
      "[111]\ttraining's binary_logloss: 0.346138\n",
      "[112]\ttraining's binary_logloss: 0.346113\n",
      "[113]\ttraining's binary_logloss: 0.346097\n",
      "[114]\ttraining's binary_logloss: 0.346079\n",
      "[115]\ttraining's binary_logloss: 0.346059\n",
      "[116]\ttraining's binary_logloss: 0.346045\n",
      "[117]\ttraining's binary_logloss: 0.346028\n",
      "[118]\ttraining's binary_logloss: 0.346013\n",
      "[119]\ttraining's binary_logloss: 0.345995\n",
      "[120]\ttraining's binary_logloss: 0.345985\n",
      "[121]\ttraining's binary_logloss: 0.345972\n",
      "[122]\ttraining's binary_logloss: 0.345947\n",
      "[123]\ttraining's binary_logloss: 0.345927\n",
      "[124]\ttraining's binary_logloss: 0.34591\n",
      "[125]\ttraining's binary_logloss: 0.345896\n",
      "[126]\ttraining's binary_logloss: 0.345877\n",
      "[127]\ttraining's binary_logloss: 0.34586\n",
      "[128]\ttraining's binary_logloss: 0.345843\n",
      "[129]\ttraining's binary_logloss: 0.345827\n",
      "[130]\ttraining's binary_logloss: 0.34581\n",
      "[131]\ttraining's binary_logloss: 0.345787\n",
      "[132]\ttraining's binary_logloss: 0.345763\n",
      "[133]\ttraining's binary_logloss: 0.345748\n",
      "[134]\ttraining's binary_logloss: 0.345732\n",
      "[135]\ttraining's binary_logloss: 0.345714\n",
      "[136]\ttraining's binary_logloss: 0.3457\n",
      "[137]\ttraining's binary_logloss: 0.345679\n",
      "[138]\ttraining's binary_logloss: 0.345661\n",
      "[139]\ttraining's binary_logloss: 0.345647\n",
      "[140]\ttraining's binary_logloss: 0.345627\n",
      "[141]\ttraining's binary_logloss: 0.345609\n",
      "[142]\ttraining's binary_logloss: 0.345594\n",
      "[143]\ttraining's binary_logloss: 0.345581\n",
      "[144]\ttraining's binary_logloss: 0.345566\n",
      "[145]\ttraining's binary_logloss: 0.345549\n",
      "[146]\ttraining's binary_logloss: 0.345534\n",
      "[147]\ttraining's binary_logloss: 0.345516\n",
      "[148]\ttraining's binary_logloss: 0.345504\n",
      "[149]\ttraining's binary_logloss: 0.345484\n",
      "[150]\ttraining's binary_logloss: 0.34546\n",
      "[151]\ttraining's binary_logloss: 0.345448\n",
      "[152]\ttraining's binary_logloss: 0.345434\n",
      "[153]\ttraining's binary_logloss: 0.345425\n",
      "[154]\ttraining's binary_logloss: 0.345405\n",
      "[155]\ttraining's binary_logloss: 0.345383\n",
      "[156]\ttraining's binary_logloss: 0.345365\n",
      "[157]\ttraining's binary_logloss: 0.345351\n",
      "[158]\ttraining's binary_logloss: 0.345334\n",
      "[159]\ttraining's binary_logloss: 0.34532\n",
      "[160]\ttraining's binary_logloss: 0.345298\n",
      "[161]\ttraining's binary_logloss: 0.345282\n",
      "[162]\ttraining's binary_logloss: 0.345271\n",
      "[163]\ttraining's binary_logloss: 0.345263\n",
      "[164]\ttraining's binary_logloss: 0.345248\n",
      "[165]\ttraining's binary_logloss: 0.345227\n",
      "[166]\ttraining's binary_logloss: 0.345207\n",
      "[167]\ttraining's binary_logloss: 0.345196\n",
      "[168]\ttraining's binary_logloss: 0.345182\n",
      "[169]\ttraining's binary_logloss: 0.34516\n",
      "[170]\ttraining's binary_logloss: 0.34514\n",
      "[171]\ttraining's binary_logloss: 0.345132\n",
      "[172]\ttraining's binary_logloss: 0.345123\n",
      "[173]\ttraining's binary_logloss: 0.345104\n",
      "[174]\ttraining's binary_logloss: 0.345096\n",
      "[175]\ttraining's binary_logloss: 0.345082\n",
      "[176]\ttraining's binary_logloss: 0.345067\n",
      "[177]\ttraining's binary_logloss: 0.34506\n",
      "[178]\ttraining's binary_logloss: 0.345049\n",
      "[179]\ttraining's binary_logloss: 0.345042\n",
      "[180]\ttraining's binary_logloss: 0.345023\n",
      "[181]\ttraining's binary_logloss: 0.345003\n",
      "[182]\ttraining's binary_logloss: 0.344987\n",
      "[183]\ttraining's binary_logloss: 0.34497\n",
      "[184]\ttraining's binary_logloss: 0.34496\n",
      "[185]\ttraining's binary_logloss: 0.344949\n",
      "[186]\ttraining's binary_logloss: 0.344931\n",
      "[187]\ttraining's binary_logloss: 0.344921\n",
      "[188]\ttraining's binary_logloss: 0.344905\n",
      "[189]\ttraining's binary_logloss: 0.344893\n",
      "[190]\ttraining's binary_logloss: 0.344885\n",
      "[191]\ttraining's binary_logloss: 0.344871\n",
      "[192]\ttraining's binary_logloss: 0.344865\n",
      "[193]\ttraining's binary_logloss: 0.344851\n",
      "[194]\ttraining's binary_logloss: 0.344829\n",
      "[195]\ttraining's binary_logloss: 0.344807\n",
      "[196]\ttraining's binary_logloss: 0.344786\n",
      "[197]\ttraining's binary_logloss: 0.344764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[198]\ttraining's binary_logloss: 0.344748\n",
      "[199]\ttraining's binary_logloss: 0.344731\n",
      "[200]\ttraining's binary_logloss: 0.344713\n",
      "[201]\ttraining's binary_logloss: 0.344695\n",
      "[202]\ttraining's binary_logloss: 0.344673\n",
      "[203]\ttraining's binary_logloss: 0.344656\n",
      "[204]\ttraining's binary_logloss: 0.344619\n",
      "[205]\ttraining's binary_logloss: 0.344599\n",
      "[206]\ttraining's binary_logloss: 0.344579\n",
      "[207]\ttraining's binary_logloss: 0.344562\n",
      "[208]\ttraining's binary_logloss: 0.344549\n",
      "[209]\ttraining's binary_logloss: 0.344536\n",
      "[210]\ttraining's binary_logloss: 0.344529\n",
      "[211]\ttraining's binary_logloss: 0.344518\n",
      "[212]\ttraining's binary_logloss: 0.344508\n",
      "[213]\ttraining's binary_logloss: 0.344492\n",
      "[214]\ttraining's binary_logloss: 0.344482\n",
      "[215]\ttraining's binary_logloss: 0.344461\n",
      "[216]\ttraining's binary_logloss: 0.344446\n",
      "[217]\ttraining's binary_logloss: 0.344423\n",
      "[218]\ttraining's binary_logloss: 0.344404\n",
      "[219]\ttraining's binary_logloss: 0.344393\n",
      "[220]\ttraining's binary_logloss: 0.344384\n",
      "[221]\ttraining's binary_logloss: 0.344377\n",
      "[222]\ttraining's binary_logloss: 0.344354\n",
      "[223]\ttraining's binary_logloss: 0.344336\n",
      "[224]\ttraining's binary_logloss: 0.344318\n",
      "[225]\ttraining's binary_logloss: 0.344298\n",
      "[226]\ttraining's binary_logloss: 0.344283\n",
      "[227]\ttraining's binary_logloss: 0.344272\n",
      "[228]\ttraining's binary_logloss: 0.344266\n",
      "[229]\ttraining's binary_logloss: 0.344247\n",
      "[230]\ttraining's binary_logloss: 0.344238\n",
      "[231]\ttraining's binary_logloss: 0.344222\n",
      "[232]\ttraining's binary_logloss: 0.344216\n",
      "[233]\ttraining's binary_logloss: 0.344194\n",
      "[234]\ttraining's binary_logloss: 0.344171\n",
      "[235]\ttraining's binary_logloss: 0.344155\n",
      "[236]\ttraining's binary_logloss: 0.344144\n",
      "[237]\ttraining's binary_logloss: 0.344122\n",
      "[238]\ttraining's binary_logloss: 0.344103\n",
      "[239]\ttraining's binary_logloss: 0.344092\n",
      "[240]\ttraining's binary_logloss: 0.344083\n",
      "[241]\ttraining's binary_logloss: 0.344064\n",
      "[242]\ttraining's binary_logloss: 0.344042\n",
      "[243]\ttraining's binary_logloss: 0.344023\n",
      "[244]\ttraining's binary_logloss: 0.344009\n",
      "[245]\ttraining's binary_logloss: 0.343992\n",
      "[246]\ttraining's binary_logloss: 0.343984\n",
      "[247]\ttraining's binary_logloss: 0.343969\n",
      "[248]\ttraining's binary_logloss: 0.343949\n",
      "[249]\ttraining's binary_logloss: 0.343943\n",
      "[250]\ttraining's binary_logloss: 0.343935\n",
      "[251]\ttraining's binary_logloss: 0.343919\n",
      "[252]\ttraining's binary_logloss: 0.343905\n",
      "[253]\ttraining's binary_logloss: 0.343889\n",
      "[254]\ttraining's binary_logloss: 0.343872\n",
      "[255]\ttraining's binary_logloss: 0.343863\n",
      "[256]\ttraining's binary_logloss: 0.34385\n",
      "[257]\ttraining's binary_logloss: 0.343836\n",
      "[258]\ttraining's binary_logloss: 0.343823\n",
      "[259]\ttraining's binary_logloss: 0.343808\n",
      "[260]\ttraining's binary_logloss: 0.343793\n",
      "[261]\ttraining's binary_logloss: 0.343775\n",
      "[262]\ttraining's binary_logloss: 0.343758\n",
      "[263]\ttraining's binary_logloss: 0.343747\n",
      "[264]\ttraining's binary_logloss: 0.343737\n",
      "[265]\ttraining's binary_logloss: 0.343729\n",
      "[266]\ttraining's binary_logloss: 0.343716\n",
      "[267]\ttraining's binary_logloss: 0.343703\n",
      "[268]\ttraining's binary_logloss: 0.343698\n",
      "[269]\ttraining's binary_logloss: 0.343667\n",
      "[270]\ttraining's binary_logloss: 0.34366\n",
      "[271]\ttraining's binary_logloss: 0.343652\n",
      "[272]\ttraining's binary_logloss: 0.343645\n",
      "[273]\ttraining's binary_logloss: 0.343631\n",
      "[274]\ttraining's binary_logloss: 0.343624\n",
      "[275]\ttraining's binary_logloss: 0.343608\n",
      "[276]\ttraining's binary_logloss: 0.343588\n",
      "[277]\ttraining's binary_logloss: 0.343569\n",
      "[278]\ttraining's binary_logloss: 0.343561\n",
      "[279]\ttraining's binary_logloss: 0.34355\n",
      "[280]\ttraining's binary_logloss: 0.343544\n",
      "[281]\ttraining's binary_logloss: 0.343525\n",
      "[282]\ttraining's binary_logloss: 0.34351\n",
      "[283]\ttraining's binary_logloss: 0.343493\n",
      "[284]\ttraining's binary_logloss: 0.343478\n",
      "[285]\ttraining's binary_logloss: 0.343466\n",
      "[286]\ttraining's binary_logloss: 0.343448\n",
      "[287]\ttraining's binary_logloss: 0.343431\n",
      "[288]\ttraining's binary_logloss: 0.343409\n",
      "[289]\ttraining's binary_logloss: 0.343393\n",
      "[290]\ttraining's binary_logloss: 0.343376\n",
      "[291]\ttraining's binary_logloss: 0.343368\n",
      "[292]\ttraining's binary_logloss: 0.343356\n",
      "[293]\ttraining's binary_logloss: 0.343347\n",
      "[294]\ttraining's binary_logloss: 0.343341\n",
      "[295]\ttraining's binary_logloss: 0.343334\n",
      "[296]\ttraining's binary_logloss: 0.343319\n",
      "[297]\ttraining's binary_logloss: 0.343301\n",
      "[298]\ttraining's binary_logloss: 0.343292\n",
      "[299]\ttraining's binary_logloss: 0.343278\n",
      "[300]\ttraining's binary_logloss: 0.343263\n",
      "[301]\ttraining's binary_logloss: 0.343252\n",
      "[302]\ttraining's binary_logloss: 0.343241\n",
      "[303]\ttraining's binary_logloss: 0.343235\n",
      "[304]\ttraining's binary_logloss: 0.343224\n",
      "[305]\ttraining's binary_logloss: 0.343214\n",
      "[306]\ttraining's binary_logloss: 0.343195\n",
      "[307]\ttraining's binary_logloss: 0.343176\n",
      "[308]\ttraining's binary_logloss: 0.343159\n",
      "[309]\ttraining's binary_logloss: 0.343145\n",
      "[310]\ttraining's binary_logloss: 0.343129\n",
      "[311]\ttraining's binary_logloss: 0.343124\n",
      "[312]\ttraining's binary_logloss: 0.343115\n",
      "[313]\ttraining's binary_logloss: 0.3431\n",
      "[314]\ttraining's binary_logloss: 0.343089\n",
      "[315]\ttraining's binary_logloss: 0.343073\n",
      "[316]\ttraining's binary_logloss: 0.343057\n",
      "[317]\ttraining's binary_logloss: 0.343041\n",
      "[318]\ttraining's binary_logloss: 0.343026\n",
      "[319]\ttraining's binary_logloss: 0.342996\n",
      "[320]\ttraining's binary_logloss: 0.342987\n",
      "[321]\ttraining's binary_logloss: 0.342971\n",
      "[322]\ttraining's binary_logloss: 0.342958\n",
      "[323]\ttraining's binary_logloss: 0.342942\n",
      "[324]\ttraining's binary_logloss: 0.342933\n",
      "[325]\ttraining's binary_logloss: 0.342918\n",
      "[326]\ttraining's binary_logloss: 0.342907\n",
      "[327]\ttraining's binary_logloss: 0.342896\n",
      "[328]\ttraining's binary_logloss: 0.342882\n",
      "[329]\ttraining's binary_logloss: 0.342868\n",
      "[330]\ttraining's binary_logloss: 0.342851\n",
      "[331]\ttraining's binary_logloss: 0.342839\n",
      "[332]\ttraining's binary_logloss: 0.34282\n",
      "[333]\ttraining's binary_logloss: 0.342803\n",
      "[334]\ttraining's binary_logloss: 0.342785\n",
      "[335]\ttraining's binary_logloss: 0.342771\n",
      "[336]\ttraining's binary_logloss: 0.342757\n",
      "[337]\ttraining's binary_logloss: 0.342752\n",
      "[338]\ttraining's binary_logloss: 0.342742\n",
      "[339]\ttraining's binary_logloss: 0.342726\n",
      "[340]\ttraining's binary_logloss: 0.342709\n",
      "[341]\ttraining's binary_logloss: 0.342695\n",
      "[342]\ttraining's binary_logloss: 0.34268\n",
      "[343]\ttraining's binary_logloss: 0.342664\n",
      "[344]\ttraining's binary_logloss: 0.342646\n",
      "[345]\ttraining's binary_logloss: 0.342633\n",
      "[346]\ttraining's binary_logloss: 0.342625\n",
      "[347]\ttraining's binary_logloss: 0.342605\n",
      "[348]\ttraining's binary_logloss: 0.342592\n",
      "[349]\ttraining's binary_logloss: 0.342578\n",
      "[350]\ttraining's binary_logloss: 0.342564\n",
      "[351]\ttraining's binary_logloss: 0.342555\n",
      "[352]\ttraining's binary_logloss: 0.342541\n",
      "[353]\ttraining's binary_logloss: 0.342535\n",
      "[354]\ttraining's binary_logloss: 0.342528\n",
      "[355]\ttraining's binary_logloss: 0.34252\n",
      "[356]\ttraining's binary_logloss: 0.342506\n",
      "[357]\ttraining's binary_logloss: 0.342494\n",
      "[358]\ttraining's binary_logloss: 0.342482\n",
      "[359]\ttraining's binary_logloss: 0.342479\n",
      "[360]\ttraining's binary_logloss: 0.342468\n",
      "[361]\ttraining's binary_logloss: 0.342462\n",
      "[362]\ttraining's binary_logloss: 0.342459\n",
      "[363]\ttraining's binary_logloss: 0.342452\n",
      "[364]\ttraining's binary_logloss: 0.342439\n",
      "[365]\ttraining's binary_logloss: 0.342434\n",
      "[366]\ttraining's binary_logloss: 0.34242\n",
      "[367]\ttraining's binary_logloss: 0.342411\n",
      "[368]\ttraining's binary_logloss: 0.342397\n",
      "[369]\ttraining's binary_logloss: 0.342392\n",
      "[370]\ttraining's binary_logloss: 0.342377\n",
      "[371]\ttraining's binary_logloss: 0.342364\n",
      "[372]\ttraining's binary_logloss: 0.342348\n",
      "[373]\ttraining's binary_logloss: 0.342342\n",
      "[374]\ttraining's binary_logloss: 0.34233\n",
      "[375]\ttraining's binary_logloss: 0.342324\n",
      "[376]\ttraining's binary_logloss: 0.342317\n",
      "[377]\ttraining's binary_logloss: 0.342309\n",
      "[378]\ttraining's binary_logloss: 0.3423\n",
      "[379]\ttraining's binary_logloss: 0.342294\n",
      "[380]\ttraining's binary_logloss: 0.342291\n",
      "[381]\ttraining's binary_logloss: 0.342283\n",
      "[382]\ttraining's binary_logloss: 0.342269\n",
      "[383]\ttraining's binary_logloss: 0.342253\n",
      "[384]\ttraining's binary_logloss: 0.342238\n",
      "[385]\ttraining's binary_logloss: 0.342218\n",
      "[386]\ttraining's binary_logloss: 0.3422\n",
      "[387]\ttraining's binary_logloss: 0.342184\n",
      "[388]\ttraining's binary_logloss: 0.342174\n",
      "[389]\ttraining's binary_logloss: 0.342158\n",
      "[390]\ttraining's binary_logloss: 0.342148\n",
      "[391]\ttraining's binary_logloss: 0.342134\n",
      "[392]\ttraining's binary_logloss: 0.342121\n",
      "[393]\ttraining's binary_logloss: 0.342106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[394]\ttraining's binary_logloss: 0.34209\n",
      "[395]\ttraining's binary_logloss: 0.342077\n",
      "[396]\ttraining's binary_logloss: 0.342064\n",
      "[397]\ttraining's binary_logloss: 0.342056\n",
      "[398]\ttraining's binary_logloss: 0.34204\n",
      "[399]\ttraining's binary_logloss: 0.342026\n",
      "[400]\ttraining's binary_logloss: 0.34201\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[400]\ttraining's binary_logloss: 0.34201\n"
     ]
    }
   ],
   "source": [
    "#health4 LGBM logloss 값이 낮아질수록 더 나은 예측\n",
    "from lightgbm import LGBMClassifier\n",
    "import pandas as pd\n",
    "\n",
    "lgbm_wrapper=LGBMClassifier(n_estimators=400, random_state=0)\n",
    "\n",
    "evals=[(X_train, y_train)]\n",
    "lgbm_wrapper.fit(X_train, y_train, early_stopping_rounds=100, eval_metric='logloss',\n",
    "                eval_set=evals, verbose=True)\n",
    "preds4=lgbm_wrapper.predict(X_test)\n",
    "pred_proba4=lgbm_wrapper.predict_proba(X_test)[:,-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차행렬\n",
      "[[133881  10518]\n",
      " [ 21992  29998]]\n",
      "정확도:0.8345, 정밀도:0.7404,재현율:0.5770, F1:0.6486, AUC:0.8887\n"
     ]
    }
   ],
   "source": [
    "#health4 LGBM\n",
    "get_clf_eval(y_test, preds4, pred_proba4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차행렬\n",
      "[[133237  11284]\n",
      " [ 22645  29223]]\n",
      "정확도:0.8272, 정밀도:0.7214,재현율:0.5634, F1:0.6327, AUC:0.8792\n"
     ]
    }
   ],
   "source": [
    "#health4 LogisticRegression\n",
    "X=health4_df.iloc[:,:-1]\n",
    "y=health4_df.iloc[:,-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)\n",
    "\n",
    "lr_clf=LogisticRegression()\n",
    "lr_clf.fit(X_train, y_train)\n",
    "pred_lr=lr_clf.predict(X_test)\n",
    "pred_proba_lr=lr_clf.predict_proba(X_test)[:,-1]\n",
    "\n",
    "get_clf_eval(y_test, pred_lr, pred_proba_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#health2 DT GridSearchCV 최적의 하이퍼 파라미터 찾기\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "\n",
    "health_df=pd.read_csv('health2.csv')\n",
    "X_features=health_df.iloc[:,:-1]\n",
    "y_labels=health_df.iloc[:,-1]\n",
    "\n",
    "dt_clf=DecisionTreeClassifier()\n",
    "X_train, X_test, y_train, y_test=train_test_split(X_features, y_labels, test_size=0.2, random_state=10)\n",
    "\n",
    "params={'max_depth':[6,8,10,12], 'min_samples_split':[800, 1000, 1500, 2000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'max_depth': 6, 'min_samples_split': 800}</td>\n",
       "      <td>0.772786</td>\n",
       "      <td>13</td>\n",
       "      <td>0.772981</td>\n",
       "      <td>0.773050</td>\n",
       "      <td>0.773925</td>\n",
       "      <td>0.772212</td>\n",
       "      <td>0.771763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'max_depth': 6, 'min_samples_split': 1000}</td>\n",
       "      <td>0.772786</td>\n",
       "      <td>13</td>\n",
       "      <td>0.772981</td>\n",
       "      <td>0.773050</td>\n",
       "      <td>0.773925</td>\n",
       "      <td>0.772212</td>\n",
       "      <td>0.771763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'max_depth': 6, 'min_samples_split': 1500}</td>\n",
       "      <td>0.772729</td>\n",
       "      <td>16</td>\n",
       "      <td>0.772906</td>\n",
       "      <td>0.773025</td>\n",
       "      <td>0.773925</td>\n",
       "      <td>0.772025</td>\n",
       "      <td>0.771763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'max_depth': 6, 'min_samples_split': 2000}</td>\n",
       "      <td>0.772729</td>\n",
       "      <td>15</td>\n",
       "      <td>0.772938</td>\n",
       "      <td>0.772956</td>\n",
       "      <td>0.773813</td>\n",
       "      <td>0.772025</td>\n",
       "      <td>0.771913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'max_depth': 8, 'min_samples_split': 800}</td>\n",
       "      <td>0.774839</td>\n",
       "      <td>10</td>\n",
       "      <td>0.774994</td>\n",
       "      <td>0.774606</td>\n",
       "      <td>0.775806</td>\n",
       "      <td>0.773919</td>\n",
       "      <td>0.774869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'max_depth': 8, 'min_samples_split': 1000}</td>\n",
       "      <td>0.774894</td>\n",
       "      <td>9</td>\n",
       "      <td>0.775038</td>\n",
       "      <td>0.774631</td>\n",
       "      <td>0.775900</td>\n",
       "      <td>0.773962</td>\n",
       "      <td>0.774937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'max_depth': 8, 'min_samples_split': 1500}</td>\n",
       "      <td>0.774581</td>\n",
       "      <td>11</td>\n",
       "      <td>0.774575</td>\n",
       "      <td>0.774244</td>\n",
       "      <td>0.775675</td>\n",
       "      <td>0.773475</td>\n",
       "      <td>0.774937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'max_depth': 8, 'min_samples_split': 2000}</td>\n",
       "      <td>0.774539</td>\n",
       "      <td>12</td>\n",
       "      <td>0.774675</td>\n",
       "      <td>0.774081</td>\n",
       "      <td>0.775575</td>\n",
       "      <td>0.773406</td>\n",
       "      <td>0.774956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 800}</td>\n",
       "      <td>0.775465</td>\n",
       "      <td>3</td>\n",
       "      <td>0.775937</td>\n",
       "      <td>0.775062</td>\n",
       "      <td>0.776344</td>\n",
       "      <td>0.774625</td>\n",
       "      <td>0.775356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 1000}</td>\n",
       "      <td>0.775702</td>\n",
       "      <td>2</td>\n",
       "      <td>0.776106</td>\n",
       "      <td>0.775425</td>\n",
       "      <td>0.776537</td>\n",
       "      <td>0.774775</td>\n",
       "      <td>0.775669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 1500}</td>\n",
       "      <td>0.775151</td>\n",
       "      <td>7</td>\n",
       "      <td>0.775412</td>\n",
       "      <td>0.774663</td>\n",
       "      <td>0.775981</td>\n",
       "      <td>0.774100</td>\n",
       "      <td>0.775600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 2000}</td>\n",
       "      <td>0.775070</td>\n",
       "      <td>8</td>\n",
       "      <td>0.775556</td>\n",
       "      <td>0.774563</td>\n",
       "      <td>0.775925</td>\n",
       "      <td>0.773713</td>\n",
       "      <td>0.775594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'max_depth': 12, 'min_samples_split': 800}</td>\n",
       "      <td>0.775463</td>\n",
       "      <td>4</td>\n",
       "      <td>0.775569</td>\n",
       "      <td>0.775081</td>\n",
       "      <td>0.776144</td>\n",
       "      <td>0.774988</td>\n",
       "      <td>0.775531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'max_depth': 12, 'min_samples_split': 1000}</td>\n",
       "      <td>0.775845</td>\n",
       "      <td>1</td>\n",
       "      <td>0.775806</td>\n",
       "      <td>0.775613</td>\n",
       "      <td>0.776513</td>\n",
       "      <td>0.775369</td>\n",
       "      <td>0.775925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'max_depth': 12, 'min_samples_split': 1500}</td>\n",
       "      <td>0.775442</td>\n",
       "      <td>5</td>\n",
       "      <td>0.775431</td>\n",
       "      <td>0.774806</td>\n",
       "      <td>0.776069</td>\n",
       "      <td>0.774906</td>\n",
       "      <td>0.776000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'max_depth': 12, 'min_samples_split': 2000}</td>\n",
       "      <td>0.775366</td>\n",
       "      <td>6</td>\n",
       "      <td>0.775756</td>\n",
       "      <td>0.774544</td>\n",
       "      <td>0.776319</td>\n",
       "      <td>0.774338</td>\n",
       "      <td>0.775875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          params  mean_test_score  \\\n",
       "0     {'max_depth': 6, 'min_samples_split': 800}         0.772786   \n",
       "1    {'max_depth': 6, 'min_samples_split': 1000}         0.772786   \n",
       "2    {'max_depth': 6, 'min_samples_split': 1500}         0.772729   \n",
       "3    {'max_depth': 6, 'min_samples_split': 2000}         0.772729   \n",
       "4     {'max_depth': 8, 'min_samples_split': 800}         0.774839   \n",
       "5    {'max_depth': 8, 'min_samples_split': 1000}         0.774894   \n",
       "6    {'max_depth': 8, 'min_samples_split': 1500}         0.774581   \n",
       "7    {'max_depth': 8, 'min_samples_split': 2000}         0.774539   \n",
       "8    {'max_depth': 10, 'min_samples_split': 800}         0.775465   \n",
       "9   {'max_depth': 10, 'min_samples_split': 1000}         0.775702   \n",
       "10  {'max_depth': 10, 'min_samples_split': 1500}         0.775151   \n",
       "11  {'max_depth': 10, 'min_samples_split': 2000}         0.775070   \n",
       "12   {'max_depth': 12, 'min_samples_split': 800}         0.775463   \n",
       "13  {'max_depth': 12, 'min_samples_split': 1000}         0.775845   \n",
       "14  {'max_depth': 12, 'min_samples_split': 1500}         0.775442   \n",
       "15  {'max_depth': 12, 'min_samples_split': 2000}         0.775366   \n",
       "\n",
       "    rank_test_score  split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0                13           0.772981           0.773050           0.773925   \n",
       "1                13           0.772981           0.773050           0.773925   \n",
       "2                16           0.772906           0.773025           0.773925   \n",
       "3                15           0.772938           0.772956           0.773813   \n",
       "4                10           0.774994           0.774606           0.775806   \n",
       "5                 9           0.775038           0.774631           0.775900   \n",
       "6                11           0.774575           0.774244           0.775675   \n",
       "7                12           0.774675           0.774081           0.775575   \n",
       "8                 3           0.775937           0.775062           0.776344   \n",
       "9                 2           0.776106           0.775425           0.776537   \n",
       "10                7           0.775412           0.774663           0.775981   \n",
       "11                8           0.775556           0.774563           0.775925   \n",
       "12                4           0.775569           0.775081           0.776144   \n",
       "13                1           0.775806           0.775613           0.776513   \n",
       "14                5           0.775431           0.774806           0.776069   \n",
       "15                6           0.775756           0.774544           0.776319   \n",
       "\n",
       "    split3_test_score  split4_test_score  \n",
       "0            0.772212           0.771763  \n",
       "1            0.772212           0.771763  \n",
       "2            0.772025           0.771763  \n",
       "3            0.772025           0.771913  \n",
       "4            0.773919           0.774869  \n",
       "5            0.773962           0.774937  \n",
       "6            0.773475           0.774937  \n",
       "7            0.773406           0.774956  \n",
       "8            0.774625           0.775356  \n",
       "9            0.774775           0.775669  \n",
       "10           0.774100           0.775600  \n",
       "11           0.773713           0.775594  \n",
       "12           0.774988           0.775531  \n",
       "13           0.775369           0.775925  \n",
       "14           0.774906           0.776000  \n",
       "15           0.774338           0.775875  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#health2\n",
    "grid_dtree=GridSearchCV(dt_clf, param_grid=params, cv=5, refit=True)\n",
    "\n",
    "grid_dtree.fit(X_train, y_train)\n",
    "\n",
    "scores_df=pd.DataFrame(grid_dtree.cv_results_)\n",
    "scores_df[['params','mean_test_score','rank_test_score','split0_test_score','split1_test_score','split2_test_score',\n",
    "           'split3_test_score','split4_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV 최적 파라미터: {'max_depth': 12, 'min_samples_split': 1000}\n",
      "GridSearchCV 최고 정확도:0.7758\n"
     ]
    }
   ],
   "source": [
    "print('GridSearchCV 최적 파라미터:', grid_dtree.best_params_)\n",
    "print('GridSearchCV 최고 정확도:{0:.4f}'.format(grid_dtree.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#health4 DT GridSearchCV 최적의 하이퍼 파라미터 찾기\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "\n",
    "X=health4_df.iloc[:,:-1]\n",
    "y=health4_df.iloc[:,-1]\n",
    "\n",
    "dt4_clf=DecisionTreeClassifier()\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "params={'max_depth':[10,30,50,100], 'min_samples_split':[1500, 2000, 2500, 3000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 1500}</td>\n",
       "      <td>0.833352</td>\n",
       "      <td>14</td>\n",
       "      <td>0.833718</td>\n",
       "      <td>0.833291</td>\n",
       "      <td>0.833046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 2000}</td>\n",
       "      <td>0.833377</td>\n",
       "      <td>13</td>\n",
       "      <td>0.833688</td>\n",
       "      <td>0.833199</td>\n",
       "      <td>0.833245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 2500}</td>\n",
       "      <td>0.833311</td>\n",
       "      <td>15</td>\n",
       "      <td>0.833631</td>\n",
       "      <td>0.833084</td>\n",
       "      <td>0.833218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 3000}</td>\n",
       "      <td>0.833152</td>\n",
       "      <td>16</td>\n",
       "      <td>0.833642</td>\n",
       "      <td>0.833088</td>\n",
       "      <td>0.832725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 1500}</td>\n",
       "      <td>0.833519</td>\n",
       "      <td>7</td>\n",
       "      <td>0.834009</td>\n",
       "      <td>0.833543</td>\n",
       "      <td>0.833004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 2000}</td>\n",
       "      <td>0.833563</td>\n",
       "      <td>1</td>\n",
       "      <td>0.834089</td>\n",
       "      <td>0.833398</td>\n",
       "      <td>0.833203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 2500}</td>\n",
       "      <td>0.833550</td>\n",
       "      <td>4</td>\n",
       "      <td>0.834039</td>\n",
       "      <td>0.833497</td>\n",
       "      <td>0.833115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 3000}</td>\n",
       "      <td>0.833428</td>\n",
       "      <td>10</td>\n",
       "      <td>0.834112</td>\n",
       "      <td>0.833512</td>\n",
       "      <td>0.832661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'max_depth': 50, 'min_samples_split': 1500}</td>\n",
       "      <td>0.833519</td>\n",
       "      <td>7</td>\n",
       "      <td>0.834009</td>\n",
       "      <td>0.833543</td>\n",
       "      <td>0.833004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'max_depth': 50, 'min_samples_split': 2000}</td>\n",
       "      <td>0.833563</td>\n",
       "      <td>1</td>\n",
       "      <td>0.834089</td>\n",
       "      <td>0.833398</td>\n",
       "      <td>0.833203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'max_depth': 50, 'min_samples_split': 2500}</td>\n",
       "      <td>0.833550</td>\n",
       "      <td>4</td>\n",
       "      <td>0.834039</td>\n",
       "      <td>0.833497</td>\n",
       "      <td>0.833115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'max_depth': 50, 'min_samples_split': 3000}</td>\n",
       "      <td>0.833428</td>\n",
       "      <td>10</td>\n",
       "      <td>0.834112</td>\n",
       "      <td>0.833512</td>\n",
       "      <td>0.832661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'max_depth': 100, 'min_samples_split': 1500}</td>\n",
       "      <td>0.833519</td>\n",
       "      <td>7</td>\n",
       "      <td>0.834009</td>\n",
       "      <td>0.833543</td>\n",
       "      <td>0.833004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'max_depth': 100, 'min_samples_split': 2000}</td>\n",
       "      <td>0.833563</td>\n",
       "      <td>1</td>\n",
       "      <td>0.834089</td>\n",
       "      <td>0.833398</td>\n",
       "      <td>0.833203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'max_depth': 100, 'min_samples_split': 2500}</td>\n",
       "      <td>0.833550</td>\n",
       "      <td>4</td>\n",
       "      <td>0.834039</td>\n",
       "      <td>0.833497</td>\n",
       "      <td>0.833115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'max_depth': 100, 'min_samples_split': 3000}</td>\n",
       "      <td>0.833428</td>\n",
       "      <td>10</td>\n",
       "      <td>0.834112</td>\n",
       "      <td>0.833512</td>\n",
       "      <td>0.832661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           params  mean_test_score  \\\n",
       "0    {'max_depth': 10, 'min_samples_split': 1500}         0.833352   \n",
       "1    {'max_depth': 10, 'min_samples_split': 2000}         0.833377   \n",
       "2    {'max_depth': 10, 'min_samples_split': 2500}         0.833311   \n",
       "3    {'max_depth': 10, 'min_samples_split': 3000}         0.833152   \n",
       "4    {'max_depth': 30, 'min_samples_split': 1500}         0.833519   \n",
       "5    {'max_depth': 30, 'min_samples_split': 2000}         0.833563   \n",
       "6    {'max_depth': 30, 'min_samples_split': 2500}         0.833550   \n",
       "7    {'max_depth': 30, 'min_samples_split': 3000}         0.833428   \n",
       "8    {'max_depth': 50, 'min_samples_split': 1500}         0.833519   \n",
       "9    {'max_depth': 50, 'min_samples_split': 2000}         0.833563   \n",
       "10   {'max_depth': 50, 'min_samples_split': 2500}         0.833550   \n",
       "11   {'max_depth': 50, 'min_samples_split': 3000}         0.833428   \n",
       "12  {'max_depth': 100, 'min_samples_split': 1500}         0.833519   \n",
       "13  {'max_depth': 100, 'min_samples_split': 2000}         0.833563   \n",
       "14  {'max_depth': 100, 'min_samples_split': 2500}         0.833550   \n",
       "15  {'max_depth': 100, 'min_samples_split': 3000}         0.833428   \n",
       "\n",
       "    rank_test_score  split0_test_score  split1_test_score  split2_test_score  \n",
       "0                14           0.833718           0.833291           0.833046  \n",
       "1                13           0.833688           0.833199           0.833245  \n",
       "2                15           0.833631           0.833084           0.833218  \n",
       "3                16           0.833642           0.833088           0.832725  \n",
       "4                 7           0.834009           0.833543           0.833004  \n",
       "5                 1           0.834089           0.833398           0.833203  \n",
       "6                 4           0.834039           0.833497           0.833115  \n",
       "7                10           0.834112           0.833512           0.832661  \n",
       "8                 7           0.834009           0.833543           0.833004  \n",
       "9                 1           0.834089           0.833398           0.833203  \n",
       "10                4           0.834039           0.833497           0.833115  \n",
       "11               10           0.834112           0.833512           0.832661  \n",
       "12                7           0.834009           0.833543           0.833004  \n",
       "13                1           0.834089           0.833398           0.833203  \n",
       "14                4           0.834039           0.833497           0.833115  \n",
       "15               10           0.834112           0.833512           0.832661  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_dtree4=GridSearchCV(dt4_clf, param_grid=params, cv=3, refit=True)\n",
    "\n",
    "grid_dtree4.fit(X_train, y_train)\n",
    "\n",
    "scores4_df=pd.DataFrame(grid_dtree4.cv_results_)\n",
    "scores4_df[['params','mean_test_score','rank_test_score','split0_test_score','split1_test_score','split2_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV 최적 파라미터: {'max_depth': 30, 'min_samples_split': 2000}\n",
      "GridSearchCV 최고 정확도:0.8336\n"
     ]
    }
   ],
   "source": [
    "print('GridSearchCV 최적 파라미터:', grid_dtree4.best_params_)\n",
    "print('GridSearchCV 최고 정확도:{0:.4f}'.format(grid_dtree4.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 1500}</td>\n",
       "      <td>0.833088</td>\n",
       "      <td>15</td>\n",
       "      <td>0.834385</td>\n",
       "      <td>0.833691</td>\n",
       "      <td>0.831342</td>\n",
       "      <td>0.833111</td>\n",
       "      <td>0.832913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 2000}</td>\n",
       "      <td>0.833093</td>\n",
       "      <td>14</td>\n",
       "      <td>0.834588</td>\n",
       "      <td>0.833583</td>\n",
       "      <td>0.831336</td>\n",
       "      <td>0.833085</td>\n",
       "      <td>0.832875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 2500}</td>\n",
       "      <td>0.833126</td>\n",
       "      <td>10</td>\n",
       "      <td>0.834518</td>\n",
       "      <td>0.833697</td>\n",
       "      <td>0.831406</td>\n",
       "      <td>0.833181</td>\n",
       "      <td>0.832831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 3000}</td>\n",
       "      <td>0.833004</td>\n",
       "      <td>16</td>\n",
       "      <td>0.834289</td>\n",
       "      <td>0.833895</td>\n",
       "      <td>0.831399</td>\n",
       "      <td>0.832926</td>\n",
       "      <td>0.832512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 1500}</td>\n",
       "      <td>0.833349</td>\n",
       "      <td>7</td>\n",
       "      <td>0.834843</td>\n",
       "      <td>0.833175</td>\n",
       "      <td>0.832010</td>\n",
       "      <td>0.833811</td>\n",
       "      <td>0.832907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 2000}</td>\n",
       "      <td>0.833403</td>\n",
       "      <td>4</td>\n",
       "      <td>0.834805</td>\n",
       "      <td>0.833131</td>\n",
       "      <td>0.832354</td>\n",
       "      <td>0.833626</td>\n",
       "      <td>0.833098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 2500}</td>\n",
       "      <td>0.833410</td>\n",
       "      <td>1</td>\n",
       "      <td>0.834665</td>\n",
       "      <td>0.833360</td>\n",
       "      <td>0.832501</td>\n",
       "      <td>0.833607</td>\n",
       "      <td>0.832920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 3000}</td>\n",
       "      <td>0.833123</td>\n",
       "      <td>11</td>\n",
       "      <td>0.834429</td>\n",
       "      <td>0.833544</td>\n",
       "      <td>0.831667</td>\n",
       "      <td>0.833422</td>\n",
       "      <td>0.832550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'max_depth': 50, 'min_samples_split': 1500}</td>\n",
       "      <td>0.833349</td>\n",
       "      <td>7</td>\n",
       "      <td>0.834843</td>\n",
       "      <td>0.833175</td>\n",
       "      <td>0.832010</td>\n",
       "      <td>0.833811</td>\n",
       "      <td>0.832907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'max_depth': 50, 'min_samples_split': 2000}</td>\n",
       "      <td>0.833403</td>\n",
       "      <td>4</td>\n",
       "      <td>0.834805</td>\n",
       "      <td>0.833131</td>\n",
       "      <td>0.832354</td>\n",
       "      <td>0.833626</td>\n",
       "      <td>0.833098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'max_depth': 50, 'min_samples_split': 2500}</td>\n",
       "      <td>0.833410</td>\n",
       "      <td>1</td>\n",
       "      <td>0.834665</td>\n",
       "      <td>0.833360</td>\n",
       "      <td>0.832501</td>\n",
       "      <td>0.833607</td>\n",
       "      <td>0.832920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'max_depth': 50, 'min_samples_split': 3000}</td>\n",
       "      <td>0.833123</td>\n",
       "      <td>11</td>\n",
       "      <td>0.834429</td>\n",
       "      <td>0.833544</td>\n",
       "      <td>0.831667</td>\n",
       "      <td>0.833422</td>\n",
       "      <td>0.832550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'max_depth': 100, 'min_samples_split': 1500}</td>\n",
       "      <td>0.833349</td>\n",
       "      <td>7</td>\n",
       "      <td>0.834843</td>\n",
       "      <td>0.833175</td>\n",
       "      <td>0.832010</td>\n",
       "      <td>0.833811</td>\n",
       "      <td>0.832907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'max_depth': 100, 'min_samples_split': 2000}</td>\n",
       "      <td>0.833403</td>\n",
       "      <td>4</td>\n",
       "      <td>0.834805</td>\n",
       "      <td>0.833131</td>\n",
       "      <td>0.832354</td>\n",
       "      <td>0.833626</td>\n",
       "      <td>0.833098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'max_depth': 100, 'min_samples_split': 2500}</td>\n",
       "      <td>0.833410</td>\n",
       "      <td>1</td>\n",
       "      <td>0.834665</td>\n",
       "      <td>0.833360</td>\n",
       "      <td>0.832501</td>\n",
       "      <td>0.833607</td>\n",
       "      <td>0.832920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'max_depth': 100, 'min_samples_split': 3000}</td>\n",
       "      <td>0.833123</td>\n",
       "      <td>11</td>\n",
       "      <td>0.834429</td>\n",
       "      <td>0.833544</td>\n",
       "      <td>0.831667</td>\n",
       "      <td>0.833422</td>\n",
       "      <td>0.832550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           params  mean_test_score  \\\n",
       "0    {'max_depth': 10, 'min_samples_split': 1500}         0.833088   \n",
       "1    {'max_depth': 10, 'min_samples_split': 2000}         0.833093   \n",
       "2    {'max_depth': 10, 'min_samples_split': 2500}         0.833126   \n",
       "3    {'max_depth': 10, 'min_samples_split': 3000}         0.833004   \n",
       "4    {'max_depth': 30, 'min_samples_split': 1500}         0.833349   \n",
       "5    {'max_depth': 30, 'min_samples_split': 2000}         0.833403   \n",
       "6    {'max_depth': 30, 'min_samples_split': 2500}         0.833410   \n",
       "7    {'max_depth': 30, 'min_samples_split': 3000}         0.833123   \n",
       "8    {'max_depth': 50, 'min_samples_split': 1500}         0.833349   \n",
       "9    {'max_depth': 50, 'min_samples_split': 2000}         0.833403   \n",
       "10   {'max_depth': 50, 'min_samples_split': 2500}         0.833410   \n",
       "11   {'max_depth': 50, 'min_samples_split': 3000}         0.833123   \n",
       "12  {'max_depth': 100, 'min_samples_split': 1500}         0.833349   \n",
       "13  {'max_depth': 100, 'min_samples_split': 2000}         0.833403   \n",
       "14  {'max_depth': 100, 'min_samples_split': 2500}         0.833410   \n",
       "15  {'max_depth': 100, 'min_samples_split': 3000}         0.833123   \n",
       "\n",
       "    rank_test_score  split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0                15           0.834385           0.833691           0.831342   \n",
       "1                14           0.834588           0.833583           0.831336   \n",
       "2                10           0.834518           0.833697           0.831406   \n",
       "3                16           0.834289           0.833895           0.831399   \n",
       "4                 7           0.834843           0.833175           0.832010   \n",
       "5                 4           0.834805           0.833131           0.832354   \n",
       "6                 1           0.834665           0.833360           0.832501   \n",
       "7                11           0.834429           0.833544           0.831667   \n",
       "8                 7           0.834843           0.833175           0.832010   \n",
       "9                 4           0.834805           0.833131           0.832354   \n",
       "10                1           0.834665           0.833360           0.832501   \n",
       "11               11           0.834429           0.833544           0.831667   \n",
       "12                7           0.834843           0.833175           0.832010   \n",
       "13                4           0.834805           0.833131           0.832354   \n",
       "14                1           0.834665           0.833360           0.832501   \n",
       "15               11           0.834429           0.833544           0.831667   \n",
       "\n",
       "    split3_test_score  split4_test_score  \n",
       "0            0.833111           0.832913  \n",
       "1            0.833085           0.832875  \n",
       "2            0.833181           0.832831  \n",
       "3            0.832926           0.832512  \n",
       "4            0.833811           0.832907  \n",
       "5            0.833626           0.833098  \n",
       "6            0.833607           0.832920  \n",
       "7            0.833422           0.832550  \n",
       "8            0.833811           0.832907  \n",
       "9            0.833626           0.833098  \n",
       "10           0.833607           0.832920  \n",
       "11           0.833422           0.832550  \n",
       "12           0.833811           0.832907  \n",
       "13           0.833626           0.833098  \n",
       "14           0.833607           0.832920  \n",
       "15           0.833422           0.832550  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_dtree4=GridSearchCV(dt4_clf, param_grid=params, cv=5, refit=True)\n",
    "\n",
    "grid_dtree4.fit(X_train, y_train)\n",
    "\n",
    "scores4_df=pd.DataFrame(grid_dtree4.cv_results_)\n",
    "scores4_df[['params','mean_test_score','rank_test_score','split0_test_score','split1_test_score','split2_test_score',\n",
    "            'split3_test_score','split4_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV 최적 파라미터: {'max_depth': 30, 'min_samples_split': 2500}\n",
      "GridSearchCV 최고 정확도:0.8334\n"
     ]
    }
   ],
   "source": [
    "print('GridSearchCV 최적 파라미터:', grid_dtree4.best_params_)\n",
    "print('GridSearchCV 최고 정확도:{0:.4f}'.format(grid_dtree4.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "랜덤 포레스트 정확도: 0.8149\n"
     ]
    }
   ],
   "source": [
    "#RandomForest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# 랜덤 포레스트 학습 및 별도의 테스트 셋으로 예측 성능 평가\n",
    "rf_clf = RandomForestClassifier(random_state=0)\n",
    "rf_clf.fit(X_train , y_train)\n",
    "pred_rf = rf_clf.predict(X_test)\n",
    "accuracy_rf = accuracy_score(y_test , pred_rf)\n",
    "print('랜덤 포레스트 정확도: {0:.4f}'.format(accuracy_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적 하이퍼 파라미터:\n",
      " {'max_depth': 30, 'min_samples_split': 500, 'n_estimators': 100}\n",
      "최고 예측 정확도: 0.8348\n"
     ]
    }
   ],
   "source": [
    "#RandomForest GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameter = {\n",
    "    'n_estimators':[100],\n",
    "    'max_depth' : [10,30,50,100],\n",
    "    'min_samples_split' : [500,1000, 1200]\n",
    "}\n",
    "# RandomForestClassifier 객체 생성 후 GridSearchCV 수행\n",
    "rf_clf = RandomForestClassifier(random_state=0, n_jobs=-1)\n",
    "grid_cv = GridSearchCV(rf_clf , param_grid=parameter, cv=2, n_jobs=-1 )\n",
    "grid_cv.fit(X_train , y_train)\n",
    "\n",
    "print('최적 하이퍼 파라미터:\\n', grid_cv.best_params_)\n",
    "print('최고 예측 정확도: {0:.4f}'.format(grid_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도: 0.8344\n"
     ]
    }
   ],
   "source": [
    "rf_clf1 = RandomForestClassifier(n_estimators=100, max_depth=30,\n",
    "                                 min_samples_split=500, random_state=0)\n",
    "rf_clf1.fit(X_train , y_train)\n",
    "pred_rf1 = rf_clf1.predict(X_test)\n",
    "print('예측 정확도: {0:.4f}'.format(accuracy_score(y_test , pred_rf1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhIAAAF1CAYAAAC9JAPAAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy86wFpkAAAACXBIWXMAAAsTAAALEwEAmpwYAAAbF0lEQVR4nO3deZRlZX3u8e8DzdxM0sxToyIQuYjQBnECjJqgGGSJFw0O4NByIxqXghOJkmAg0eAEupSoOICKAhJckoje2OgFzaIxDVzGyxim2DRDC9gitL/7x9mlx7Kqu+rtrjrU6e9nrVp99n7fvffvvN2rz3Ped59TqSokSZJarDXoAiRJ0sxlkJAkSc0MEpIkqZlBQpIkNTNISJKkZgYJSZLUzCAhadKSfCDJ5wddh6TBM0hI0yzJbUmWJXm472e71XDOF62uGlemqk6uqjdP1/VWJMmJSc4adB0TkeSzfX/nv07yWN/2v67G62yZ5GtJHkzyQJKzV9e5pdFmDboAaQ318qr6waCLGJFkVlU9Pug6JivJjPo/rKqOAY6BXgACnlpVr52CS50PXA7sDPwS2HMKriEBzkhITxhJNk3yhST3JLkryYeTrN21PSXJvye5L8mSJGcn2axr+yqwE/Cd7p3te5IcmOTOUef/7axF9y7+3CRnJfkFcNSKrj9Grb+dBUgyN0klOTrJHd074GOSPCvJVd274tP7jj0qyaVJTkuyNMn1Sf6kr327JBcmuT/JTUneMuq6/XUfA3wAOKJ77ld2/Y5Ocl2Sh5LckuStfec4MMmdSd6dZHH3fI/ua98gyalJbu/q+z9JNujanp3ksu45XZnkwFHP65bumrcmOXKSf/9/nuSa7twLkuwx6u/u/Umu7cb3zCTrj3OelwA7AsdX1dKqeqyq/nMytUiTYZCQnji+DDwOPBV4JvASYGT5IMApwHbAHvReKE4EqKrXAf9Fb5ZjdlV9ZILXOxQ4F9gMOHsl15+I/YBdgSOATwAnAC8Cng78zyQHjOp7CzAH+BBwfpIndW1fB+7snuvhwMn9QWNU3V8ATgbO6Z77M7o+i4FDgE2Ao4GPJ9mn7xzbAJsC2wNvAj6dZPOu7Z+AfYHnAE8C3gP8Jsn2wHeBD3f7jwPO65YRNgI+BRxcVRt3xy6a6MAleVr3vN8JbAlcRC8YrtvX7UjgT4GnAE8D/nqc0z0buAH4chc8Lx819tJqZZCQBuOC7p3ng0kuSLI1cDDwzqp6pKoWAx8HXg1QVTdV1fer6tGquhf4GLCqLw4/qaoLquo39F5wx73+BJ1UVb+qqouBR4CvV9XiqroL+DG9cDJiMfCJ7t3yOfRe+F6WZEfgecB7u3MtAj4PvG6suqtq2ViFVNV3q+rm6rkEuBh4fl+Xx4C/665/EfAwsFuStYA3An9VVXdV1fKquqyqHgVeC1xUVRd11/4+sBB4aXfO3wB7Jtmgqu6pqmsmMXZHAN/t/o4foxdmNqAXSEacXlV3VNX9wN8DrxnnXDvQC4E/pBeYTgX+JcmcSdQjTZhBQhqMV1TVZt3PK+itZa8D3DMSMIDPAVsBJNkqyTe6JYdfAGfReze/Ku7oe7zC60/Qz/seLxtje3bf9l31+78x8HZ6MxDbAfdX1UOj2rYfp+4xJTk4yU+75ZEH6b3Y94/XfaPuCfllV98cYH3g5jFOuzPwqr4A+CC90LNtVT1CLwwcQ28Mv5tk95XV2Wc7es8TgC7c3cH4z3tkvMayDLitqr7QBaVvdMc+dxL1SBNmkJCeGO4AHgXm9AWMTarq6V37KUABe1XVJvTeHafv+NG/xvcRYMORje5ehy1H9ek/ZmXXX922T9Jf/07A3d3Pk5JsPKrtrnHq/oPtJOsB59F7V791VW1Gb6kgrNwS4Ff0lg9GuwP4at/4bFZVG1XVPwBU1feq6sXAtsD1wD9P4Hoj7qYXVEaeQ+gtX/U/7x37Ho+M11iu4g/HSJoyBgnpCaCq7qE3/X5qkk2SrJXeDZYjyxcb05t+f7Bbqz9+1Cl+Djy5b/tGYP0kL0uyDr319PVW4fqr21bAO5Ksk+RV9O77uKiq7gAuA05Jsn6Svejdw7Cijy/+HJjbLUsArEvvud4LPJ7kYHpT/SvVzQR8EfhYd9Pn2kn278LJWcDLk/xpt3/97sbNHZJs3d0suRG9QPYwsHwS4/FNeks7f9L9fb27O89lfX3e1l3rSfRuMD1nnHN9G9g8yRu6Og+nN7Nx6STqkSbMICE9cbye3ovgtcAD9G4o3LZr+1tgH2ApvRv+zh917CnAX3dT7sdV1VLgL+ndX3AXvRmKO1mxFV1/dfsPejdmLqG33n94Vd3Xtb0GmEvvHfe3gQ919yOM51vdn/cl+Vm3LPIOei/ODwB/AVw4idqOA66m9/HJ+4F/BNbqQs6h9F7E76U3Q3E8vf9H16L34n93d8wB9MZ/QqrqBnqzTKfRG5OX07t59td93b5GL+zd0v18eJxz3Q/8efc8lgLvAw6tqiUTrUeajPz+MqUkTa0kRwFvrqrnDbqWmSLJbfTG7Anz3SPSCGckJElSM4OEJElq5tKGJElq5oyEJElqZpCQJEnNZtRvznuimDNnTs2dO3fQZUiSNC2uuOKKJVU1+kvtAINEk7lz57Jw4cJBlyFJ0rRIcvt4bS5tSJKkZgYJSZLUzCAhSZKaeY9Eg+vuvI99j//KoMuQJOkPXPHR10/r9ZyRkCRJzQwSkiSpmUFCkiQ1M0hIkqRmBglJktTMICFJkpoZJCRJUjODhCRJamaQkCRJzQwSkiSpmUFCkiQ1M0hIkqRmBglJktTMICFJkpoZJCRJUjODhCRJamaQkCRJzQwSkiSp2RM+SCSZtaJtSZI0OBMKEkkuSHJFkmuSzO/2vSnJjUkWJPnnJKd3+7dMcl6Sy7uf567gvH+c5LIk/9n9uVu3/6gk30ryHeDiMbZnJ/nfSX6W5Ookh3bHzU1yXVfPNUkuTrJB1/asJFcl+UmSjyb5v93+tbvty7v2t67KgEqStCaZ6IzEG6tqX2Ae8I4k2wN/AzwbeDGwe1/fTwIfr6pnAa8EPr+C814PvKCqngl8EDi5r21/4A1V9cIxtn8FHFZV+wAHAacmSddvV+DTVfV04MGuBoAzgWOqan9ged913gQs7ep9FvCWJLtMZFAkSVrTTXSZ4B1JDuse7wi8Drikqu4HSPIt4Gld+4uAP/rd6zqbJNm4qh4a47ybAl9OsitQwDp9bd8fOf8Y2wFOTvIC4DfA9sDWXdutVbWoe3wFMDfJZsDGVXVZt/9rwCHd45cAeyU5vK+mXYFb+wvtZmLmA6y78RZjPBVJktY8Kw0SSQ6kFw72r6pfJlkA3ADsMc4ha3V9l03g+icBP6yqw5LMBRb0tT0yqm//9pHAlsC+VfVYktuA9bu2R/v6LQc2oBc8xhPg7VX1vRUVWlVnAGcAbLTNLrWivpIkrSkmsrSxKfBAFyJ2p7ecsSFwQJLNu5sfX9nX/2Lg2JGNJHuv5Nx3dY+PmkTdmwKLuxBxELDzijpX1QPAQ0me3e16dV/z94D/lWSdrt6nJdloErVIkrTGmkiQ+DdgVpKr6M0g/JTei//JwH8APwCuBZZ2/d8BzOtuXLwWOGYF5/4IcEqSS4G1J1H32d01FtKbnbh+Ase8CTgjyU/ozUKM1Pv5rv6fdTdgfo6JL/lIkrRGS1XbLH2S2VX1cDcj8W3gi1X17dVa3Wo0Um/3+H3AtlX1Vy3n2mibXWr31/3taq1PkqTV4YqPvn61nzPJFVU1b6y2VXnnfWKSF9G7N+Fi4IJVONd0eFmS99N7zrczuaUUSZI0huYgUVXHTbRvkqOB0e/+L62qt7Vef7Kq6hzgnOm6niRJa4JpuRegqs6k9z0OkiRpiDzhvyJbkiQ9cRkkJElSM4OEJElqZpCQJEnNDBKSJKmZQUKSJDUzSEiSpGYGCUmS1MwgIUmSmhkkJElSM4OEJElqZpCQJEnNDBKSJKmZQUKSJDWbll8jPmz22GELFn709YMuQ5KkgXNGQpIkNTNISJKkZgYJSZLUzCAhSZKaGSQkSVIzg4QkSWpmkJAkSc0MEpIkqZlBQpIkNfObLRv8+p5r+K+/+x+DLkOSVslOH7x60CVoCDgjIUmSmhkkJElSM4OEJElqZpCQJEnNDBKSJKmZQUKSJDUzSEiSpGYGCUmS1MwgIUmSmhkkJElSM4OEJElqZpCQJEnNDBKSJKmZQUKSJDUzSEiSpGYGCUmS1MwgIUmSmhkkJElSs1mDLmB1S7IcuLpv1yuAucC/ALfSC0+Lgb+oqsVJdgM+B2wGrAf8uKrmT2PJkiTNWMM4I7Gsqvbu+7mt2//jbnsv4HLgbd3+TwEf79r2AE4bQM2SJM1IwxgkVihJgI2BB7pd2wJ3jrRX1dVjHSdJkv7Q0C1tABskWdQ9vrWqDuseP7/bvwXwCPCBbv/HgX9PchlwMXBmVT04+qRJ5gPzAbbfdJ0pK16SpJlkGGck+pc2DuvbP7K0sSNwJvARgKo6E9gD+BZwIPDTJOuNPmlVnVFV86pq3pM2Wnvqn4UkSTPAMAaJibgQeMHIRlXdXVVfrKpDgceBPQdWmSRJM8iaGiSeB9wMkOTPkqzTPd6G3tLHXQOsTZKkGWMY75EYz8g9EgGWAm/u9r8E+GSSX3Xbx1fVfw+gPkmSZpyhCxJVNXuMfQuATcfp/y7gXVNcliRJQ2lNXdqQJEmrgUFCkiQ1M0hIkqRmBglJktTMICFJkpoZJCRJUjODhCRJamaQkCRJzQwSkiSpmUFCkiQ1M0hIkqRmBglJktTMICFJkpoZJCRJUjODhCRJamaQkCRJzWYNuoCZaN1tn85OH1w46DIkSRo4ZyQkSVIzg4QkSWpmkJAkSc0MEpIkqZlBQpIkNTNISJKkZgYJSZLUzCAhSZKaGSQkSVIzg4QkSWrmV2Q3uH7x9Tz3tOcOugyN4dK3XzroEiRpjeKMhCRJamaQkCRJzQwSkiSpmUFCkiQ1M0hIkqRmBglJktTMICFJkpoZJCRJUjODhCRJamaQkCRJzQwSkiSpmUFCkiQ1M0hIkqRmBglJktTMICFJkpoZJCRJUjODhCRJajaUQSLJCUmuSXJVkkVJ9kuyIMkN3fZ1Seb39b8tydVJrkxycZJtBlm/JEkzxdAFiST7A4cA+1TVXsCLgDu65iOram/gucA/Jlm379CDquoZwELgA9NYsiRJM9bQBQlgW2BJVT0KUFVLquruUX1mA48Ay8c4/kfAU6e2REmShsMwBomLgR2T3JjkM0kO6Gs7O8lVwA3ASVU1VpA4BLh6OgqVJGmmG7ogUVUPA/sC84F7gXOSHNU1H9ktd+wEHJdk575Df5hkEbAJcMro8yaZn2RhkoWPPfzYVD4FSZJmjFmDLmAqdDMNC4AFSa4G3jCq/d4kPwP2A27vdh9UVUtWcM4zgDMAZu80u6aibkmSZpqhm5FIsluSXft27c3vwsJInw2BZwI3T2NpkiQNnWGckZgNnJZkM+Bx4CZ6yxzn0rtHYhmwHvClqrpiYFVKkjQEhi5IdOHgOWM0HbiCY+ZOVT2SJA2zoVvakCRJ08cgIUmSmhkkJElSM4OEJElqZpCQJEnNDBKSJKmZQUKSJDUzSEiSpGYGCUmS1MwgIUmSmhkkJElSM4OEJElqZpCQJEnNDBKSJKmZQUKSJDUzSEiSpGazBl3ATLT7Vrtz6dsvHXQZkiQNnDMSkiSpmUFCkiQ1M0hIkqRmBglJktTMICFJkpoZJCRJUjODhCRJamaQkCRJzQwSkiSpmUFCkiQ18yuyGzx0ww1c8oIDBl3GKjvgR5cMugRJ0gznjIQkSWpmkJAkSc0MEpIkqZlBQpIkNTNISJKkZgYJSZLUzCAhSZKaGSQkSVIzg4QkSWpmkJAkSc0MEpIkqZlBQpIkNTNISJKkZgYJSZLUzCAhSZKaGSQkSVIzg4QkSWo2lEEiyfIki5JcmeRnSZ7T7Z+bpJKc1Nd3TpLHkpzebZ+Y5LhB1S5J0kwylEECWFZVe1fVM4D3A6f0td0CHNK3/SrgmuksTpKkYTGsQaLfJsADfdvLgOuSzOu2jwC+Oe1VSZI0BGYNuoApskGSRcD6wLbAC0e1fwN4dZL/BpYDdwPbTWuFkiQNgWENEsuqam+AJPsDX0myZ1/7vwEnAT8HzpnICZPMB+YDbL3eequ1WEmSZqqhX9qoqp8Ac4At+/b9GrgCeDdw3gTPc0ZVzauqeZuus86U1CpJ0kwzrDMSv5Vkd2Bt4D5gw76mU4FLquq+JAOpTZKkmW5Yg8TIPRIAAd5QVcv7A0NVXYOf1pAkaZUMZZCoqrXH2X8bsOcY+78EfKl7fOLUVSZJ0nAZ+nskJEnS1DFISJKkZgYJSZLUzCAhSZKaGSQkSVIzg4QkSWpmkJAkSc0MEpIkqZlBQpIkNTNISJKkZgYJSZLUzCAhSZKaGSQkSVIzg4QkSWpmkJAkSc0MEpIkqZlBQpIkNZs16AJmoo13240DfnTJoMuQJGngnJGQJEnNDBKSJKmZQUKSJDUzSEiSpGYGCUmS1MwgIUmSmhkkJElSM4OEJElqZpCQJEnNDBKSJKmZX5HdYPGdSzn93d+Z0msce+rLp/T8kiStDs5ISJKkZgYJSZLUzCAhSZKaGSQkSVIzg4QkSWpmkJAkSc0MEpIkqZlBQpIkNTNISJKkZgYJSZLUzCAhSZKaGSQkSVIzg4QkSWpmkJAkSc0MEpIkqZlBQpIkNTNISJKkZkMTJJIsT7IoyTVJrkzyriRrdW0HJlnatV+V5AdJturajkpyb9d2bZK3DPaZSJI0cwxNkACWVdXeVfV04MXAS4EP9bX/uGvfC7gceFtf2zlVtTdwIHBykq2nqWZJkma0YQoSv1VVi4H5wLFJ0t/WbW8MPDDOcTcDO09HnZIkzXSzBl3AVKmqW7qlja26Xc9PsgjYAngE+MDoY5I8GXgycNMYbfPphRM233jLKapakqSZZShnJPr0z0aMLG3sCJwJfKSv7YguZHwdeGtV3T/6RFV1RlXNq6p5szfcdEqLliRpphjaGYludmE5sBjYY1TzhcB5fdvnVNWx01WbJEnDYihnJJJsCXwWOL2qaowuz6N3L4QkSVoFwzQjsUG3PLEO8DjwVeBjfe0j90gEWAq8eboLlCRp2AxNkKiqtVfQtgAY88aGqvoS8KUpKUqSpCE3lEsbkiRpehgkJElSM4OEJElqZpCQJEnNDBKSJKmZQUKSJDUzSEiSpGYGCUmS1MwgIUmSmhkkJElSM4OEJElqZpCQJEnNDBKSJKmZQUKSJDUzSEiSpGYGCUmS1GzWoAuYibbaYVOOPfXlgy5DkqSBc0ZCkiQ1M0hIkqRmBglJktTMICFJkpoZJCRJUjODhCRJamaQkCRJzQwSkiSpmUFCkiQ1M0hIkqRmfkV2g3tuvZm/f+3hv7fvhLPOHVA1kiQNjjMSkiSpmUFCkiQ1M0hIkqRmBglJktTMICFJkpoZJCRJUjODhCRJamaQkCRJzQwSkiSpmUFCkiQ1M0hIkqRmBglJktTMICFJkpoZJCRJUjODhCRJamaQkCRJzQwSkiSp2dAFiSQnJLkmyVVJFiXZL8mCJDd024uSnNv1/VSSvxl17KcHV70kSTPLrEEXsDol2R84BNinqh5NMgdYt2s+sqoWjjrkr4FFSc4GCngz8MxpK1iSpBluqIIEsC2wpKoeBaiqJQBJxuxcVb9IcgJwerfrg1X14DTUKUnSUBi2pY2LgR2T3JjkM0kO6Gs7u29p46MjO6vq68DmwCZV9dXpLliSpJlsqGYkqurhJPsCzwcOAs5J8r6ueaylDZLsAGwDVJLZVfXwWOdOMh+YD7DphhtMSf2SJM00QxUkAKpqObAAWJDkauANKznkk8CJwB7Ah4DjxznvGcAZANtvsXmtpnIlSZrRhipIJNkN+E1V/b9u197A7cCe4/Q/GNgK+AqwIXBlkjOr6tppKFeSpBlvqIIEMBs4LclmwOPATfSWI86ld4/Esq7fEnqf7vgEcHhVFfBIkvfQu/HyhdNctyRJM9JQBYmqugJ4zhhNB45zyG6jjj8fOH81lyVJ0tAatk9tSJKkaWSQkCRJzQwSkiSpmUFCkiQ1M0hIkqRmBglJktTMICFJkpoZJCRJUjODhCRJamaQkCRJzQwSkiSpmUFCkiQ1M0hIkqRmBglJktTMICFJkpoZJCRJUrNZgy5gJtp2l6dwwlnnDroMSZIGzhkJSZLUzCAhSZKaGSQkSVIzg4QkSWpmkJAkSc1SVYOuYcZJ8hBww6DrWIPMAZYMuog1hGM9vRzv6eNYr5qdq2rLsRr8+GebG6pq3qCLWFMkWeh4Tw/Heno53tPHsZ46Lm1IkqRmBglJktTMINHmjEEXsIZxvKePYz29HO/p41hPEW+2lCRJzZyRkCRJzQwSK5Dkz5LckOSmJO8boz1JPtW1X5Vkn0HUOQwmMNa7J/lJkkeTHDeIGofJBMb7yO7f9FVJLkvyjEHUOQwmMNaHduO8KMnCJM8bRJ3DYmXj3dfvWUmWJzl8OusbRi5tjCPJ2sCNwIuBO4HLgddU1bV9fV4KvB14KbAf8Mmq2m8A5c5oExzrrYCdgVcAD1TVPw2g1KEwwfF+DnBdVT2Q5GDgRP9tT94Ex3o28EhVVZK9gG9W1e4DKXiGm8h49/X7PvAr4ItV5a9zXgXOSIzvj4GbquqWqvo18A3g0FF9DgW+Uj0/BTZLsu10FzoEVjrWVbW4qi4HHhtEgUNmIuN9WVU90G3+FNhhmmscFhMZ64frd+/oNgJ8d9duIv9vQ+8N4HnA4uksblgZJMa3PXBH3/ad3b7J9tHKOY7Ta7Lj/SbgX6e0ouE1obFOcliS64HvAm+cptqG0UrHO8n2wGHAZ6exrqFmkBhfxtg3+p3CRPpo5RzH6TXh8U5yEL0g8d4prWh4TWisq+rb3XLGK4CTprqoITaR8f4E8N6qWj715awZ/Irs8d0J7Ni3vQNwd0MfrZzjOL0mNN7dev3ngYOr6r5pqm3YTOrfdlX9KMlTksypKn8vxORNZLznAd9IAr3fv/HSJI9X1QXTUuEQckZifJcDuybZJcm6wKuBC0f1uRB4fffpjWcDS6vqnukudAhMZKy1+qx0vJPsBJwPvK6qbhxAjcNiImP91HSvat0nv9YFDG5tVjreVbVLVc2tqrnAucBfGiJWjTMS46iqx5McC3wPWJvenb3XJDmma/8scBG9T2zcBPwSOHpQ9c5kExnrJNsAC4FNgN8keSfwR1X1i0HVPVNN8N/2B4EtgM90r3GP+wuPJm+CY/1Kem9IHgOWAUf03XypSZjgeGs18+OfkiSpmUsbkiSpmUFCkiQ1M0hIkqRmBglJktTMICFJkpoZJCRJUjODhCRJamaQkCRJzf4/DImULvYhV+4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "ftr_importances_values = rf_clf1.feature_importances_\n",
    "ftr_importances = pd.Series(ftr_importances_values,index=X_train.columns  )\n",
    "ftr_top6 = ftr_importances.sort_values(ascending=False)[:6]\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title('Feature importances Top 6')\n",
    "sns.barplot(x=ftr_top6 , y = ftr_top6.index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stacking\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "X_train,X_test, y_train,y_test=train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_clf4=KNeighborsClassifier(n_neighbors=4)\n",
    "rf_clf4=RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "dt_clf4=DecisionTreeClassifier()\n",
    "ada_clf4=AdaBoostClassifier(n_estimators=100)\n",
    "\n",
    "#스태킹으로 만들어진 데이터 세트를 학습, 예측할 최종 모델\n",
    "lr_final=LogisticRegression(C=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(n_estimators=100)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_clf4.fit(X_train, y_train)\n",
    "rf_clf4.fit(X_train, y_train)\n",
    "dt_clf4.fit(X_train, y_train)\n",
    "ada_clf4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN 정확도: 0.8092\n",
      "RandomForest 정확도: 0.8149\n",
      "DecisionTree 정확도: 0.7720\n",
      "AdaBoost 정확도: 0.8323\n"
     ]
    }
   ],
   "source": [
    "knn_pred4=knn_clf4.predict(X_test)\n",
    "rf_pred4=rf_clf4.predict(X_test)\n",
    "dt_pred4=dt_clf4.predict(X_test)\n",
    "ada_pred4=ada_clf4.predict(X_test)\n",
    "\n",
    "print('KNN 정확도: {0:.4f}'.format(accuracy_score(y_test, knn_pred4)))\n",
    "print('RandomForest 정확도: {0:.4f}'.format(accuracy_score(y_test, rf_pred4)))\n",
    "print('DecisionTree 정확도: {0:.4f}'.format(accuracy_score(y_test, dt_pred4)))\n",
    "print('AdaBoost 정확도: {0:.4f}'.format(accuracy_score(y_test, ada_pred4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 196389)\n",
      "(196389, 4)\n"
     ]
    }
   ],
   "source": [
    "predict=np.array([knn_pred4, rf_pred4, dt_pred4, ada_pred4])\n",
    "print(predict.shape)\n",
    "\n",
    "predict=np.transpose(predict)\n",
    "print(predict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 메타모델의 예측 정확도: 0.8285\n"
     ]
    }
   ],
   "source": [
    "lr_final.fit(predict, y_test)\n",
    "final=lr_final.predict(predict)\n",
    "\n",
    "print('최종 메타모델의 예측 정확도: {0:.4f}'.format(accuracy_score(y_test, final)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [196389, 785553]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-e4455f3433f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlr_final\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlr_final\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'최종 메타모델의 예측 정확도: {0:.4f}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\deep\\datab\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1342\u001b[0m         X, y = self._validate_data(X, y, accept_sparse='csr', dtype=_dtype,\n\u001b[0;32m   1343\u001b[0m                                    \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"C\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1344\u001b[1;33m                                    accept_large_sparse=solver != 'liblinear')\n\u001b[0m\u001b[0;32m   1345\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\deep\\datab\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\deep\\datab\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\deep\\datab\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    810\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    811\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 812\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    813\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    814\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\deep\\datab\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 256\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [196389, 785553]"
     ]
    }
   ],
   "source": [
    "lr_final.fit(predict, y_train)\n",
    "final=lr_final.predict(predict)\n",
    "\n",
    "print('최종 메타모델의 예측 정확도: {0:.4f}'.format(accuracy_score(y_test, final)))\n",
    "\n",
    "#이 시점에서 oversampling(smote방법)해서 맞춰도 되는건지...->걍 y_test 로 하면 됨~!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest\n",
      "\n",
      "최적 하이퍼 파라미터:\n",
      " {'max_depth': 30, 'min_samples_split': 500, 'n_estimators': 100}\n",
      "최고 예측 정확도: 0.8348\n"
     ]
    }
   ],
   "source": [
    "print('RandomForest\\n')\n",
    "print('최적 하이퍼 파라미터:\\n', grid_cv.best_params_)\n",
    "print('최고 예측 정확도: {0:.4f}'.format(grid_cv.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Ridge회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston 데이터 세트 크기: (981942, 7)\n",
      "5 folds 의 개별 Negative MSE scores:  [-0.052 -0.167 -0.131 -0.104 -0.206]\n",
      "5 folds 의 개별 RMSE scores:  [0.227 0.409 0.362 0.322 0.454]\n",
      "5 folds 의 평균 RMSE :0.355 \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.datasets import load_boston\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "health4_df=pd.read_csv('health4.csv')\n",
    "\n",
    "X=health4_df.iloc[:,:-1]\n",
    "y=health4_df.iloc[:,-1]\n",
    "\n",
    "\n",
    "print('Boston 데이터 세트 크기:',health4_df.shape)\n",
    "\n",
    "\n",
    "ridge=Ridge(alpha=10)\n",
    "neg_mse_scores=cross_val_score(ridge, X, y, scoring=\"neg_mean_squared_error\",cv=5)\n",
    "rmse_scores=np.sqrt(-1*neg_mse_scores)\n",
    "avg_rmse=np.mean(rmse_scores)\n",
    "print('5 folds 의 개별 Negative MSE scores: ', np.round(neg_mse_scores,3))\n",
    "print('5 folds 의 개별 RMSE scores: ', np.round(rmse_scores,3))\n",
    "print('5 folds 의 평균 RMSE :{0:.3f} '.format(avg_rmse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha 0일때 5 folds 의 평균 RMSE: 0.355\n",
      "alpha 0.1일때 5 folds 의 평균 RMSE: 0.355\n",
      "alpha 1일때 5 folds 의 평균 RMSE: 0.355\n",
      "alpha 10일때 5 folds 의 평균 RMSE: 0.355\n",
      "alpha 100일때 5 folds 의 평균 RMSE: 0.355\n",
      "alpha 150일때 5 folds 의 평균 RMSE: 0.355\n",
      "alpha 200일때 5 folds 의 평균 RMSE: 0.355\n"
     ]
    }
   ],
   "source": [
    "alphas=[0,0.1,1,10,100,150, 200]\n",
    "\n",
    "for alpha in alphas:\n",
    "    ridge=Ridge(alpha=alpha)\n",
    "    \n",
    "    neg_mse_scores=cross_val_score(ridge, X, y, scoring=\"neg_mean_squared_error\",cv=5)\n",
    "    avg_rmse=np.mean(np.sqrt(-1*neg_mse_scores))\n",
    "    print('alpha {0}일때 5 folds 의 평균 RMSE: {1:.3f}'.format(alpha, avg_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 5 is out of bounds for axis 0 with size 5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-98-1bf51df726a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mcoeff_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcoeff\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mcoeff\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcoeff\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0maxs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0maxs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_xlim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbarplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcoeff\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcoeff\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 5 is out of bounds for axis 0 with size 5"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x432 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs= plt.subplots(figsize=(18,6), nrows=1, ncols=5)\n",
    "\n",
    "coeff_df=pd.DataFrame()\n",
    "\n",
    "for pos, alpha in enumerate(alphas):\n",
    "    ridge=Ridge(alpha=alpha)\n",
    "    ridge.fit(X, y)\n",
    "    coeff=pd.Series(data=ridge.coef_, index=X.columns)\n",
    "    colname='alpha:'+str(alpha)\n",
    "    coeff_df[colname]=coeff\n",
    "    coeff=coeff.sort_values(ascending=False)\n",
    "    axs[pos].set_title(colname)\n",
    "    axs[pos].set_xlim(-3,6)\n",
    "    sns.barplot(x=coeff.values, y=coeff.index, ax=axs[pos])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha:0</th>\n",
       "      <th>alpha:0.1</th>\n",
       "      <th>alpha:1</th>\n",
       "      <th>alpha:10</th>\n",
       "      <th>alpha:100</th>\n",
       "      <th>alpha:150</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age_arrange</th>\n",
       "      <td>0.112998</td>\n",
       "      <td>0.112998</td>\n",
       "      <td>0.112998</td>\n",
       "      <td>0.112998</td>\n",
       "      <td>0.112993</td>\n",
       "      <td>0.112990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEX</th>\n",
       "      <td>0.024660</td>\n",
       "      <td>0.024660</td>\n",
       "      <td>0.024660</td>\n",
       "      <td>0.024659</td>\n",
       "      <td>0.024652</td>\n",
       "      <td>0.024647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMI</th>\n",
       "      <td>0.011413</td>\n",
       "      <td>0.011413</td>\n",
       "      <td>0.011413</td>\n",
       "      <td>0.011413</td>\n",
       "      <td>0.011412</td>\n",
       "      <td>0.011412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FBS</th>\n",
       "      <td>0.005671</td>\n",
       "      <td>0.005671</td>\n",
       "      <td>0.005671</td>\n",
       "      <td>0.005671</td>\n",
       "      <td>0.005671</td>\n",
       "      <td>0.005671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SBP</th>\n",
       "      <td>0.004618</td>\n",
       "      <td>0.004618</td>\n",
       "      <td>0.004618</td>\n",
       "      <td>0.004618</td>\n",
       "      <td>0.004618</td>\n",
       "      <td>0.004618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DBP</th>\n",
       "      <td>-0.000738</td>\n",
       "      <td>-0.000738</td>\n",
       "      <td>-0.000738</td>\n",
       "      <td>-0.000738</td>\n",
       "      <td>-0.000738</td>\n",
       "      <td>-0.000739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              alpha:0  alpha:0.1   alpha:1  alpha:10  alpha:100  alpha:150\n",
       "age_arrange  0.112998   0.112998  0.112998  0.112998   0.112993   0.112990\n",
       "SEX          0.024660   0.024660  0.024660  0.024659   0.024652   0.024647\n",
       "BMI          0.011413   0.011413  0.011413  0.011413   0.011412   0.011412\n",
       "FBS          0.005671   0.005671  0.005671  0.005671   0.005671   0.005671\n",
       "SBP          0.004618   0.004618  0.004618  0.004618   0.004618   0.004618\n",
       "DBP         -0.000738  -0.000738 -0.000738 -0.000738  -0.000738  -0.000739"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_alphas=[0,0.1,1,10,100]\n",
    "sort_column='alpha:'+str(ridge_alphas[0])\n",
    "coeff_df.sort_values(by=sort_column, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Lasso회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, ElasticNet\n",
    "\n",
    "def get_linear_reg_eval(model_name, params=None, X_data_n=None, y_target_n=None,verbose=True):\n",
    "    coeff_df=pd.DataFrame()\n",
    "    if verbose: print('####### ', model_name, \"#######\")\n",
    "    for param in params:\n",
    "        if model_name=='Ridge':model=Ridge(alpha=param)\n",
    "        elif model_name=='Lasso':model=Lasso(alpha=param)\n",
    "        elif model_name=='ElasticNet':model=ElasticNet(alpha=param, l1_ratio=0.7)\n",
    "        neg_mse_scores=cross_val_score(model, X_data_n, y_target_n, scoring=\"neg_mean_squared_error\", cv=5)\n",
    "        avg_rmse=np.mean(np.sqrt(-1*neg_mse_scores))\n",
    "        print('alpha {0}일때 5 폴드 세트의 평균 RMSE: {1:.3f}'.format(param, avg_rmse))\n",
    "        model.fit(X, y)\n",
    "        coeff=pd.Series(data=model.coef_, index=X.columns)\n",
    "        colname='alpha:'+str(param)\n",
    "        coeff_df[colname]=coeff\n",
    "    return coeff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######  Ridge #######\n",
      "alpha 0일때 5 폴드 세트의 평균 RMSE: 0.355\n",
      "alpha 0.1일때 5 폴드 세트의 평균 RMSE: 0.355\n",
      "alpha 1일때 5 폴드 세트의 평균 RMSE: 0.355\n",
      "alpha 10일때 5 폴드 세트의 평균 RMSE: 0.355\n",
      "alpha 100일때 5 폴드 세트의 평균 RMSE: 0.355\n"
     ]
    }
   ],
   "source": [
    "rigge_alphas=[0.07,0.1,0.5,1,3]\n",
    "coeff_lasso_df=get_linear_reg_eval('Ridge', params=ridge_alphas, X_data_n=X, y_target_n=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######  Lasso #######\n",
      "alpha 0.07일때 5 폴드 세트의 평균 RMSE: 0.361\n",
      "alpha 0.1일때 5 폴드 세트의 평균 RMSE: 0.369\n",
      "alpha 0.5일때 5 폴드 세트의 평균 RMSE: 0.400\n",
      "alpha 1일때 5 폴드 세트의 평균 RMSE: 0.406\n",
      "alpha 3일때 5 폴드 세트의 평균 RMSE: 0.438\n"
     ]
    }
   ],
   "source": [
    "lasso_alphas=[0.07,0.1,0.5,1,3]\n",
    "coeff_lasso_df=get_linear_reg_eval('Lasso', params=lasso_alphas, X_data_n=X, y_target_n=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha:0.07</th>\n",
       "      <th>alpha:0.1</th>\n",
       "      <th>alpha:0.5</th>\n",
       "      <th>alpha:1</th>\n",
       "      <th>alpha:3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age_arrange</th>\n",
       "      <td>0.077934</td>\n",
       "      <td>0.062174</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FBS</th>\n",
       "      <td>0.006104</td>\n",
       "      <td>0.006309</td>\n",
       "      <td>0.006445</td>\n",
       "      <td>0.005604</td>\n",
       "      <td>0.001561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SBP</th>\n",
       "      <td>0.005128</td>\n",
       "      <td>0.005563</td>\n",
       "      <td>0.005388</td>\n",
       "      <td>0.003245</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMI</th>\n",
       "      <td>0.003931</td>\n",
       "      <td>0.000976</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEX</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DBP</th>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             alpha:0.07  alpha:0.1  alpha:0.5   alpha:1   alpha:3\n",
       "age_arrange    0.077934   0.062174   0.000000  0.000000  0.000000\n",
       "FBS            0.006104   0.006309   0.006445  0.005604  0.001561\n",
       "SBP            0.005128   0.005563   0.005388  0.003245  0.000000\n",
       "BMI            0.003931   0.000976   0.000000  0.000000  0.000000\n",
       "SEX            0.000000   0.000000   0.000000  0.000000  0.000000\n",
       "DBP           -0.000000  -0.000000   0.000000  0.000000  0.000000"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort_column='alpha:'+str(lasso_alphas[0])\n",
    "coeff_lasso_df.sort_values(by=sort_column, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#엘라스틱넷회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######  ElasticNet #######\n",
      "alpha 0.07일때 5 폴드 세트의 평균 RMSE: 0.357\n",
      "alpha 0.1일때 5 폴드 세트의 평균 RMSE: 0.361\n",
      "alpha 0.5일때 5 폴드 세트의 평균 RMSE: 0.398\n",
      "alpha 1일때 5 폴드 세트의 평균 RMSE: 0.402\n",
      "alpha 3일때 5 폴드 세트의 평균 RMSE: 0.424\n"
     ]
    }
   ],
   "source": [
    "elastic_alphas=[0.07,0.1,0.5,1,3]\n",
    "coeff_elastic_df=get_linear_reg_eval('ElasticNet', params=elastic_alphas, X_data_n=X, y_target_n=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha:0.07</th>\n",
       "      <th>alpha:0.1</th>\n",
       "      <th>alpha:0.5</th>\n",
       "      <th>alpha:1</th>\n",
       "      <th>alpha:3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age_arrange</th>\n",
       "      <td>0.077934</td>\n",
       "      <td>0.062174</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FBS</th>\n",
       "      <td>0.006104</td>\n",
       "      <td>0.006309</td>\n",
       "      <td>0.006445</td>\n",
       "      <td>0.005604</td>\n",
       "      <td>0.001561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SBP</th>\n",
       "      <td>0.005128</td>\n",
       "      <td>0.005563</td>\n",
       "      <td>0.005388</td>\n",
       "      <td>0.003245</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMI</th>\n",
       "      <td>0.003931</td>\n",
       "      <td>0.000976</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEX</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DBP</th>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             alpha:0.07  alpha:0.1  alpha:0.5   alpha:1   alpha:3\n",
       "age_arrange    0.077934   0.062174   0.000000  0.000000  0.000000\n",
       "FBS            0.006104   0.006309   0.006445  0.005604  0.001561\n",
       "SBP            0.005128   0.005563   0.005388  0.003245  0.000000\n",
       "BMI            0.003931   0.000976   0.000000  0.000000  0.000000\n",
       "SEX            0.000000   0.000000   0.000000  0.000000  0.000000\n",
       "DBP           -0.000000  -0.000000   0.000000  0.000000  0.000000"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort_column='alpha:'+str(elastic_alphas[0])\n",
    "coeff_lasso_df.sort_values(by=sort_column, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#독립변수간 영향력 이미 최소화, 회귀계수가 규제를 할 만큼의 영향력을 가진게 없음-> 규제선형모델을 사용 할 필요가 없음\n",
    "#(회귀를 돌려도 되지만 굳이 규제 줄 필요X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
