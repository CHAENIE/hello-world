{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 영상의 이동변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "src=cv2.imread('C:/deep/opencv/image/tekapo.bmp')\n",
    "\n",
    "if src is None:\n",
    "    print('Image load failed')\n",
    "    sys.exit()\n",
    "\n",
    "aff=np.array([[1,0,200],[0,1,100]], dtype=np.float32)\n",
    "\n",
    "dst=cv2.warpAffine(src, aff, (0,0))\n",
    "\n",
    "cv2.imshow('src', src)\n",
    "cv2.imshow('dst',dst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전단변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "src=cv2.imread('C:/deep/opencv/image/tekapo.bmp')\n",
    "\n",
    "if src is None:\n",
    "    print('Image load failed')\n",
    "    sys.exit()\n",
    "    \n",
    "aff=np.array([[1,0.5,0],[0,1,0]], dtype=np.float32)\n",
    "h,w=src.shape[:2]\n",
    "dst=cv2.warpAffine(src,aff,(w+int(h*0.5),h))\n",
    "\n",
    "cv2.imshow('src', src)\n",
    "cv2.imshow('dst',dst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 영상 확대와 축소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "src=cv2.imread('C:/deep/opencv/image/rose.bmp')\n",
    "\n",
    "if src is None:\n",
    "    print('Image load failed')\n",
    "    sys.exit()\n",
    "    \n",
    "dst1=cv2.resize(src, (0,0), fx=4, fy=4, interpolation=cv2.INTER_NEAREST)\n",
    "dst2=cv2.resize(src,(1920,1280)) #default=cv2.INTER_LINEAR\n",
    "dst3=cv2.resize(src,(1920,1280), interpolation=cv2.INTER_CUBIC)\n",
    "dst4=cv2.resize(src,(1920,1280), interpolation=cv2.INTER_LANCZOS4)\n",
    "\n",
    "cv2.imshow('src', src)\n",
    "cv2.imshow('dst1',dst1[500:900,400:800])\n",
    "cv2.imshow('dst2',dst2[500:900,400:800])\n",
    "cv2.imshow('dst3',dst3[500:900,400:800])\n",
    "cv2.imshow('dst4',dst4[500:900,400:800])\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 회전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "\n",
    "src=cv2.imread('C:/deep/opencv/image/tekapo.bmp')\n",
    "\n",
    "if src is None:\n",
    "    print('Image load failed')\n",
    "    sys.exit()\n",
    "    \n",
    "rad=20*math.pi/180 #반시계 방향\n",
    "aff=np.array([[math.cos(rad), math.sin(rad),0],\n",
    "             [-math.sin(rad), math.cos(rad),0]], dtype=np.float32)\n",
    "\n",
    "dst=cv2.warpAffine(src, aff, (0,0))\n",
    "\n",
    "cv2.imshow('src', src)\n",
    "cv2.imshow('dst',dst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480\n",
      "640\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "src=cv2.imread('C:/deep/opencv/image/tekapo.bmp')\n",
    "print(src.shape[0])\n",
    "print(src.shape[1])\n",
    "\n",
    "if src is None:\n",
    "    print('Image load failed')\n",
    "    sys.exit()\n",
    "    \n",
    "cp=(src.shape[1]/2 , src.shape[0]/2)\n",
    "rot=cv2.getRotationMatrix2D(cp, 20, 1)\n",
    "\n",
    "dst=cv2.warpAffine(src, rot, (0, 0))\n",
    "\n",
    "cv2.imshow('src', src)\n",
    "cv2.imshow('dst',dst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 어파인 변환 / 투시 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "src=cv2.imread('C:/deep/opencv/image/card.bmp')\n",
    "\n",
    "if src is None:\n",
    "    print('image load failed')\n",
    "    sys.exit()\n",
    "    \n",
    "w,h=320,480\n",
    "srcQuad=np.array([[470,134],[604,165],[557,307],[406,264]], np.float32)\n",
    "dstQuad=np.array([[0,0],[w-1,0],[w-1,h-1],[0,h-1]], np.float32)\n",
    "\n",
    "pers=cv2.getPerspectiveTransform(srcQuad, dstQuad)\n",
    "dst=cv2.warpPerspective(src,pers,(w,h))\n",
    "\n",
    "cv2.imshow('src', src)\n",
    "cv2.imshow('dst',dst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "명함 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVENT_LBUTTONDOWN: 339, 364\n",
      "EVENT_LBUTTONDOWN: 861, 366\n",
      "EVENT_LBUTTONDOWN: 897, 664\n",
      "EVENT_LBUTTONDOWN: 282, 661\n"
     ]
    }
   ],
   "source": [
    "#객체 좌표 찾기\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "oldx=oldy=-1\n",
    "\n",
    "def on_mouse(event, x,y, flags, param):\n",
    "    global oldx, oldy\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        oldx, oldy=x,y\n",
    "        print('EVENT_LBUTTONDOWN: %d, %d' % (x,y))\n",
    "\n",
    "src=cv2.imread('C:/deep/opencv/image/namecard8.jpg')\n",
    "\n",
    "cv2.namedWindow('image')\n",
    "cv2.setMouseCallback('image', on_mouse, src)\n",
    "\n",
    "\n",
    "cv2.imshow('image', src)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "src=cv2.imread('C:/deep/opencv/image/namecard8.jpg')\n",
    "\n",
    "if src is None:\n",
    "    print('image load failed')\n",
    "    sys.exit()\n",
    "\n",
    "w,h=600,480\n",
    "srcQuad=np.array([[338, 366],[864, 366],[896, 667],[283, 661]], np.float32)\n",
    "dstQuad=np.array([[0,0],[w-1,0],[w-1,h-1],[0,h-1]], np.float32)\n",
    "\n",
    "pers=cv2.getPerspectiveTransform(srcQuad, dstQuad)\n",
    "dst=cv2.warpPerspective(src,pers,(w,h))\n",
    "\n",
    "cv2.imshow('src', src)\n",
    "cv2.imshow('dst',dst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "명함실습2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVENT_LBUTTONDOWN: 33, 417\n",
      "EVENT_LBUTTONDOWN: 592, 414\n",
      "EVENT_LBUTTONDOWN: 615, 724\n",
      "EVENT_LBUTTONDOWN: 11, 720\n"
     ]
    }
   ],
   "source": [
    "#객체 좌표 찾기\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "oldx= oldy=-1\n",
    "\n",
    "def on_mouse(event, x, y, flags, param):\n",
    "    global oldx, oldy\n",
    "    \n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        oldx, oldy = x,y\n",
    "        print('EVENT_LBUTTONDOWN: %d, %d' % (x,y))\n",
    "\n",
    "img=cv2.imread('C:/deep/opencv/image/namecard9.jpg')\n",
    "\n",
    "cv2.namedWindow('image')\n",
    "cv2.setMouseCallback('image', on_mouse, img)\n",
    "cv2.imshow('image',img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#이미지 잘라내기\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "src=cv2.imread('C:/deep/opencv/image/namecard9.jpg')\n",
    "\n",
    "if src is None:\n",
    "    print('image load failed')\n",
    "    sys.exit()\n",
    "    \n",
    "w,h=600,480\n",
    "srcQuad=np.array([[33, 417],[592, 414],[615, 724],[11, 720]],np.float32)\n",
    "dstQuad=np.array([[0,0],[w-1,0],[w-1,h-1],[0,h-1]],np.float32)\n",
    "\n",
    "pers=cv2.getPerspectiveTransform(srcQuad, dstQuad)\n",
    "dst=cv2.warpPerspective(src, pers, (w,h))\n",
    "\n",
    "cv2.imshow('src',src)\n",
    "cv2.imshow('dst',dst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 문서 스캐너"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 707\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def drawROI(img, corners):\n",
    "    cpy = img.copy()\n",
    "    \n",
    "    c1=(192, 192, 255)\n",
    "    c2=(128, 128, 255)\n",
    "    \n",
    "    for pt in corners:\n",
    "        cv2.circle(cpy, tuple(pt), 25, c1, -1, cv2.LINE_AA)\n",
    "        \n",
    "    cv2.line(cpy, tuple(corners[0]), tuple(corners[1]), c2,2,cv2.LINE_AA)\n",
    "    cv2.line(cpy, tuple(corners[1]), tuple(corners[2]), c2,2,cv2.LINE_AA)\n",
    "    cv2.line(cpy, tuple(corners[2]), tuple(corners[3]), c2,2,cv2.LINE_AA)\n",
    "    cv2.line(cpy, tuple(corners[3]), tuple(corners[0]), c2,2,cv2.LINE_AA)\n",
    "    \n",
    "    disp = cv2.addWeighted(img, 0.3, cpy, 0.7, 0)\n",
    "    \n",
    "    return disp\n",
    "\n",
    "def onMouse(event, x, y, flags, param):\n",
    "    global srcQuad, dragSrc, ptOld, src\n",
    "    \n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        for i in range(4):\n",
    "            if cv2.norm(srcQuad[i]-(x,y))<25:\n",
    "                dragSrc[i]=True\n",
    "                ptOld=(x,y)\n",
    "                break\n",
    "    if event == cv2.EVENT_LBUTTONUP:\n",
    "        for i in range(4):\n",
    "            dragSrc[i]=False\n",
    "    if event == cv2.EVENT_MOUSEMOVE:\n",
    "        for i in range(4):\n",
    "            if dragSrc[i]:\n",
    "                dx=x-ptOld[0]\n",
    "                dy=y-ptOld[1]\n",
    "                \n",
    "                srcQuad[i]+= (dx, dy)\n",
    "                \n",
    "                cpy=drawROI(src, srcQuad)\n",
    "                cv2.imshow('img',cpy)\n",
    "                ptOld=(x,y)\n",
    "                break\n",
    "                \n",
    "#입력 이미지 불러오기\n",
    "src=cv2.imread('C:/deep/opencv/image/scan11.jpg')\n",
    "\n",
    "if src is None:\n",
    "    print('Image open failed')\n",
    "    sys.exit()\n",
    "    \n",
    "#입력 영상 크기 및 출력 영상 크기\n",
    "h,w=src.shape[:2]\n",
    "dw=500\n",
    "dh=round(dw*297/210) #A4용지 크기:210x297mm\n",
    "print(dw,dh)\n",
    "\n",
    "#모서리 점들의 좌표, 드래그 상태 여부 (반시계방향)\n",
    "srcQuad=np.array([[20,20],[20,h-20],[w-20,h-20],[w-20,20]], np.float32)\n",
    "dstQuad=np.array([[0,0],[0,dh-1],[dw-1,dh-1],[dw-1,0]], np.float32)\n",
    "dragSrc=[False, False, False, False]\n",
    "\n",
    "disp=drawROI(src, srcQuad)\n",
    "cv2.imshow('img', disp)\n",
    "cv2.setMouseCallback('img',onMouse)\n",
    "\n",
    "while True:\n",
    "    key=cv2.waitKey()\n",
    "    if key==13:\n",
    "        break\n",
    "    elif key==27:\n",
    "        cv2.destroyWindow('img')\n",
    "        sys.exit()\n",
    "        \n",
    "#투시 변환\n",
    "pers=cv2.getPerspectiveTransform(srcQuad, dstQuad)\n",
    "dst=cv2.warpPerspective(src, pers, (dw,dh), flags=cv2.INTER_CUBIC)\n",
    "\n",
    "#결과 영상 출력\n",
    "cv2.namedWindow('dst',cv2.WINDOW_NORMAL)\n",
    "cv2.imshow('dst', dst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\f1\\2f\\a5\\574c57fb22cfcf24f315c8feda132fd0463a9b07ef78394d07\\pytesseract-0.3.6-py2.py3-none-any.whl\n",
      "Requirement already satisfied: Pillow in c:\\users\\user\\anaconda3\\envs\\cw\\lib\\site-packages (from pytesseract) (7.2.0)\n",
      "Installing collected packages: pytesseract\n",
      "Successfully installed pytesseract-0.3.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pytesseract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tesseract-ocr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "영문명함 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVENT_LBUTTONDOWN: 338, 368\n",
      "EVENT_LBUTTONDOWN: 864, 369\n",
      "EVENT_LBUTTONDOWN: 896, 663\n",
      "EVENT_LBUTTONDOWN: 287, 661\n"
     ]
    }
   ],
   "source": [
    "#객체 좌표 찾기\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "oldx=oldy=-1\n",
    "\n",
    "def on_mouse(event, x,y, flags, param):\n",
    "    global oldx, oldy\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        oldx, oldy=x,y\n",
    "        print('EVENT_LBUTTONDOWN: %d, %d' % (x,y))\n",
    "\n",
    "src=cv2.imread('C:/deep/opencv/image/namecard8.jpg')\n",
    "\n",
    "cv2.namedWindow('image')\n",
    "cv2.setMouseCallback('image', on_mouse, src)\n",
    "\n",
    "\n",
    "cv2.imshow('image', src)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\n",
      "KASOM\n",
      "Big Data Strategy Planning Offic\n",
      "\n",
      "Senior Researct\n",
      "\n",
      "Sung Won, Lee\n",
      "\n",
      " \n",
      "\n",
      ") aE\n",
      "\n",
      "Mobile,\n",
      "\n",
      "Iwi\n",
      "[Seoul Republic of Korea\n",
      "\n",
      "|\n",
      "\f",
      "\n"
     ]
    }
   ],
   "source": [
    "#원하는 이미지 잘라내기\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pytesseract\n",
    "\n",
    "src=cv2.imread('C:/deep/opencv/image/namecard8.jpg')\n",
    "\n",
    "if src is None:\n",
    "    print('image load failed')\n",
    "    sys.exit()\n",
    "\n",
    "w,h=600,480\n",
    "srcQuad=np.array([[338, 366],[864, 366],[896, 667],[283, 661]], np.float32)\n",
    "dstQuad=np.array([[0,0],[w-1,0],[w-1,h-1],[0,h-1]], np.float32)\n",
    "\n",
    "pers=cv2.getPerspectiveTransform(srcQuad, dstQuad)\n",
    "dst=cv2.warpPerspective(src,pers,(w,h))\n",
    "\n",
    "#tesseract-ocr\n",
    "print(pytesseract.image_to_string(dst, lang='Hangul+eng'))\n",
    "img_gray=cv2.cvtColor(dst, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cv2.imshow('src', src)\n",
    "cv2.imshow('dst',dst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "한영명함 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVENT_LBUTTONDOWN: 36, 419\n",
      "EVENT_LBUTTONDOWN: 590, 415\n",
      "EVENT_LBUTTONDOWN: 619, 723\n",
      "EVENT_LBUTTONDOWN: 7, 725\n"
     ]
    }
   ],
   "source": [
    "#객체 좌표 찾기\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "oldx=oldy=-1\n",
    "\n",
    "def on_mouse(event, x,y, flags, param):\n",
    "    global oldx, oldy\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        oldx, oldy=x,y\n",
    "        print('EVENT_LBUTTONDOWN: %d, %d' % (x,y))\n",
    "\n",
    "src=cv2.imread('C:/deep/opencv/image/namecard9.jpg')\n",
    "\n",
    "cv2.namedWindow('image')\n",
    "cv2.setMouseCallback('image', on_mouse, src)\n",
    "\n",
    "\n",
    "cv2.imshow('image', src)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KASOM\n",
      "\n",
      "8098279 이성원\n",
      "merge Oe\n",
      "\n",
      "( 사 ) 한 국 소 프 트 웨 어 기 술 인 협회\n",
      "\n",
      "IRD. >“ a,\n",
      "Isw1600@kasoms.orkr\n",
      "http,//wwwkasoms.orkr\n",
      "\n",
      " \n",
      "\f",
      "\n"
     ]
    }
   ],
   "source": [
    "#원하는 이미지 잘라내기\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pytesseract\n",
    "\n",
    "src=cv2.imread('C:/deep/opencv/image/namecard9.jpg')\n",
    "\n",
    "if src is None:\n",
    "    print('image load failed')\n",
    "    sys.exit()\n",
    "\n",
    "w,h=600,480\n",
    "srcQuad=np.array([[36, 419],[590, 415],[619, 723],[7, 725]], np.float32)\n",
    "dstQuad=np.array([[0,0],[w-1,0],[w-1,h-1],[0,h-1]], np.float32)\n",
    "\n",
    "pers=cv2.getPerspectiveTransform(srcQuad, dstQuad)\n",
    "dst=cv2.warpPerspective(src,pers,(w,h))\n",
    "\n",
    "#tesseract-ocr\n",
    "print(pytesseract.image_to_string(dst, lang='Hangul+eng'))\n",
    "img_gray=cv2.cvtColor(dst, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cv2.imshow('src', src)\n",
    "cv2.imshow('dst',dst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가격표 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVENT_LBUTTONDOWN: 366, 579\n",
      "EVENT_LBUTTONDOWN: 720, 569\n",
      "EVENT_LBUTTONDOWN: 721, 739\n",
      "EVENT_LBUTTONDOWN: 360, 754\n"
     ]
    }
   ],
   "source": [
    "#객체 좌표 찾기\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "oldx=oldy=-1\n",
    "\n",
    "def on_mouse(event, x,y, flags, param):\n",
    "    global oldx, oldy\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        oldx, oldy=x,y\n",
    "        print('EVENT_LBUTTONDOWN: %d, %d' % (x,y))\n",
    "\n",
    "src=cv2.imread('C:/deep/opencv/image/ocr_ex2.jpg')\n",
    "\n",
    "cv2.namedWindow('image')\n",
    "cv2.setMouseCallback('image', on_mouse, src)\n",
    "\n",
    "\n",
    "cv2.imshow('image', src)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12,900 ~\n",
      "케 어 존 아 크 네 클 래 리 파 잉\n",
      "pH 젤 클 렌 저 380\n",
      "\f",
      "\n"
     ]
    }
   ],
   "source": [
    "#원하는 이미지 잘라내기\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pytesseract\n",
    "\n",
    "src=cv2.imread('C:/deep/opencv/image/ocr_ex2.jpg')\n",
    "\n",
    "if src is None:\n",
    "    print('image load failed')\n",
    "    sys.exit()\n",
    "\n",
    "w,h=600,480\n",
    "srcQuad=np.array([[353, 494],[762, 486],[772, 738],[351, 747]], np.float32)\n",
    "dstQuad=np.array([[0,0],[w-1,0],[w-1,h-1],[0,h-1]], np.float32)\n",
    "\n",
    "pers=cv2.getPerspectiveTransform(srcQuad, dstQuad)\n",
    "dst=cv2.warpPerspective(src,pers,(w,h))\n",
    "\n",
    "#tesseract-ocr\n",
    "print(pytesseract.image_to_string(dst, lang='Hangul+eng'))\n",
    "img_gray=cv2.cvtColor(dst, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cv2.imshow('src', src)\n",
    "cv2.imshow('dst',dst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 영상 분할과 객체검출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "src=cv2.imread('C:/deep/opencv/image/nemo.jpg')\n",
    "\n",
    "if src is None:\n",
    "    print('image load failed')\n",
    "    sys.exit()\n",
    "    \n",
    "rc=cv2.selectROI(src)\n",
    "mask=np.zeros(src.shape[:2], np.uint8)\n",
    "\n",
    "cv2.grabCut(src, mask, rc, None, None, 5, cv2.GC_INIT_WITH_RECT)\n",
    "\n",
    "mask2=np.where((mask==0)|(mask==2),0,1).astype('uint8')\n",
    "dst=src*mask2[:,:,np.newaxis]\n",
    "\n",
    "cv2.imshow('dst',dst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 얼굴 검출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.1511\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "src=cv2.imread('C:/deep/opencv/image/lenna.bmp')\n",
    "\n",
    "if src is None:\n",
    "    print('image load failed')\n",
    "    sys.exit()\n",
    "    \n",
    "classifier=cv2.CascadeClassifier('C:/deep/opencv/model/haarcascade_frontalface_alt2.xml')\n",
    "\n",
    "if classifier.empty():\n",
    "    print('XML load failed')\n",
    "    sys.exit()\n",
    "    \n",
    "tm=cv2.TickMeter()\n",
    "tm.start()\n",
    "    \n",
    "faces=classifier.detectMultiScale(src, scaleFactor=1.2, minSize=(100,100))\n",
    "\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(src,(x,y,w,h), (255,0,255), 2)\n",
    "\n",
    "tm.stop()\n",
    "print(tm.getTimeMilli())\n",
    "\n",
    "cv2.imshow('src',src)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.9594\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "src=cv2.imread('C:/deep/opencv/image/kids2.png')\n",
    "\n",
    "if src is None:\n",
    "    print('image load failed')\n",
    "    sys.exit()\n",
    "    \n",
    "classifier=cv2.CascadeClassifier('C:/deep/opencv/model/haarcascade_frontalface_alt2.xml')\n",
    "\n",
    "if classifier.empty():\n",
    "    print('XML load failed')\n",
    "    sys.exit()\n",
    "    \n",
    "tm=cv2.TickMeter()\n",
    "tm.start()\n",
    "    \n",
    "faces=classifier.detectMultiScale(src, scaleFactor=1.2, minSize=(100,100))\n",
    "\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(src,(x,y,w,h), (255,0,255), 2)\n",
    "\n",
    "tm.stop()\n",
    "print(tm.getTimeMilli())\n",
    "\n",
    "cv2.imshow('src',src)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 눈검출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.9936\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "src=cv2.imread('C:/deep/opencv/image/lenna.bmp')\n",
    "\n",
    "if src is None:\n",
    "    print('image load failed')\n",
    "    sys.exit()\n",
    "    \n",
    "face_classifier=cv2.CascadeClassifier('C:/deep/opencv/model/haarcascade_frontalface_alt2.xml')\n",
    "eye_classifier=cv2.CascadeClassifier('C:/Users/user/anaconda3/envs/cw/Lib/site-packages/cv2/data/haarcascade_eye.xml')\n",
    "\n",
    "if classifier.empty():\n",
    "    print('XML load failed')\n",
    "    sys.exit()\n",
    "    \n",
    "tm=cv2.TickMeter()\n",
    "tm.start()\n",
    "    \n",
    "faces=classifier.detectMultiScale(src)\n",
    "\n",
    "for (x1,y1,w1,h1) in faces:\n",
    "    cv2.rectangle(src, (x1,y1), (x1+w1, y1+h1), (255,0,255), 2)\n",
    "    faceROI=src[y1:y1+h1//2, x1:x1+w1]\n",
    "    eyes=eye_classifier.detectMultiScale(faceROI)\n",
    "    \n",
    "    for (x2,y2,w2,h2) in eyes:\n",
    "        center=(x2+w2//2, y2+h2//2)\n",
    "        cv2.circle(faceROI, center, w2//2, (255,0,0),2,cv2.LINE_AA)\n",
    "\n",
    "tm.stop()\n",
    "print(tm.getTimeMilli())\n",
    "\n",
    "cv2.imshow('src',src)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.5945\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "src=cv2.imread('C:/deep/opencv/image/kids2.png')\n",
    "\n",
    "if src is None:\n",
    "    print('image load failed')\n",
    "    sys.exit()\n",
    "    \n",
    "face_classifier=cv2.CascadeClassifier('C:/deep/opencv/model/haarcascade_frontalface_alt2.xml')\n",
    "eye_classifier=cv2.CascadeClassifier('C:/Users/user/anaconda3/envs/cw/Lib/site-packages/cv2/data/haarcascade_lefteye_2splits.xml')\n",
    "\n",
    "if face_classifier.empty() or eye_classifier.empty():\n",
    "    print('XML load failed')\n",
    "    sys.exit()\n",
    "    \n",
    "tm=cv2.TickMeter()\n",
    "tm.start()\n",
    "    \n",
    "faces=classifier.detectMultiScale(src,scaleFactor=1.2)\n",
    "\n",
    "for (x1,y1,w1,h1) in faces:\n",
    "    cv2.rectangle(src, (x1,y1), (x1+w1, y1+h1), (255,0,255), 2)\n",
    "    faceROI=src[y1:y1+h1//2, x1:x1+w1]\n",
    "    eyes=eye_classifier.detectMultiScale(faceROI)\n",
    "    \n",
    "    for (x2,y2,w2,h2) in eyes:\n",
    "        center=(x2+w2//2, y2+h2//2)\n",
    "        cv2.circle(faceROI, center, w2//2, (255,0,0),2,cv2.LINE_AA)\n",
    "\n",
    "tm.stop()\n",
    "print(tm.getTimeMilli())\n",
    "\n",
    "cv2.imshow('src',src)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOG 보행자 검출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap=cv2.VideoCapture('C:/deep/opencv/image/vtest.avi')\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print('video open failed')\n",
    "    sys.exit()\n",
    "    \n",
    "hog=cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "\n",
    "while True:\n",
    "    ret, frame=cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    detected, _=hog.detectMultiScale(frame)\n",
    "    for (x,y,w,h) in detected:\n",
    "        c=(random.randint(0,255), random.randint(0,255), random.randint(0,255))\n",
    "        cv2.rectangle(frame,(x,y),(x+w, y+h), c, 3)\n",
    "        \n",
    "    cv2.imshow('frame',frame)\n",
    "    if cv2.waitKey(10)==27:\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
