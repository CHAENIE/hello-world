{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단일 컬럼 데이터 추출:\n",
      " 0    4\n",
      "1    4\n",
      "2    4\n",
      "Name: DIS, dtype: int64\n",
      "\n",
      "여러 컬럼들의 데이터 추출:\n",
      "    SBP  DIS\n",
      "0  116    4\n",
      "1  100    4\n",
      "2  100    4\n",
      "피처 데이터 shape: (1000000, 7)\n",
      "        SEX  age_arrange  BTH_G  SBP  DBP  FBS   BMI\n",
      "0         1            1      1  116   78   94  16.6\n",
      "1         1            1      1  100   60   79  22.3\n",
      "2         1            1      1  100   60   87  21.9\n",
      "3         1            1      1  111   70   72  20.2\n",
      "4         1            1      1  120   80   98  20.0\n",
      "...     ...          ...    ...  ...  ...  ...   ...\n",
      "999995    2            6     27  120   70   81  23.1\n",
      "999996    2            6     27  110   70  104  27.2\n",
      "999997    2            6     27  115   53  110  25.2\n",
      "999998    2            6     27  120   70   90  19.7\n",
      "999999    2            6     27  116   73   92  17.6\n",
      "\n",
      "[1000000 rows x 7 columns]\n",
      "0         4\n",
      "1         4\n",
      "2         4\n",
      "3         4\n",
      "4         4\n",
      "         ..\n",
      "999995    2\n",
      "999996    2\n",
      "999997    1\n",
      "999998    2\n",
      "999999    4\n",
      "Name: DIS, Length: 1000000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "health_df=pd.read_csv('health2.csv')\n",
    "print('단일 컬럼 데이터 추출:\\n',health_df[  'DIS' ].head(3))\n",
    "print('\\n여러 컬럼들의 데이터 추출:\\n', health_df[ ['SBP','DIS']].head(3))\n",
    "\n",
    "X_features=health_df.iloc[:,:-1]\n",
    "y_labels=health_df.iloc[:,-1]\n",
    "print('피처 데이터 shape: {0}'.format(X_features.shape))\n",
    "print(X_features)\n",
    "print(y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도:0.6861\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error,r2_score, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_clf=DecisionTreeClassifier()\n",
    "X_train, X_test, y_train, y_test=train_test_split(X_features, y_labels, test_size=0.2, random_state=10)\n",
    "\n",
    "dt_clf.fit(X_train, y_train)\n",
    "pred=dt_clf.predict(X_test)\n",
    "print('예측 정확도:{0:.4f}'.format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: n_estimaitors\n",
      "[1]\ttraining's multi_logloss: 0.746317\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\ttraining's multi_logloss: 0.706783\n",
      "[3]\ttraining's multi_logloss: 0.677958\n",
      "[4]\ttraining's multi_logloss: 0.655896\n",
      "[5]\ttraining's multi_logloss: 0.638555\n",
      "[6]\ttraining's multi_logloss: 0.624635\n",
      "[7]\ttraining's multi_logloss: 0.613387\n",
      "[8]\ttraining's multi_logloss: 0.604141\n",
      "[9]\ttraining's multi_logloss: 0.596578\n",
      "[10]\ttraining's multi_logloss: 0.590309\n",
      "[11]\ttraining's multi_logloss: 0.585073\n",
      "[12]\ttraining's multi_logloss: 0.58068\n",
      "[13]\ttraining's multi_logloss: 0.576982\n",
      "[14]\ttraining's multi_logloss: 0.573882\n",
      "[15]\ttraining's multi_logloss: 0.571265\n",
      "[16]\ttraining's multi_logloss: 0.569038\n",
      "[17]\ttraining's multi_logloss: 0.567135\n",
      "[18]\ttraining's multi_logloss: 0.565517\n",
      "[19]\ttraining's multi_logloss: 0.564098\n",
      "[20]\ttraining's multi_logloss: 0.562884\n",
      "[21]\ttraining's multi_logloss: 0.561846\n",
      "[22]\ttraining's multi_logloss: 0.560948\n",
      "[23]\ttraining's multi_logloss: 0.560138\n",
      "[24]\ttraining's multi_logloss: 0.559442\n",
      "[25]\ttraining's multi_logloss: 0.558842\n",
      "[26]\ttraining's multi_logloss: 0.558296\n",
      "[27]\ttraining's multi_logloss: 0.557812\n",
      "[28]\ttraining's multi_logloss: 0.557377\n",
      "[29]\ttraining's multi_logloss: 0.556994\n",
      "[30]\ttraining's multi_logloss: 0.556656\n",
      "[31]\ttraining's multi_logloss: 0.556344\n",
      "[32]\ttraining's multi_logloss: 0.556053\n",
      "[33]\ttraining's multi_logloss: 0.555793\n",
      "[34]\ttraining's multi_logloss: 0.555566\n",
      "[35]\ttraining's multi_logloss: 0.55535\n",
      "[36]\ttraining's multi_logloss: 0.555155\n",
      "[37]\ttraining's multi_logloss: 0.554967\n",
      "[38]\ttraining's multi_logloss: 0.554803\n",
      "[39]\ttraining's multi_logloss: 0.554628\n",
      "[40]\ttraining's multi_logloss: 0.554472\n",
      "[41]\ttraining's multi_logloss: 0.554319\n",
      "[42]\ttraining's multi_logloss: 0.554178\n",
      "[43]\ttraining's multi_logloss: 0.554036\n",
      "[44]\ttraining's multi_logloss: 0.553904\n",
      "[45]\ttraining's multi_logloss: 0.553786\n",
      "[46]\ttraining's multi_logloss: 0.55367\n",
      "[47]\ttraining's multi_logloss: 0.553559\n",
      "[48]\ttraining's multi_logloss: 0.553458\n",
      "[49]\ttraining's multi_logloss: 0.553362\n",
      "[50]\ttraining's multi_logloss: 0.553263\n",
      "[51]\ttraining's multi_logloss: 0.553182\n",
      "[52]\ttraining's multi_logloss: 0.553091\n",
      "[53]\ttraining's multi_logloss: 0.552985\n",
      "[54]\ttraining's multi_logloss: 0.552882\n",
      "[55]\ttraining's multi_logloss: 0.552776\n",
      "[56]\ttraining's multi_logloss: 0.552665\n",
      "[57]\ttraining's multi_logloss: 0.552586\n",
      "[58]\ttraining's multi_logloss: 0.552497\n",
      "[59]\ttraining's multi_logloss: 0.552433\n",
      "[60]\ttraining's multi_logloss: 0.552356\n",
      "[61]\ttraining's multi_logloss: 0.552272\n",
      "[62]\ttraining's multi_logloss: 0.552191\n",
      "[63]\ttraining's multi_logloss: 0.55212\n",
      "[64]\ttraining's multi_logloss: 0.552061\n",
      "[65]\ttraining's multi_logloss: 0.551966\n",
      "[66]\ttraining's multi_logloss: 0.551878\n",
      "[67]\ttraining's multi_logloss: 0.551801\n",
      "[68]\ttraining's multi_logloss: 0.551715\n",
      "[69]\ttraining's multi_logloss: 0.551645\n",
      "[70]\ttraining's multi_logloss: 0.551571\n",
      "[71]\ttraining's multi_logloss: 0.551486\n",
      "[72]\ttraining's multi_logloss: 0.551396\n",
      "[73]\ttraining's multi_logloss: 0.551334\n",
      "[74]\ttraining's multi_logloss: 0.551254\n",
      "[75]\ttraining's multi_logloss: 0.551187\n",
      "[76]\ttraining's multi_logloss: 0.551121\n",
      "[77]\ttraining's multi_logloss: 0.55159\n",
      "[78]\ttraining's multi_logloss: 0.551008\n",
      "[79]\ttraining's multi_logloss: 0.550945\n",
      "[80]\ttraining's multi_logloss: 0.550887\n",
      "[81]\ttraining's multi_logloss: 0.550813\n",
      "[82]\ttraining's multi_logloss: 0.550756\n",
      "[83]\ttraining's multi_logloss: 0.55069\n",
      "[84]\ttraining's multi_logloss: 0.550625\n",
      "[85]\ttraining's multi_logloss: 0.550554\n",
      "[86]\ttraining's multi_logloss: 0.55082\n",
      "[87]\ttraining's multi_logloss: 0.550471\n",
      "[88]\ttraining's multi_logloss: 0.550414\n",
      "[89]\ttraining's multi_logloss: 0.551029\n",
      "[90]\ttraining's multi_logloss: 0.550526\n",
      "[91]\ttraining's multi_logloss: 0.550277\n",
      "[92]\ttraining's multi_logloss: 0.550212\n",
      "[93]\ttraining's multi_logloss: 0.550161\n",
      "[94]\ttraining's multi_logloss: 0.55106\n",
      "[95]\ttraining's multi_logloss: 0.55081\n",
      "[96]\ttraining's multi_logloss: 0.551842\n",
      "[97]\ttraining's multi_logloss: 0.550115\n",
      "[98]\ttraining's multi_logloss: 0.552807\n",
      "[99]\ttraining's multi_logloss: 0.550012\n",
      "[100]\ttraining's multi_logloss: 0.551041\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[99]\ttraining's multi_logloss: 0.550012\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "import pandas as pd\n",
    "\n",
    "lgbm_wrapper=LGBMClassifier(n_estimaitors=400, random_state=10)\n",
    "\n",
    "evals=[(X_train, y_train)]\n",
    "lgbm_wrapper.fit(X_train, y_train, early_stopping_rounds=100, eval_metric='logloss',\n",
    "                eval_set=evals, verbose=True)\n",
    "preds=lgbm_wrapper.predict(X_test)\n",
    "pred_proba=lgbm_wrapper.predict_proba(X_test)[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,precision_score, recall_score, confusion_matrix, f1_score, roc_auc_score, precision_recall_curve, roc_curve\n",
    "\n",
    "def get_clf_eval(y_test,pred=None, pred_proba=None):\n",
    "    confusion=confusion_matrix(y_test,pred)\n",
    "    accuracy=accuracy_score(y_test,pred)\n",
    "    precision=precision_score(y_test,pred)\n",
    "    recall=recall_score(y_test,pred)\n",
    "    f1=f1_score(y_test, pred)\n",
    "    roc_auc=roc_auc_score(y_test,pred_proba)\n",
    "    \n",
    "    print('오차행렬')\n",
    "    print(confusion)\n",
    "    print('정확도:{0:.4f}, 정밀도:{1:.4f},재현율:{2:.4f}, F1:{3:.4f}, AUC:{4:.4f}'.format(accuracy,precision,recall,f1,roc_auc))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-8e6d81db4b7d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_clf_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpred_proba\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-22-7c2c7f0e4db9>\u001b[0m in \u001b[0;36mget_clf_eval\u001b[1;34m(y_test, pred, pred_proba)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mconfusion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0maccuracy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mprecision\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprecision_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mrecall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrecall_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mf1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\deep\\datab\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\deep\\datab\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mprecision_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1621\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'precision'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1622\u001b[0m                                                  \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1623\u001b[1;33m                                                  zero_division=zero_division)\n\u001b[0m\u001b[0;32m   1624\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1625\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\deep\\datab\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\deep\\datab\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1432\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1433\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[1;32m-> 1434\u001b[1;33m                                     pos_label)\n\u001b[0m\u001b[0;32m   1435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1436\u001b[0m     \u001b[1;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\deep\\datab\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1263\u001b[0m             raise ValueError(\"Target is %s but average='binary'. Please \"\n\u001b[0;32m   1264\u001b[0m                              \u001b[1;34m\"choose another average setting, one of %r.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1265\u001b[1;33m                              % (y_type, average_options))\n\u001b[0m\u001b[0;32m   1266\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mpos_label\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1267\u001b[0m         warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "\u001b[1;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
     ]
    }
   ],
   "source": [
    "get_clf_eval(y_test, preds,pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
