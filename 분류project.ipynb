{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "국가 건강검진데이터-'혈압,혈당데이터'\n",
    "[연도] 2013~2014년 일반검진 및 생애전환기 건강검진 데이터 1,000,000건\n",
    "[항목] 연령, 수축기혈압, 이완기혈압, 공복혈당, 성별, 고혈압/당뇨병 진료여부, 체질량지수\n",
    "[변수]\n",
    "- BTH_G : 연령(그룹)   -> age_arrange (1:20~30, 2:31~40, 3:41~50, 4:51~60, 5:61~70, 6:71이상)\n",
    "- SBP : 수축기혈압\n",
    "- DBP : 이완기혈압\n",
    "- FBS : 공복혈당\n",
    "- SEX : 성별(남성:1, 여성:2)\n",
    "- DIS : 고혈압/당뇨병 진료여부      -> (1:1+2+3 진료내역 있음, 0:4 진료내역 없음)\n",
    "        고혈압/당뇨병 진료내역 있음: 1\n",
    "        고혈압 진료내역 있음: 2\n",
    "        당뇨병 진료내역 있음: 3\n",
    "        고혈압/당뇨병 진료내역 없음: 4\n",
    "- BMI : 체질량지수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4    740662\n",
      "2    162826\n",
      "1     53398\n",
      "3     43114\n",
      "Name: DIS, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEX</th>\n",
       "      <th>age_arrange</th>\n",
       "      <th>BTH_G</th>\n",
       "      <th>SBP</th>\n",
       "      <th>DBP</th>\n",
       "      <th>FBS</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DIS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>116</td>\n",
       "      <td>78</td>\n",
       "      <td>94</td>\n",
       "      <td>16.6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>79</td>\n",
       "      <td>22.3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>87</td>\n",
       "      <td>21.9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SEX  age_arrange  BTH_G  SBP  DBP  FBS   BMI  DIS\n",
       "0    1            1      1  116   78   94  16.6    4\n",
       "1    1            1      1  100   60   79  22.3    4\n",
       "2    1            1      1  100   60   87  21.9    4"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,precision_score, recall_score, confusion_matrix, f1_score, roc_auc_score, precision_recall_curve, roc_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "health_df=pd.read_csv('health2.csv')\n",
    "print(health_df['DIS'].value_counts())\n",
    "health_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "health_df=pd.read_csv('health2.csv')\n",
    "print('단일 컬럼 데이터 추출:\\n',health_df[  'DIS' ].head(3))\n",
    "print('\\n여러 컬럼들의 데이터 추출:\\n', health_df[ ['SBP','DIS']].head(3))\n",
    "\n",
    "X_features=health_df.iloc[:,:-1]\n",
    "y_labels=health_df.iloc[:,-1]\n",
    "print('피처 데이터 shape: {0}'.format(X_features.shape))\n",
    "print(X_features)\n",
    "print(y_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 전처리: 엑셀\n",
    "1) SBP>=180 , DBP>=110 , DIS=4 삭제 (학습 시, 혈압 높아도 진료내역 없음(4)으로 학습할 수 있기 때문)\n",
    "2) FBS>=126, DIS=4 삭제\n",
    "3) BTH_G -> age_arrange 변경 (1:20~30, 2:31~40, 3:41~50, 4:51~60, 5:61~70, 6:71이상) \n",
    "4) DIS -> 이진분류 변경 (1:1+2+3 진료내역 있음, 0:4 진료내역 없음)\n",
    "건강검진 시 수축기혈압과 이완기혈압, 공복혈당을 보았을때 이전에 고혈압/당뇨병 진료내역이 있는지 확인(높음->진료내역있음)\n",
    "예측모델: 수축기혈압과 이완기혈압, 공복혈당 데이터를 받아서 그 값이 높을 경우 관리의 필요성 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    722604\n",
      "1    259338\n",
      "Name: DIS, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEX</th>\n",
       "      <th>age_arrange</th>\n",
       "      <th>SBP</th>\n",
       "      <th>DBP</th>\n",
       "      <th>FBS</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DIS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>116</td>\n",
       "      <td>78</td>\n",
       "      <td>94</td>\n",
       "      <td>16.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>79</td>\n",
       "      <td>22.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>87</td>\n",
       "      <td>21.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SEX  age_arrange  SBP  DBP  FBS   BMI  DIS\n",
       "0    1            1  116   78   94  16.6    0\n",
       "1    1            1  100   60   79  22.3    0\n",
       "2    1            1  100   60   87  21.9    0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "health4_df=pd.read_csv('health4.csv')\n",
    "print(health4_df['DIS'].value_counts())\n",
    "health4_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "health_df=pd.read_csv('health4.csv')\n",
    "print('단일 컬럼 데이터 추출:\\n',health_df[  'DIS' ].head(3))\n",
    "print('\\n여러 컬럼들의 데이터 추출:\\n', health_df[ ['SBP','DIS']].head(3))\n",
    "\n",
    "X=health4_df.iloc[:,:-1]\n",
    "y_labels=health_df.iloc[:,-1]\n",
    "print('피처 데이터 shape: {0}'.format(X_features.shape))\n",
    "print(X_features)\n",
    "print(y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 981942 entries, 0 to 981941\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   SEX          981942 non-null  int64  \n",
      " 1   age_arrange  981942 non-null  int64  \n",
      " 2   SBP          981942 non-null  int64  \n",
      " 3   DBP          981942 non-null  int64  \n",
      " 4   FBS          981942 non-null  int64  \n",
      " 5   BMI          981942 non-null  float64\n",
      " 6   DIS          981942 non-null  int64  \n",
      "dtypes: float64(1), int64(6)\n",
      "memory usage: 52.4 MB\n"
     ]
    }
   ],
   "source": [
    "health4_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도:0.6861\n"
     ]
    }
   ],
   "source": [
    "#health2 DT\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error,r2_score, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_clf=DecisionTreeClassifier()\n",
    "X_train, X_test, y_train, y_test=train_test_split(X_features, y_labels, test_size=0.2, random_state=10)\n",
    "\n",
    "dt_clf.fit(X_train, y_train)\n",
    "pred=dt_clf.predict(X_test)\n",
    "pred_prob=dt_clf.predict_proba(X_test)\n",
    "print('예측 정확도:{0:.4f}'.format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도:0.7714\n"
     ]
    }
   ],
   "source": [
    "#health4 dt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error,r2_score, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt4_clf=DecisionTreeClassifier()\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "dt4_clf.fit(X_train, y_train)\n",
    "pred4=dt4_clf.predict(X_test)\n",
    "print('예측 정확도:{0:.4f}'.format(accuracy_score(y_test, pred4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,precision_score, recall_score, confusion_matrix, f1_score, roc_auc_score, precision_recall_curve, roc_curve\n",
    "\n",
    "def get_clf_eval(y_test,pred=None, pred_proba=None):\n",
    "    confusion=confusion_matrix(y_test,pred)\n",
    "    accuracy=accuracy_score(y_test,pred)\n",
    "    precision=precision_score(y_test,pred)\n",
    "    recall=recall_score(y_test,pred)\n",
    "    f1=f1_score(y_test, pred)\n",
    "    roc_auc=roc_auc_score(y_test,pred_proba)\n",
    "    \n",
    "    print('오차행렬')\n",
    "    print(confusion)\n",
    "    print('정확도:{0:.4f}, 정밀도:{1:.4f},재현율:{2:.4f}, F1:{3:.4f}, AUC:{4:.4f}'.format(accuracy,precision,recall,f1,roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차행렬\n",
      "[[122159  22240]\n",
      " [ 22649  29341]]\n",
      "정확도:0.7714, 정밀도:0.5688,재현율:0.5644, F1:0.5666\n"
     ]
    }
   ],
   "source": [
    "#health4 dt\n",
    "from sklearn.metrics import accuracy_score,precision_score, recall_score, confusion_matrix, f1_score, roc_auc_score, precision_recall_curve, roc_curve\n",
    "\n",
    "def get_clf_eval_dt(y_test,pred=None, pred_proba=None):\n",
    "    confusion=confusion_matrix(y_test,pred)\n",
    "    accuracy=accuracy_score(y_test,pred)\n",
    "    precision=precision_score(y_test,pred)\n",
    "    recall=recall_score(y_test,pred)\n",
    "    f1=f1_score(y_test, pred)\n",
    "\n",
    "    \n",
    "    print('오차행렬')\n",
    "    print(confusion)\n",
    "    print('정확도:{0:.4f}, 정밀도:{1:.4f},재현율:{2:.4f}, F1:{3:.4f}'.format(accuracy,precision,recall,f1))\n",
    "\n",
    "get_clf_eval_dt(y_test, pred4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.538724\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[2]\ttraining's binary_logloss: 0.509487\n",
      "[3]\ttraining's binary_logloss: 0.486199\n",
      "[4]\ttraining's binary_logloss: 0.467097\n",
      "[5]\ttraining's binary_logloss: 0.451297\n",
      "[6]\ttraining's binary_logloss: 0.437881\n",
      "[7]\ttraining's binary_logloss: 0.426563\n",
      "[8]\ttraining's binary_logloss: 0.416808\n",
      "[9]\ttraining's binary_logloss: 0.408474\n",
      "[10]\ttraining's binary_logloss: 0.401255\n",
      "[11]\ttraining's binary_logloss: 0.394969\n",
      "[12]\ttraining's binary_logloss: 0.389464\n",
      "[13]\ttraining's binary_logloss: 0.384685\n",
      "[14]\ttraining's binary_logloss: 0.380488\n",
      "[15]\ttraining's binary_logloss: 0.376811\n",
      "[16]\ttraining's binary_logloss: 0.373558\n",
      "[17]\ttraining's binary_logloss: 0.370693\n",
      "[18]\ttraining's binary_logloss: 0.368225\n",
      "[19]\ttraining's binary_logloss: 0.366037\n",
      "[20]\ttraining's binary_logloss: 0.36411\n",
      "[21]\ttraining's binary_logloss: 0.362372\n",
      "[22]\ttraining's binary_logloss: 0.360808\n",
      "[23]\ttraining's binary_logloss: 0.359424\n",
      "[24]\ttraining's binary_logloss: 0.358201\n",
      "[25]\ttraining's binary_logloss: 0.357103\n",
      "[26]\ttraining's binary_logloss: 0.356115\n",
      "[27]\ttraining's binary_logloss: 0.355253\n",
      "[28]\ttraining's binary_logloss: 0.354463\n",
      "[29]\ttraining's binary_logloss: 0.353769\n",
      "[30]\ttraining's binary_logloss: 0.353139\n",
      "[31]\ttraining's binary_logloss: 0.352583\n",
      "[32]\ttraining's binary_logloss: 0.352081\n",
      "[33]\ttraining's binary_logloss: 0.351633\n",
      "[34]\ttraining's binary_logloss: 0.351234\n",
      "[35]\ttraining's binary_logloss: 0.350846\n",
      "[36]\ttraining's binary_logloss: 0.350492\n",
      "[37]\ttraining's binary_logloss: 0.3502\n",
      "[38]\ttraining's binary_logloss: 0.349934\n",
      "[39]\ttraining's binary_logloss: 0.349692\n",
      "[40]\ttraining's binary_logloss: 0.349479\n",
      "[41]\ttraining's binary_logloss: 0.349268\n",
      "[42]\ttraining's binary_logloss: 0.349096\n",
      "[43]\ttraining's binary_logloss: 0.348919\n",
      "[44]\ttraining's binary_logloss: 0.34877\n",
      "[45]\ttraining's binary_logloss: 0.348634\n",
      "[46]\ttraining's binary_logloss: 0.348491\n",
      "[47]\ttraining's binary_logloss: 0.34837\n",
      "[48]\ttraining's binary_logloss: 0.348263\n",
      "[49]\ttraining's binary_logloss: 0.348146\n",
      "[50]\ttraining's binary_logloss: 0.348057\n",
      "[51]\ttraining's binary_logloss: 0.34797\n",
      "[52]\ttraining's binary_logloss: 0.347893\n",
      "[53]\ttraining's binary_logloss: 0.34782\n",
      "[54]\ttraining's binary_logloss: 0.347757\n",
      "[55]\ttraining's binary_logloss: 0.347691\n",
      "[56]\ttraining's binary_logloss: 0.347624\n",
      "[57]\ttraining's binary_logloss: 0.34756\n",
      "[58]\ttraining's binary_logloss: 0.347511\n",
      "[59]\ttraining's binary_logloss: 0.347464\n",
      "[60]\ttraining's binary_logloss: 0.34742\n",
      "[61]\ttraining's binary_logloss: 0.347382\n",
      "[62]\ttraining's binary_logloss: 0.34733\n",
      "[63]\ttraining's binary_logloss: 0.34729\n",
      "[64]\ttraining's binary_logloss: 0.347253\n",
      "[65]\ttraining's binary_logloss: 0.347208\n",
      "[66]\ttraining's binary_logloss: 0.347175\n",
      "[67]\ttraining's binary_logloss: 0.34714\n",
      "[68]\ttraining's binary_logloss: 0.347113\n",
      "[69]\ttraining's binary_logloss: 0.347086\n",
      "[70]\ttraining's binary_logloss: 0.347038\n",
      "[71]\ttraining's binary_logloss: 0.347006\n",
      "[72]\ttraining's binary_logloss: 0.346972\n",
      "[73]\ttraining's binary_logloss: 0.34695\n",
      "[74]\ttraining's binary_logloss: 0.346925\n",
      "[75]\ttraining's binary_logloss: 0.346904\n",
      "[76]\ttraining's binary_logloss: 0.346876\n",
      "[77]\ttraining's binary_logloss: 0.346851\n",
      "[78]\ttraining's binary_logloss: 0.346815\n",
      "[79]\ttraining's binary_logloss: 0.346792\n",
      "[80]\ttraining's binary_logloss: 0.346768\n",
      "[81]\ttraining's binary_logloss: 0.346749\n",
      "[82]\ttraining's binary_logloss: 0.346728\n",
      "[83]\ttraining's binary_logloss: 0.346698\n",
      "[84]\ttraining's binary_logloss: 0.346677\n",
      "[85]\ttraining's binary_logloss: 0.346658\n",
      "[86]\ttraining's binary_logloss: 0.346637\n",
      "[87]\ttraining's binary_logloss: 0.34662\n",
      "[88]\ttraining's binary_logloss: 0.3466\n",
      "[89]\ttraining's binary_logloss: 0.34658\n",
      "[90]\ttraining's binary_logloss: 0.346556\n",
      "[91]\ttraining's binary_logloss: 0.346542\n",
      "[92]\ttraining's binary_logloss: 0.346511\n",
      "[93]\ttraining's binary_logloss: 0.346482\n",
      "[94]\ttraining's binary_logloss: 0.346469\n",
      "[95]\ttraining's binary_logloss: 0.346451\n",
      "[96]\ttraining's binary_logloss: 0.346426\n",
      "[97]\ttraining's binary_logloss: 0.346407\n",
      "[98]\ttraining's binary_logloss: 0.346386\n",
      "[99]\ttraining's binary_logloss: 0.346359\n",
      "[100]\ttraining's binary_logloss: 0.346341\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.346341\n"
     ]
    }
   ],
   "source": [
    "#health4 LGBM logloss 값이 낮아질수록 더 나은 예측\n",
    "from lightgbm import LGBMClassifier\n",
    "import pandas as pd\n",
    "\n",
    "lgbm_wrapper=LGBMClassifier(n_estimators=100, random_state=0)\n",
    "\n",
    "evals=[(X_train, y_train)]\n",
    "lgbm_wrapper.fit(X_train, y_train, early_stopping_rounds=40, eval_metric='logloss',\n",
    "                eval_set=evals, verbose=True)\n",
    "preds4=lgbm_wrapper.predict(X_test)\n",
    "pred_proba4=lgbm_wrapper.predict_proba(X_test)[:,-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.538724\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\ttraining's binary_logloss: 0.509487\n",
      "[3]\ttraining's binary_logloss: 0.486199\n",
      "[4]\ttraining's binary_logloss: 0.467097\n",
      "[5]\ttraining's binary_logloss: 0.451297\n",
      "[6]\ttraining's binary_logloss: 0.437881\n",
      "[7]\ttraining's binary_logloss: 0.426563\n",
      "[8]\ttraining's binary_logloss: 0.416808\n",
      "[9]\ttraining's binary_logloss: 0.408474\n",
      "[10]\ttraining's binary_logloss: 0.401255\n",
      "[11]\ttraining's binary_logloss: 0.394969\n",
      "[12]\ttraining's binary_logloss: 0.389464\n",
      "[13]\ttraining's binary_logloss: 0.384685\n",
      "[14]\ttraining's binary_logloss: 0.380488\n",
      "[15]\ttraining's binary_logloss: 0.376811\n",
      "[16]\ttraining's binary_logloss: 0.373558\n",
      "[17]\ttraining's binary_logloss: 0.370693\n",
      "[18]\ttraining's binary_logloss: 0.368225\n",
      "[19]\ttraining's binary_logloss: 0.366037\n",
      "[20]\ttraining's binary_logloss: 0.36411\n",
      "[21]\ttraining's binary_logloss: 0.362372\n",
      "[22]\ttraining's binary_logloss: 0.360808\n",
      "[23]\ttraining's binary_logloss: 0.359424\n",
      "[24]\ttraining's binary_logloss: 0.358201\n",
      "[25]\ttraining's binary_logloss: 0.357103\n",
      "[26]\ttraining's binary_logloss: 0.356115\n",
      "[27]\ttraining's binary_logloss: 0.355253\n",
      "[28]\ttraining's binary_logloss: 0.354463\n",
      "[29]\ttraining's binary_logloss: 0.353769\n",
      "[30]\ttraining's binary_logloss: 0.353139\n",
      "[31]\ttraining's binary_logloss: 0.352583\n",
      "[32]\ttraining's binary_logloss: 0.352081\n",
      "[33]\ttraining's binary_logloss: 0.351633\n",
      "[34]\ttraining's binary_logloss: 0.351234\n",
      "[35]\ttraining's binary_logloss: 0.350846\n",
      "[36]\ttraining's binary_logloss: 0.350492\n",
      "[37]\ttraining's binary_logloss: 0.3502\n",
      "[38]\ttraining's binary_logloss: 0.349934\n",
      "[39]\ttraining's binary_logloss: 0.349692\n",
      "[40]\ttraining's binary_logloss: 0.349479\n",
      "[41]\ttraining's binary_logloss: 0.349268\n",
      "[42]\ttraining's binary_logloss: 0.349096\n",
      "[43]\ttraining's binary_logloss: 0.348919\n",
      "[44]\ttraining's binary_logloss: 0.34877\n",
      "[45]\ttraining's binary_logloss: 0.348634\n",
      "[46]\ttraining's binary_logloss: 0.348491\n",
      "[47]\ttraining's binary_logloss: 0.34837\n",
      "[48]\ttraining's binary_logloss: 0.348263\n",
      "[49]\ttraining's binary_logloss: 0.348146\n",
      "[50]\ttraining's binary_logloss: 0.348057\n",
      "[51]\ttraining's binary_logloss: 0.34797\n",
      "[52]\ttraining's binary_logloss: 0.347893\n",
      "[53]\ttraining's binary_logloss: 0.34782\n",
      "[54]\ttraining's binary_logloss: 0.347757\n",
      "[55]\ttraining's binary_logloss: 0.347691\n",
      "[56]\ttraining's binary_logloss: 0.347624\n",
      "[57]\ttraining's binary_logloss: 0.34756\n",
      "[58]\ttraining's binary_logloss: 0.347511\n",
      "[59]\ttraining's binary_logloss: 0.347464\n",
      "[60]\ttraining's binary_logloss: 0.34742\n",
      "[61]\ttraining's binary_logloss: 0.347382\n",
      "[62]\ttraining's binary_logloss: 0.34733\n",
      "[63]\ttraining's binary_logloss: 0.34729\n",
      "[64]\ttraining's binary_logloss: 0.347253\n",
      "[65]\ttraining's binary_logloss: 0.347208\n",
      "[66]\ttraining's binary_logloss: 0.347175\n",
      "[67]\ttraining's binary_logloss: 0.34714\n",
      "[68]\ttraining's binary_logloss: 0.347113\n",
      "[69]\ttraining's binary_logloss: 0.347086\n",
      "[70]\ttraining's binary_logloss: 0.347038\n",
      "[71]\ttraining's binary_logloss: 0.347006\n",
      "[72]\ttraining's binary_logloss: 0.346972\n",
      "[73]\ttraining's binary_logloss: 0.34695\n",
      "[74]\ttraining's binary_logloss: 0.346925\n",
      "[75]\ttraining's binary_logloss: 0.346904\n",
      "[76]\ttraining's binary_logloss: 0.346876\n",
      "[77]\ttraining's binary_logloss: 0.346851\n",
      "[78]\ttraining's binary_logloss: 0.346815\n",
      "[79]\ttraining's binary_logloss: 0.346792\n",
      "[80]\ttraining's binary_logloss: 0.346768\n",
      "[81]\ttraining's binary_logloss: 0.346749\n",
      "[82]\ttraining's binary_logloss: 0.346728\n",
      "[83]\ttraining's binary_logloss: 0.346698\n",
      "[84]\ttraining's binary_logloss: 0.346677\n",
      "[85]\ttraining's binary_logloss: 0.346658\n",
      "[86]\ttraining's binary_logloss: 0.346637\n",
      "[87]\ttraining's binary_logloss: 0.34662\n",
      "[88]\ttraining's binary_logloss: 0.3466\n",
      "[89]\ttraining's binary_logloss: 0.34658\n",
      "[90]\ttraining's binary_logloss: 0.346556\n",
      "[91]\ttraining's binary_logloss: 0.346542\n",
      "[92]\ttraining's binary_logloss: 0.346511\n",
      "[93]\ttraining's binary_logloss: 0.346482\n",
      "[94]\ttraining's binary_logloss: 0.346469\n",
      "[95]\ttraining's binary_logloss: 0.346451\n",
      "[96]\ttraining's binary_logloss: 0.346426\n",
      "[97]\ttraining's binary_logloss: 0.346407\n",
      "[98]\ttraining's binary_logloss: 0.346386\n",
      "[99]\ttraining's binary_logloss: 0.346359\n",
      "[100]\ttraining's binary_logloss: 0.346341\n",
      "[101]\ttraining's binary_logloss: 0.346315\n",
      "[102]\ttraining's binary_logloss: 0.346297\n",
      "[103]\ttraining's binary_logloss: 0.346283\n",
      "[104]\ttraining's binary_logloss: 0.346263\n",
      "[105]\ttraining's binary_logloss: 0.346248\n",
      "[106]\ttraining's binary_logloss: 0.346219\n",
      "[107]\ttraining's binary_logloss: 0.346199\n",
      "[108]\ttraining's binary_logloss: 0.346186\n",
      "[109]\ttraining's binary_logloss: 0.346172\n",
      "[110]\ttraining's binary_logloss: 0.346154\n",
      "[111]\ttraining's binary_logloss: 0.346138\n",
      "[112]\ttraining's binary_logloss: 0.346113\n",
      "[113]\ttraining's binary_logloss: 0.346097\n",
      "[114]\ttraining's binary_logloss: 0.346079\n",
      "[115]\ttraining's binary_logloss: 0.346059\n",
      "[116]\ttraining's binary_logloss: 0.346045\n",
      "[117]\ttraining's binary_logloss: 0.346028\n",
      "[118]\ttraining's binary_logloss: 0.346013\n",
      "[119]\ttraining's binary_logloss: 0.345995\n",
      "[120]\ttraining's binary_logloss: 0.345985\n",
      "[121]\ttraining's binary_logloss: 0.345972\n",
      "[122]\ttraining's binary_logloss: 0.345947\n",
      "[123]\ttraining's binary_logloss: 0.345927\n",
      "[124]\ttraining's binary_logloss: 0.34591\n",
      "[125]\ttraining's binary_logloss: 0.345896\n",
      "[126]\ttraining's binary_logloss: 0.345877\n",
      "[127]\ttraining's binary_logloss: 0.34586\n",
      "[128]\ttraining's binary_logloss: 0.345843\n",
      "[129]\ttraining's binary_logloss: 0.345827\n",
      "[130]\ttraining's binary_logloss: 0.34581\n",
      "[131]\ttraining's binary_logloss: 0.345787\n",
      "[132]\ttraining's binary_logloss: 0.345763\n",
      "[133]\ttraining's binary_logloss: 0.345748\n",
      "[134]\ttraining's binary_logloss: 0.345732\n",
      "[135]\ttraining's binary_logloss: 0.345714\n",
      "[136]\ttraining's binary_logloss: 0.3457\n",
      "[137]\ttraining's binary_logloss: 0.345679\n",
      "[138]\ttraining's binary_logloss: 0.345661\n",
      "[139]\ttraining's binary_logloss: 0.345647\n",
      "[140]\ttraining's binary_logloss: 0.345627\n",
      "[141]\ttraining's binary_logloss: 0.345609\n",
      "[142]\ttraining's binary_logloss: 0.345594\n",
      "[143]\ttraining's binary_logloss: 0.345581\n",
      "[144]\ttraining's binary_logloss: 0.345566\n",
      "[145]\ttraining's binary_logloss: 0.345549\n",
      "[146]\ttraining's binary_logloss: 0.345534\n",
      "[147]\ttraining's binary_logloss: 0.345516\n",
      "[148]\ttraining's binary_logloss: 0.345504\n",
      "[149]\ttraining's binary_logloss: 0.345484\n",
      "[150]\ttraining's binary_logloss: 0.34546\n",
      "[151]\ttraining's binary_logloss: 0.345448\n",
      "[152]\ttraining's binary_logloss: 0.345434\n",
      "[153]\ttraining's binary_logloss: 0.345425\n",
      "[154]\ttraining's binary_logloss: 0.345405\n",
      "[155]\ttraining's binary_logloss: 0.345383\n",
      "[156]\ttraining's binary_logloss: 0.345365\n",
      "[157]\ttraining's binary_logloss: 0.345351\n",
      "[158]\ttraining's binary_logloss: 0.345334\n",
      "[159]\ttraining's binary_logloss: 0.34532\n",
      "[160]\ttraining's binary_logloss: 0.345298\n",
      "[161]\ttraining's binary_logloss: 0.345282\n",
      "[162]\ttraining's binary_logloss: 0.345271\n",
      "[163]\ttraining's binary_logloss: 0.345263\n",
      "[164]\ttraining's binary_logloss: 0.345248\n",
      "[165]\ttraining's binary_logloss: 0.345227\n",
      "[166]\ttraining's binary_logloss: 0.345207\n",
      "[167]\ttraining's binary_logloss: 0.345196\n",
      "[168]\ttraining's binary_logloss: 0.345182\n",
      "[169]\ttraining's binary_logloss: 0.34516\n",
      "[170]\ttraining's binary_logloss: 0.34514\n",
      "[171]\ttraining's binary_logloss: 0.345132\n",
      "[172]\ttraining's binary_logloss: 0.345123\n",
      "[173]\ttraining's binary_logloss: 0.345104\n",
      "[174]\ttraining's binary_logloss: 0.345096\n",
      "[175]\ttraining's binary_logloss: 0.345082\n",
      "[176]\ttraining's binary_logloss: 0.345067\n",
      "[177]\ttraining's binary_logloss: 0.34506\n",
      "[178]\ttraining's binary_logloss: 0.345049\n",
      "[179]\ttraining's binary_logloss: 0.345042\n",
      "[180]\ttraining's binary_logloss: 0.345023\n",
      "[181]\ttraining's binary_logloss: 0.345003\n",
      "[182]\ttraining's binary_logloss: 0.344987\n",
      "[183]\ttraining's binary_logloss: 0.34497\n",
      "[184]\ttraining's binary_logloss: 0.34496\n",
      "[185]\ttraining's binary_logloss: 0.344949\n",
      "[186]\ttraining's binary_logloss: 0.344931\n",
      "[187]\ttraining's binary_logloss: 0.344921\n",
      "[188]\ttraining's binary_logloss: 0.344905\n",
      "[189]\ttraining's binary_logloss: 0.344893\n",
      "[190]\ttraining's binary_logloss: 0.344885\n",
      "[191]\ttraining's binary_logloss: 0.344871\n",
      "[192]\ttraining's binary_logloss: 0.344865\n",
      "[193]\ttraining's binary_logloss: 0.344851\n",
      "[194]\ttraining's binary_logloss: 0.344829\n",
      "[195]\ttraining's binary_logloss: 0.344807\n",
      "[196]\ttraining's binary_logloss: 0.344786\n",
      "[197]\ttraining's binary_logloss: 0.344764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[198]\ttraining's binary_logloss: 0.344748\n",
      "[199]\ttraining's binary_logloss: 0.344731\n",
      "[200]\ttraining's binary_logloss: 0.344713\n",
      "[201]\ttraining's binary_logloss: 0.344695\n",
      "[202]\ttraining's binary_logloss: 0.344673\n",
      "[203]\ttraining's binary_logloss: 0.344656\n",
      "[204]\ttraining's binary_logloss: 0.344619\n",
      "[205]\ttraining's binary_logloss: 0.344599\n",
      "[206]\ttraining's binary_logloss: 0.344579\n",
      "[207]\ttraining's binary_logloss: 0.344562\n",
      "[208]\ttraining's binary_logloss: 0.344549\n",
      "[209]\ttraining's binary_logloss: 0.344536\n",
      "[210]\ttraining's binary_logloss: 0.344529\n",
      "[211]\ttraining's binary_logloss: 0.344518\n",
      "[212]\ttraining's binary_logloss: 0.344508\n",
      "[213]\ttraining's binary_logloss: 0.344492\n",
      "[214]\ttraining's binary_logloss: 0.344482\n",
      "[215]\ttraining's binary_logloss: 0.344461\n",
      "[216]\ttraining's binary_logloss: 0.344446\n",
      "[217]\ttraining's binary_logloss: 0.344423\n",
      "[218]\ttraining's binary_logloss: 0.344404\n",
      "[219]\ttraining's binary_logloss: 0.344393\n",
      "[220]\ttraining's binary_logloss: 0.344384\n",
      "[221]\ttraining's binary_logloss: 0.344377\n",
      "[222]\ttraining's binary_logloss: 0.344354\n",
      "[223]\ttraining's binary_logloss: 0.344336\n",
      "[224]\ttraining's binary_logloss: 0.344318\n",
      "[225]\ttraining's binary_logloss: 0.344298\n",
      "[226]\ttraining's binary_logloss: 0.344283\n",
      "[227]\ttraining's binary_logloss: 0.344272\n",
      "[228]\ttraining's binary_logloss: 0.344266\n",
      "[229]\ttraining's binary_logloss: 0.344247\n",
      "[230]\ttraining's binary_logloss: 0.344238\n",
      "[231]\ttraining's binary_logloss: 0.344222\n",
      "[232]\ttraining's binary_logloss: 0.344216\n",
      "[233]\ttraining's binary_logloss: 0.344194\n",
      "[234]\ttraining's binary_logloss: 0.344171\n",
      "[235]\ttraining's binary_logloss: 0.344155\n",
      "[236]\ttraining's binary_logloss: 0.344144\n",
      "[237]\ttraining's binary_logloss: 0.344122\n",
      "[238]\ttraining's binary_logloss: 0.344103\n",
      "[239]\ttraining's binary_logloss: 0.344092\n",
      "[240]\ttraining's binary_logloss: 0.344083\n",
      "[241]\ttraining's binary_logloss: 0.344064\n",
      "[242]\ttraining's binary_logloss: 0.344042\n",
      "[243]\ttraining's binary_logloss: 0.344023\n",
      "[244]\ttraining's binary_logloss: 0.344009\n",
      "[245]\ttraining's binary_logloss: 0.343992\n",
      "[246]\ttraining's binary_logloss: 0.343984\n",
      "[247]\ttraining's binary_logloss: 0.343969\n",
      "[248]\ttraining's binary_logloss: 0.343949\n",
      "[249]\ttraining's binary_logloss: 0.343943\n",
      "[250]\ttraining's binary_logloss: 0.343935\n",
      "[251]\ttraining's binary_logloss: 0.343919\n",
      "[252]\ttraining's binary_logloss: 0.343905\n",
      "[253]\ttraining's binary_logloss: 0.343889\n",
      "[254]\ttraining's binary_logloss: 0.343872\n",
      "[255]\ttraining's binary_logloss: 0.343863\n",
      "[256]\ttraining's binary_logloss: 0.34385\n",
      "[257]\ttraining's binary_logloss: 0.343836\n",
      "[258]\ttraining's binary_logloss: 0.343823\n",
      "[259]\ttraining's binary_logloss: 0.343808\n",
      "[260]\ttraining's binary_logloss: 0.343793\n",
      "[261]\ttraining's binary_logloss: 0.343775\n",
      "[262]\ttraining's binary_logloss: 0.343758\n",
      "[263]\ttraining's binary_logloss: 0.343747\n",
      "[264]\ttraining's binary_logloss: 0.343737\n",
      "[265]\ttraining's binary_logloss: 0.343729\n",
      "[266]\ttraining's binary_logloss: 0.343716\n",
      "[267]\ttraining's binary_logloss: 0.343703\n",
      "[268]\ttraining's binary_logloss: 0.343698\n",
      "[269]\ttraining's binary_logloss: 0.343667\n",
      "[270]\ttraining's binary_logloss: 0.34366\n",
      "[271]\ttraining's binary_logloss: 0.343652\n",
      "[272]\ttraining's binary_logloss: 0.343645\n",
      "[273]\ttraining's binary_logloss: 0.343631\n",
      "[274]\ttraining's binary_logloss: 0.343624\n",
      "[275]\ttraining's binary_logloss: 0.343608\n",
      "[276]\ttraining's binary_logloss: 0.343588\n",
      "[277]\ttraining's binary_logloss: 0.343569\n",
      "[278]\ttraining's binary_logloss: 0.343561\n",
      "[279]\ttraining's binary_logloss: 0.34355\n",
      "[280]\ttraining's binary_logloss: 0.343544\n",
      "[281]\ttraining's binary_logloss: 0.343525\n",
      "[282]\ttraining's binary_logloss: 0.34351\n",
      "[283]\ttraining's binary_logloss: 0.343493\n",
      "[284]\ttraining's binary_logloss: 0.343478\n",
      "[285]\ttraining's binary_logloss: 0.343466\n",
      "[286]\ttraining's binary_logloss: 0.343448\n",
      "[287]\ttraining's binary_logloss: 0.343431\n",
      "[288]\ttraining's binary_logloss: 0.343409\n",
      "[289]\ttraining's binary_logloss: 0.343393\n",
      "[290]\ttraining's binary_logloss: 0.343376\n",
      "[291]\ttraining's binary_logloss: 0.343368\n",
      "[292]\ttraining's binary_logloss: 0.343356\n",
      "[293]\ttraining's binary_logloss: 0.343347\n",
      "[294]\ttraining's binary_logloss: 0.343341\n",
      "[295]\ttraining's binary_logloss: 0.343334\n",
      "[296]\ttraining's binary_logloss: 0.343319\n",
      "[297]\ttraining's binary_logloss: 0.343301\n",
      "[298]\ttraining's binary_logloss: 0.343292\n",
      "[299]\ttraining's binary_logloss: 0.343278\n",
      "[300]\ttraining's binary_logloss: 0.343263\n",
      "[301]\ttraining's binary_logloss: 0.343252\n",
      "[302]\ttraining's binary_logloss: 0.343241\n",
      "[303]\ttraining's binary_logloss: 0.343235\n",
      "[304]\ttraining's binary_logloss: 0.343224\n",
      "[305]\ttraining's binary_logloss: 0.343214\n",
      "[306]\ttraining's binary_logloss: 0.343195\n",
      "[307]\ttraining's binary_logloss: 0.343176\n",
      "[308]\ttraining's binary_logloss: 0.343159\n",
      "[309]\ttraining's binary_logloss: 0.343145\n",
      "[310]\ttraining's binary_logloss: 0.343129\n",
      "[311]\ttraining's binary_logloss: 0.343124\n",
      "[312]\ttraining's binary_logloss: 0.343115\n",
      "[313]\ttraining's binary_logloss: 0.3431\n",
      "[314]\ttraining's binary_logloss: 0.343089\n",
      "[315]\ttraining's binary_logloss: 0.343073\n",
      "[316]\ttraining's binary_logloss: 0.343057\n",
      "[317]\ttraining's binary_logloss: 0.343041\n",
      "[318]\ttraining's binary_logloss: 0.343026\n",
      "[319]\ttraining's binary_logloss: 0.342996\n",
      "[320]\ttraining's binary_logloss: 0.342987\n",
      "[321]\ttraining's binary_logloss: 0.342971\n",
      "[322]\ttraining's binary_logloss: 0.342958\n",
      "[323]\ttraining's binary_logloss: 0.342942\n",
      "[324]\ttraining's binary_logloss: 0.342933\n",
      "[325]\ttraining's binary_logloss: 0.342918\n",
      "[326]\ttraining's binary_logloss: 0.342907\n",
      "[327]\ttraining's binary_logloss: 0.342896\n",
      "[328]\ttraining's binary_logloss: 0.342882\n",
      "[329]\ttraining's binary_logloss: 0.342868\n",
      "[330]\ttraining's binary_logloss: 0.342851\n",
      "[331]\ttraining's binary_logloss: 0.342839\n",
      "[332]\ttraining's binary_logloss: 0.34282\n",
      "[333]\ttraining's binary_logloss: 0.342803\n",
      "[334]\ttraining's binary_logloss: 0.342785\n",
      "[335]\ttraining's binary_logloss: 0.342771\n",
      "[336]\ttraining's binary_logloss: 0.342757\n",
      "[337]\ttraining's binary_logloss: 0.342752\n",
      "[338]\ttraining's binary_logloss: 0.342742\n",
      "[339]\ttraining's binary_logloss: 0.342726\n",
      "[340]\ttraining's binary_logloss: 0.342709\n",
      "[341]\ttraining's binary_logloss: 0.342695\n",
      "[342]\ttraining's binary_logloss: 0.34268\n",
      "[343]\ttraining's binary_logloss: 0.342664\n",
      "[344]\ttraining's binary_logloss: 0.342646\n",
      "[345]\ttraining's binary_logloss: 0.342633\n",
      "[346]\ttraining's binary_logloss: 0.342625\n",
      "[347]\ttraining's binary_logloss: 0.342605\n",
      "[348]\ttraining's binary_logloss: 0.342592\n",
      "[349]\ttraining's binary_logloss: 0.342578\n",
      "[350]\ttraining's binary_logloss: 0.342564\n",
      "[351]\ttraining's binary_logloss: 0.342555\n",
      "[352]\ttraining's binary_logloss: 0.342541\n",
      "[353]\ttraining's binary_logloss: 0.342535\n",
      "[354]\ttraining's binary_logloss: 0.342528\n",
      "[355]\ttraining's binary_logloss: 0.34252\n",
      "[356]\ttraining's binary_logloss: 0.342506\n",
      "[357]\ttraining's binary_logloss: 0.342494\n",
      "[358]\ttraining's binary_logloss: 0.342482\n",
      "[359]\ttraining's binary_logloss: 0.342479\n",
      "[360]\ttraining's binary_logloss: 0.342468\n",
      "[361]\ttraining's binary_logloss: 0.342462\n",
      "[362]\ttraining's binary_logloss: 0.342459\n",
      "[363]\ttraining's binary_logloss: 0.342452\n",
      "[364]\ttraining's binary_logloss: 0.342439\n",
      "[365]\ttraining's binary_logloss: 0.342434\n",
      "[366]\ttraining's binary_logloss: 0.34242\n",
      "[367]\ttraining's binary_logloss: 0.342411\n",
      "[368]\ttraining's binary_logloss: 0.342397\n",
      "[369]\ttraining's binary_logloss: 0.342392\n",
      "[370]\ttraining's binary_logloss: 0.342377\n",
      "[371]\ttraining's binary_logloss: 0.342364\n",
      "[372]\ttraining's binary_logloss: 0.342348\n",
      "[373]\ttraining's binary_logloss: 0.342342\n",
      "[374]\ttraining's binary_logloss: 0.34233\n",
      "[375]\ttraining's binary_logloss: 0.342324\n",
      "[376]\ttraining's binary_logloss: 0.342317\n",
      "[377]\ttraining's binary_logloss: 0.342309\n",
      "[378]\ttraining's binary_logloss: 0.3423\n",
      "[379]\ttraining's binary_logloss: 0.342294\n",
      "[380]\ttraining's binary_logloss: 0.342291\n",
      "[381]\ttraining's binary_logloss: 0.342283\n",
      "[382]\ttraining's binary_logloss: 0.342269\n",
      "[383]\ttraining's binary_logloss: 0.342253\n",
      "[384]\ttraining's binary_logloss: 0.342238\n",
      "[385]\ttraining's binary_logloss: 0.342218\n",
      "[386]\ttraining's binary_logloss: 0.3422\n",
      "[387]\ttraining's binary_logloss: 0.342184\n",
      "[388]\ttraining's binary_logloss: 0.342174\n",
      "[389]\ttraining's binary_logloss: 0.342158\n",
      "[390]\ttraining's binary_logloss: 0.342148\n",
      "[391]\ttraining's binary_logloss: 0.342134\n",
      "[392]\ttraining's binary_logloss: 0.342121\n",
      "[393]\ttraining's binary_logloss: 0.342106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[394]\ttraining's binary_logloss: 0.34209\n",
      "[395]\ttraining's binary_logloss: 0.342077\n",
      "[396]\ttraining's binary_logloss: 0.342064\n",
      "[397]\ttraining's binary_logloss: 0.342056\n",
      "[398]\ttraining's binary_logloss: 0.34204\n",
      "[399]\ttraining's binary_logloss: 0.342026\n",
      "[400]\ttraining's binary_logloss: 0.34201\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[400]\ttraining's binary_logloss: 0.34201\n"
     ]
    }
   ],
   "source": [
    "#health4 LGBM logloss 값이 낮아질수록 더 나은 예측\n",
    "from lightgbm import LGBMClassifier\n",
    "import pandas as pd\n",
    "\n",
    "lgbm_wrapper=LGBMClassifier(n_estimators=400, random_state=0)\n",
    "\n",
    "evals=[(X_train, y_train)]\n",
    "lgbm_wrapper.fit(X_train, y_train, early_stopping_rounds=100, eval_metric='logloss',\n",
    "                eval_set=evals, verbose=True)\n",
    "preds4=lgbm_wrapper.predict(X_test)\n",
    "pred_proba4=lgbm_wrapper.predict_proba(X_test)[:,-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차행렬\n",
      "[[133881  10518]\n",
      " [ 21992  29998]]\n",
      "정확도:0.8345, 정밀도:0.7404,재현율:0.5770, F1:0.6486, AUC:0.8887\n"
     ]
    }
   ],
   "source": [
    "#health4 LGBM\n",
    "get_clf_eval(y_test, preds4, pred_proba4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차행렬\n",
      "[[133237  11284]\n",
      " [ 22645  29223]]\n",
      "정확도:0.8272, 정밀도:0.7214,재현율:0.5634, F1:0.6327, AUC:0.8792\n"
     ]
    }
   ],
   "source": [
    "#health4 LogisticRegression\n",
    "X=health4_df.iloc[:,:-1]\n",
    "y=health4_df.iloc[:,-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)\n",
    "\n",
    "lr_clf=LogisticRegression()\n",
    "lr_clf.fit(X_train, y_train)\n",
    "pred_lr=lr_clf.predict(X_test)\n",
    "pred_proba_lr=lr_clf.predict_proba(X_test)[:,-1]\n",
    "\n",
    "get_clf_eval(y_test, pred_lr, pred_proba_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#health2 DT GridSearchCV 최적의 하이퍼 파라미터 찾기\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "\n",
    "health_df=pd.read_csv('health2.csv')\n",
    "X_features=health_df.iloc[:,:-1]\n",
    "y_labels=health_df.iloc[:,-1]\n",
    "\n",
    "dt_clf=DecisionTreeClassifier()\n",
    "X_train, X_test, y_train, y_test=train_test_split(X_features, y_labels, test_size=0.2, random_state=10)\n",
    "\n",
    "params={'max_depth':[6,8,10,12], 'min_samples_split':[800, 1000, 1500, 2000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'max_depth': 6, 'min_samples_split': 800}</td>\n",
       "      <td>0.772786</td>\n",
       "      <td>13</td>\n",
       "      <td>0.772981</td>\n",
       "      <td>0.773050</td>\n",
       "      <td>0.773925</td>\n",
       "      <td>0.772212</td>\n",
       "      <td>0.771763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'max_depth': 6, 'min_samples_split': 1000}</td>\n",
       "      <td>0.772786</td>\n",
       "      <td>13</td>\n",
       "      <td>0.772981</td>\n",
       "      <td>0.773050</td>\n",
       "      <td>0.773925</td>\n",
       "      <td>0.772212</td>\n",
       "      <td>0.771763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'max_depth': 6, 'min_samples_split': 1500}</td>\n",
       "      <td>0.772729</td>\n",
       "      <td>16</td>\n",
       "      <td>0.772906</td>\n",
       "      <td>0.773025</td>\n",
       "      <td>0.773925</td>\n",
       "      <td>0.772025</td>\n",
       "      <td>0.771763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'max_depth': 6, 'min_samples_split': 2000}</td>\n",
       "      <td>0.772729</td>\n",
       "      <td>15</td>\n",
       "      <td>0.772938</td>\n",
       "      <td>0.772956</td>\n",
       "      <td>0.773813</td>\n",
       "      <td>0.772025</td>\n",
       "      <td>0.771913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'max_depth': 8, 'min_samples_split': 800}</td>\n",
       "      <td>0.774839</td>\n",
       "      <td>10</td>\n",
       "      <td>0.774994</td>\n",
       "      <td>0.774606</td>\n",
       "      <td>0.775806</td>\n",
       "      <td>0.773919</td>\n",
       "      <td>0.774869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'max_depth': 8, 'min_samples_split': 1000}</td>\n",
       "      <td>0.774894</td>\n",
       "      <td>9</td>\n",
       "      <td>0.775038</td>\n",
       "      <td>0.774631</td>\n",
       "      <td>0.775900</td>\n",
       "      <td>0.773962</td>\n",
       "      <td>0.774937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'max_depth': 8, 'min_samples_split': 1500}</td>\n",
       "      <td>0.774581</td>\n",
       "      <td>11</td>\n",
       "      <td>0.774575</td>\n",
       "      <td>0.774244</td>\n",
       "      <td>0.775675</td>\n",
       "      <td>0.773475</td>\n",
       "      <td>0.774937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'max_depth': 8, 'min_samples_split': 2000}</td>\n",
       "      <td>0.774539</td>\n",
       "      <td>12</td>\n",
       "      <td>0.774675</td>\n",
       "      <td>0.774081</td>\n",
       "      <td>0.775575</td>\n",
       "      <td>0.773406</td>\n",
       "      <td>0.774956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 800}</td>\n",
       "      <td>0.775465</td>\n",
       "      <td>3</td>\n",
       "      <td>0.775937</td>\n",
       "      <td>0.775062</td>\n",
       "      <td>0.776344</td>\n",
       "      <td>0.774625</td>\n",
       "      <td>0.775356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 1000}</td>\n",
       "      <td>0.775702</td>\n",
       "      <td>2</td>\n",
       "      <td>0.776106</td>\n",
       "      <td>0.775425</td>\n",
       "      <td>0.776537</td>\n",
       "      <td>0.774775</td>\n",
       "      <td>0.775669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 1500}</td>\n",
       "      <td>0.775151</td>\n",
       "      <td>7</td>\n",
       "      <td>0.775412</td>\n",
       "      <td>0.774663</td>\n",
       "      <td>0.775981</td>\n",
       "      <td>0.774100</td>\n",
       "      <td>0.775600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 2000}</td>\n",
       "      <td>0.775070</td>\n",
       "      <td>8</td>\n",
       "      <td>0.775556</td>\n",
       "      <td>0.774563</td>\n",
       "      <td>0.775925</td>\n",
       "      <td>0.773713</td>\n",
       "      <td>0.775594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'max_depth': 12, 'min_samples_split': 800}</td>\n",
       "      <td>0.775463</td>\n",
       "      <td>4</td>\n",
       "      <td>0.775569</td>\n",
       "      <td>0.775081</td>\n",
       "      <td>0.776144</td>\n",
       "      <td>0.774988</td>\n",
       "      <td>0.775531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'max_depth': 12, 'min_samples_split': 1000}</td>\n",
       "      <td>0.775845</td>\n",
       "      <td>1</td>\n",
       "      <td>0.775806</td>\n",
       "      <td>0.775613</td>\n",
       "      <td>0.776513</td>\n",
       "      <td>0.775369</td>\n",
       "      <td>0.775925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'max_depth': 12, 'min_samples_split': 1500}</td>\n",
       "      <td>0.775442</td>\n",
       "      <td>5</td>\n",
       "      <td>0.775431</td>\n",
       "      <td>0.774806</td>\n",
       "      <td>0.776069</td>\n",
       "      <td>0.774906</td>\n",
       "      <td>0.776000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'max_depth': 12, 'min_samples_split': 2000}</td>\n",
       "      <td>0.775366</td>\n",
       "      <td>6</td>\n",
       "      <td>0.775756</td>\n",
       "      <td>0.774544</td>\n",
       "      <td>0.776319</td>\n",
       "      <td>0.774338</td>\n",
       "      <td>0.775875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          params  mean_test_score  \\\n",
       "0     {'max_depth': 6, 'min_samples_split': 800}         0.772786   \n",
       "1    {'max_depth': 6, 'min_samples_split': 1000}         0.772786   \n",
       "2    {'max_depth': 6, 'min_samples_split': 1500}         0.772729   \n",
       "3    {'max_depth': 6, 'min_samples_split': 2000}         0.772729   \n",
       "4     {'max_depth': 8, 'min_samples_split': 800}         0.774839   \n",
       "5    {'max_depth': 8, 'min_samples_split': 1000}         0.774894   \n",
       "6    {'max_depth': 8, 'min_samples_split': 1500}         0.774581   \n",
       "7    {'max_depth': 8, 'min_samples_split': 2000}         0.774539   \n",
       "8    {'max_depth': 10, 'min_samples_split': 800}         0.775465   \n",
       "9   {'max_depth': 10, 'min_samples_split': 1000}         0.775702   \n",
       "10  {'max_depth': 10, 'min_samples_split': 1500}         0.775151   \n",
       "11  {'max_depth': 10, 'min_samples_split': 2000}         0.775070   \n",
       "12   {'max_depth': 12, 'min_samples_split': 800}         0.775463   \n",
       "13  {'max_depth': 12, 'min_samples_split': 1000}         0.775845   \n",
       "14  {'max_depth': 12, 'min_samples_split': 1500}         0.775442   \n",
       "15  {'max_depth': 12, 'min_samples_split': 2000}         0.775366   \n",
       "\n",
       "    rank_test_score  split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0                13           0.772981           0.773050           0.773925   \n",
       "1                13           0.772981           0.773050           0.773925   \n",
       "2                16           0.772906           0.773025           0.773925   \n",
       "3                15           0.772938           0.772956           0.773813   \n",
       "4                10           0.774994           0.774606           0.775806   \n",
       "5                 9           0.775038           0.774631           0.775900   \n",
       "6                11           0.774575           0.774244           0.775675   \n",
       "7                12           0.774675           0.774081           0.775575   \n",
       "8                 3           0.775937           0.775062           0.776344   \n",
       "9                 2           0.776106           0.775425           0.776537   \n",
       "10                7           0.775412           0.774663           0.775981   \n",
       "11                8           0.775556           0.774563           0.775925   \n",
       "12                4           0.775569           0.775081           0.776144   \n",
       "13                1           0.775806           0.775613           0.776513   \n",
       "14                5           0.775431           0.774806           0.776069   \n",
       "15                6           0.775756           0.774544           0.776319   \n",
       "\n",
       "    split3_test_score  split4_test_score  \n",
       "0            0.772212           0.771763  \n",
       "1            0.772212           0.771763  \n",
       "2            0.772025           0.771763  \n",
       "3            0.772025           0.771913  \n",
       "4            0.773919           0.774869  \n",
       "5            0.773962           0.774937  \n",
       "6            0.773475           0.774937  \n",
       "7            0.773406           0.774956  \n",
       "8            0.774625           0.775356  \n",
       "9            0.774775           0.775669  \n",
       "10           0.774100           0.775600  \n",
       "11           0.773713           0.775594  \n",
       "12           0.774988           0.775531  \n",
       "13           0.775369           0.775925  \n",
       "14           0.774906           0.776000  \n",
       "15           0.774338           0.775875  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#health2\n",
    "grid_dtree=GridSearchCV(dt_clf, param_grid=params, cv=5, refit=True)\n",
    "\n",
    "grid_dtree.fit(X_train, y_train)\n",
    "\n",
    "scores_df=pd.DataFrame(grid_dtree.cv_results_)\n",
    "scores_df[['params','mean_test_score','rank_test_score','split0_test_score','split1_test_score','split2_test_score',\n",
    "           'split3_test_score','split4_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV 최적 파라미터: {'max_depth': 12, 'min_samples_split': 1000}\n",
      "GridSearchCV 최고 정확도:0.7758\n"
     ]
    }
   ],
   "source": [
    "print('GridSearchCV 최적 파라미터:', grid_dtree.best_params_)\n",
    "print('GridSearchCV 최고 정확도:{0:.4f}'.format(grid_dtree.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#health4 DT GridSearchCV 최적의 하이퍼 파라미터 찾기\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "\n",
    "X=health4_df.iloc[:,:-1]\n",
    "y=health4_df.iloc[:,-1]\n",
    "\n",
    "dt4_clf=DecisionTreeClassifier()\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "params={'max_depth':[10,30,50,100], 'min_samples_split':[1500, 2000, 2500, 3000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 1500}</td>\n",
       "      <td>0.833352</td>\n",
       "      <td>14</td>\n",
       "      <td>0.833718</td>\n",
       "      <td>0.833291</td>\n",
       "      <td>0.833046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 2000}</td>\n",
       "      <td>0.833377</td>\n",
       "      <td>13</td>\n",
       "      <td>0.833688</td>\n",
       "      <td>0.833199</td>\n",
       "      <td>0.833245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 2500}</td>\n",
       "      <td>0.833311</td>\n",
       "      <td>15</td>\n",
       "      <td>0.833631</td>\n",
       "      <td>0.833084</td>\n",
       "      <td>0.833218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 3000}</td>\n",
       "      <td>0.833152</td>\n",
       "      <td>16</td>\n",
       "      <td>0.833642</td>\n",
       "      <td>0.833088</td>\n",
       "      <td>0.832725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 1500}</td>\n",
       "      <td>0.833519</td>\n",
       "      <td>7</td>\n",
       "      <td>0.834009</td>\n",
       "      <td>0.833543</td>\n",
       "      <td>0.833004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 2000}</td>\n",
       "      <td>0.833563</td>\n",
       "      <td>1</td>\n",
       "      <td>0.834089</td>\n",
       "      <td>0.833398</td>\n",
       "      <td>0.833203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 2500}</td>\n",
       "      <td>0.833550</td>\n",
       "      <td>4</td>\n",
       "      <td>0.834039</td>\n",
       "      <td>0.833497</td>\n",
       "      <td>0.833115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 3000}</td>\n",
       "      <td>0.833428</td>\n",
       "      <td>10</td>\n",
       "      <td>0.834112</td>\n",
       "      <td>0.833512</td>\n",
       "      <td>0.832661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'max_depth': 50, 'min_samples_split': 1500}</td>\n",
       "      <td>0.833519</td>\n",
       "      <td>7</td>\n",
       "      <td>0.834009</td>\n",
       "      <td>0.833543</td>\n",
       "      <td>0.833004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'max_depth': 50, 'min_samples_split': 2000}</td>\n",
       "      <td>0.833563</td>\n",
       "      <td>1</td>\n",
       "      <td>0.834089</td>\n",
       "      <td>0.833398</td>\n",
       "      <td>0.833203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'max_depth': 50, 'min_samples_split': 2500}</td>\n",
       "      <td>0.833550</td>\n",
       "      <td>4</td>\n",
       "      <td>0.834039</td>\n",
       "      <td>0.833497</td>\n",
       "      <td>0.833115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'max_depth': 50, 'min_samples_split': 3000}</td>\n",
       "      <td>0.833428</td>\n",
       "      <td>10</td>\n",
       "      <td>0.834112</td>\n",
       "      <td>0.833512</td>\n",
       "      <td>0.832661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'max_depth': 100, 'min_samples_split': 1500}</td>\n",
       "      <td>0.833519</td>\n",
       "      <td>7</td>\n",
       "      <td>0.834009</td>\n",
       "      <td>0.833543</td>\n",
       "      <td>0.833004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'max_depth': 100, 'min_samples_split': 2000}</td>\n",
       "      <td>0.833563</td>\n",
       "      <td>1</td>\n",
       "      <td>0.834089</td>\n",
       "      <td>0.833398</td>\n",
       "      <td>0.833203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'max_depth': 100, 'min_samples_split': 2500}</td>\n",
       "      <td>0.833550</td>\n",
       "      <td>4</td>\n",
       "      <td>0.834039</td>\n",
       "      <td>0.833497</td>\n",
       "      <td>0.833115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'max_depth': 100, 'min_samples_split': 3000}</td>\n",
       "      <td>0.833428</td>\n",
       "      <td>10</td>\n",
       "      <td>0.834112</td>\n",
       "      <td>0.833512</td>\n",
       "      <td>0.832661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           params  mean_test_score  \\\n",
       "0    {'max_depth': 10, 'min_samples_split': 1500}         0.833352   \n",
       "1    {'max_depth': 10, 'min_samples_split': 2000}         0.833377   \n",
       "2    {'max_depth': 10, 'min_samples_split': 2500}         0.833311   \n",
       "3    {'max_depth': 10, 'min_samples_split': 3000}         0.833152   \n",
       "4    {'max_depth': 30, 'min_samples_split': 1500}         0.833519   \n",
       "5    {'max_depth': 30, 'min_samples_split': 2000}         0.833563   \n",
       "6    {'max_depth': 30, 'min_samples_split': 2500}         0.833550   \n",
       "7    {'max_depth': 30, 'min_samples_split': 3000}         0.833428   \n",
       "8    {'max_depth': 50, 'min_samples_split': 1500}         0.833519   \n",
       "9    {'max_depth': 50, 'min_samples_split': 2000}         0.833563   \n",
       "10   {'max_depth': 50, 'min_samples_split': 2500}         0.833550   \n",
       "11   {'max_depth': 50, 'min_samples_split': 3000}         0.833428   \n",
       "12  {'max_depth': 100, 'min_samples_split': 1500}         0.833519   \n",
       "13  {'max_depth': 100, 'min_samples_split': 2000}         0.833563   \n",
       "14  {'max_depth': 100, 'min_samples_split': 2500}         0.833550   \n",
       "15  {'max_depth': 100, 'min_samples_split': 3000}         0.833428   \n",
       "\n",
       "    rank_test_score  split0_test_score  split1_test_score  split2_test_score  \n",
       "0                14           0.833718           0.833291           0.833046  \n",
       "1                13           0.833688           0.833199           0.833245  \n",
       "2                15           0.833631           0.833084           0.833218  \n",
       "3                16           0.833642           0.833088           0.832725  \n",
       "4                 7           0.834009           0.833543           0.833004  \n",
       "5                 1           0.834089           0.833398           0.833203  \n",
       "6                 4           0.834039           0.833497           0.833115  \n",
       "7                10           0.834112           0.833512           0.832661  \n",
       "8                 7           0.834009           0.833543           0.833004  \n",
       "9                 1           0.834089           0.833398           0.833203  \n",
       "10                4           0.834039           0.833497           0.833115  \n",
       "11               10           0.834112           0.833512           0.832661  \n",
       "12                7           0.834009           0.833543           0.833004  \n",
       "13                1           0.834089           0.833398           0.833203  \n",
       "14                4           0.834039           0.833497           0.833115  \n",
       "15               10           0.834112           0.833512           0.832661  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_dtree4=GridSearchCV(dt4_clf, param_grid=params, cv=3, refit=True)\n",
    "\n",
    "grid_dtree4.fit(X_train, y_train)\n",
    "\n",
    "scores4_df=pd.DataFrame(grid_dtree4.cv_results_)\n",
    "scores4_df[['params','mean_test_score','rank_test_score','split0_test_score','split1_test_score','split2_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV 최적 파라미터: {'max_depth': 30, 'min_samples_split': 2000}\n",
      "GridSearchCV 최고 정확도:0.8336\n"
     ]
    }
   ],
   "source": [
    "print('GridSearchCV 최적 파라미터:', grid_dtree4.best_params_)\n",
    "print('GridSearchCV 최고 정확도:{0:.4f}'.format(grid_dtree4.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 1500}</td>\n",
       "      <td>0.833088</td>\n",
       "      <td>15</td>\n",
       "      <td>0.834385</td>\n",
       "      <td>0.833691</td>\n",
       "      <td>0.831342</td>\n",
       "      <td>0.833111</td>\n",
       "      <td>0.832913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 2000}</td>\n",
       "      <td>0.833093</td>\n",
       "      <td>14</td>\n",
       "      <td>0.834588</td>\n",
       "      <td>0.833583</td>\n",
       "      <td>0.831336</td>\n",
       "      <td>0.833085</td>\n",
       "      <td>0.832875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 2500}</td>\n",
       "      <td>0.833126</td>\n",
       "      <td>10</td>\n",
       "      <td>0.834518</td>\n",
       "      <td>0.833697</td>\n",
       "      <td>0.831406</td>\n",
       "      <td>0.833181</td>\n",
       "      <td>0.832831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 3000}</td>\n",
       "      <td>0.833004</td>\n",
       "      <td>16</td>\n",
       "      <td>0.834289</td>\n",
       "      <td>0.833895</td>\n",
       "      <td>0.831399</td>\n",
       "      <td>0.832926</td>\n",
       "      <td>0.832512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 1500}</td>\n",
       "      <td>0.833349</td>\n",
       "      <td>7</td>\n",
       "      <td>0.834843</td>\n",
       "      <td>0.833175</td>\n",
       "      <td>0.832010</td>\n",
       "      <td>0.833811</td>\n",
       "      <td>0.832907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 2000}</td>\n",
       "      <td>0.833403</td>\n",
       "      <td>4</td>\n",
       "      <td>0.834805</td>\n",
       "      <td>0.833131</td>\n",
       "      <td>0.832354</td>\n",
       "      <td>0.833626</td>\n",
       "      <td>0.833098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 2500}</td>\n",
       "      <td>0.833410</td>\n",
       "      <td>1</td>\n",
       "      <td>0.834665</td>\n",
       "      <td>0.833360</td>\n",
       "      <td>0.832501</td>\n",
       "      <td>0.833607</td>\n",
       "      <td>0.832920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 3000}</td>\n",
       "      <td>0.833123</td>\n",
       "      <td>11</td>\n",
       "      <td>0.834429</td>\n",
       "      <td>0.833544</td>\n",
       "      <td>0.831667</td>\n",
       "      <td>0.833422</td>\n",
       "      <td>0.832550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'max_depth': 50, 'min_samples_split': 1500}</td>\n",
       "      <td>0.833349</td>\n",
       "      <td>7</td>\n",
       "      <td>0.834843</td>\n",
       "      <td>0.833175</td>\n",
       "      <td>0.832010</td>\n",
       "      <td>0.833811</td>\n",
       "      <td>0.832907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'max_depth': 50, 'min_samples_split': 2000}</td>\n",
       "      <td>0.833403</td>\n",
       "      <td>4</td>\n",
       "      <td>0.834805</td>\n",
       "      <td>0.833131</td>\n",
       "      <td>0.832354</td>\n",
       "      <td>0.833626</td>\n",
       "      <td>0.833098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'max_depth': 50, 'min_samples_split': 2500}</td>\n",
       "      <td>0.833410</td>\n",
       "      <td>1</td>\n",
       "      <td>0.834665</td>\n",
       "      <td>0.833360</td>\n",
       "      <td>0.832501</td>\n",
       "      <td>0.833607</td>\n",
       "      <td>0.832920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'max_depth': 50, 'min_samples_split': 3000}</td>\n",
       "      <td>0.833123</td>\n",
       "      <td>11</td>\n",
       "      <td>0.834429</td>\n",
       "      <td>0.833544</td>\n",
       "      <td>0.831667</td>\n",
       "      <td>0.833422</td>\n",
       "      <td>0.832550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'max_depth': 100, 'min_samples_split': 1500}</td>\n",
       "      <td>0.833349</td>\n",
       "      <td>7</td>\n",
       "      <td>0.834843</td>\n",
       "      <td>0.833175</td>\n",
       "      <td>0.832010</td>\n",
       "      <td>0.833811</td>\n",
       "      <td>0.832907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'max_depth': 100, 'min_samples_split': 2000}</td>\n",
       "      <td>0.833403</td>\n",
       "      <td>4</td>\n",
       "      <td>0.834805</td>\n",
       "      <td>0.833131</td>\n",
       "      <td>0.832354</td>\n",
       "      <td>0.833626</td>\n",
       "      <td>0.833098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'max_depth': 100, 'min_samples_split': 2500}</td>\n",
       "      <td>0.833410</td>\n",
       "      <td>1</td>\n",
       "      <td>0.834665</td>\n",
       "      <td>0.833360</td>\n",
       "      <td>0.832501</td>\n",
       "      <td>0.833607</td>\n",
       "      <td>0.832920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'max_depth': 100, 'min_samples_split': 3000}</td>\n",
       "      <td>0.833123</td>\n",
       "      <td>11</td>\n",
       "      <td>0.834429</td>\n",
       "      <td>0.833544</td>\n",
       "      <td>0.831667</td>\n",
       "      <td>0.833422</td>\n",
       "      <td>0.832550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           params  mean_test_score  \\\n",
       "0    {'max_depth': 10, 'min_samples_split': 1500}         0.833088   \n",
       "1    {'max_depth': 10, 'min_samples_split': 2000}         0.833093   \n",
       "2    {'max_depth': 10, 'min_samples_split': 2500}         0.833126   \n",
       "3    {'max_depth': 10, 'min_samples_split': 3000}         0.833004   \n",
       "4    {'max_depth': 30, 'min_samples_split': 1500}         0.833349   \n",
       "5    {'max_depth': 30, 'min_samples_split': 2000}         0.833403   \n",
       "6    {'max_depth': 30, 'min_samples_split': 2500}         0.833410   \n",
       "7    {'max_depth': 30, 'min_samples_split': 3000}         0.833123   \n",
       "8    {'max_depth': 50, 'min_samples_split': 1500}         0.833349   \n",
       "9    {'max_depth': 50, 'min_samples_split': 2000}         0.833403   \n",
       "10   {'max_depth': 50, 'min_samples_split': 2500}         0.833410   \n",
       "11   {'max_depth': 50, 'min_samples_split': 3000}         0.833123   \n",
       "12  {'max_depth': 100, 'min_samples_split': 1500}         0.833349   \n",
       "13  {'max_depth': 100, 'min_samples_split': 2000}         0.833403   \n",
       "14  {'max_depth': 100, 'min_samples_split': 2500}         0.833410   \n",
       "15  {'max_depth': 100, 'min_samples_split': 3000}         0.833123   \n",
       "\n",
       "    rank_test_score  split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0                15           0.834385           0.833691           0.831342   \n",
       "1                14           0.834588           0.833583           0.831336   \n",
       "2                10           0.834518           0.833697           0.831406   \n",
       "3                16           0.834289           0.833895           0.831399   \n",
       "4                 7           0.834843           0.833175           0.832010   \n",
       "5                 4           0.834805           0.833131           0.832354   \n",
       "6                 1           0.834665           0.833360           0.832501   \n",
       "7                11           0.834429           0.833544           0.831667   \n",
       "8                 7           0.834843           0.833175           0.832010   \n",
       "9                 4           0.834805           0.833131           0.832354   \n",
       "10                1           0.834665           0.833360           0.832501   \n",
       "11               11           0.834429           0.833544           0.831667   \n",
       "12                7           0.834843           0.833175           0.832010   \n",
       "13                4           0.834805           0.833131           0.832354   \n",
       "14                1           0.834665           0.833360           0.832501   \n",
       "15               11           0.834429           0.833544           0.831667   \n",
       "\n",
       "    split3_test_score  split4_test_score  \n",
       "0            0.833111           0.832913  \n",
       "1            0.833085           0.832875  \n",
       "2            0.833181           0.832831  \n",
       "3            0.832926           0.832512  \n",
       "4            0.833811           0.832907  \n",
       "5            0.833626           0.833098  \n",
       "6            0.833607           0.832920  \n",
       "7            0.833422           0.832550  \n",
       "8            0.833811           0.832907  \n",
       "9            0.833626           0.833098  \n",
       "10           0.833607           0.832920  \n",
       "11           0.833422           0.832550  \n",
       "12           0.833811           0.832907  \n",
       "13           0.833626           0.833098  \n",
       "14           0.833607           0.832920  \n",
       "15           0.833422           0.832550  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_dtree4=GridSearchCV(dt4_clf, param_grid=params, cv=5, refit=True)\n",
    "\n",
    "grid_dtree4.fit(X_train, y_train)\n",
    "\n",
    "scores4_df=pd.DataFrame(grid_dtree4.cv_results_)\n",
    "scores4_df[['params','mean_test_score','rank_test_score','split0_test_score','split1_test_score','split2_test_score',\n",
    "            'split3_test_score','split4_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV 최적 파라미터: {'max_depth': 30, 'min_samples_split': 2500}\n",
      "GridSearchCV 최고 정확도:0.8334\n"
     ]
    }
   ],
   "source": [
    "print('GridSearchCV 최적 파라미터:', grid_dtree4.best_params_)\n",
    "print('GridSearchCV 최고 정확도:{0:.4f}'.format(grid_dtree4.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "랜덤 포레스트 정확도: 0.8149\n"
     ]
    }
   ],
   "source": [
    "#RandomForest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# 랜덤 포레스트 학습 및 별도의 테스트 셋으로 예측 성능 평가\n",
    "rf_clf = RandomForestClassifier(random_state=0)\n",
    "rf_clf.fit(X_train , y_train)\n",
    "pred_rf = rf_clf.predict(X_test)\n",
    "accuracy_rf = accuracy_score(y_test , pred_rf)\n",
    "print('랜덤 포레스트 정확도: {0:.4f}'.format(accuracy_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적 하이퍼 파라미터:\n",
      " {'max_depth': 30, 'min_samples_split': 500, 'n_estimators': 100}\n",
      "최고 예측 정확도: 0.8348\n"
     ]
    }
   ],
   "source": [
    "#RandomForest GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameter = {\n",
    "    'n_estimators':[100],\n",
    "    'max_depth' : [10,30,50,100],\n",
    "    'min_samples_split' : [500,1000, 1200]\n",
    "}\n",
    "# RandomForestClassifier 객체 생성 후 GridSearchCV 수행\n",
    "rf_clf = RandomForestClassifier(random_state=0, n_jobs=-1)\n",
    "grid_cv = GridSearchCV(rf_clf , param_grid=parameter, cv=2, n_jobs=-1 )\n",
    "grid_cv.fit(X_train , y_train)\n",
    "\n",
    "print('최적 하이퍼 파라미터:\\n', grid_cv.best_params_)\n",
    "print('최고 예측 정확도: {0:.4f}'.format(grid_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도: 0.8344\n"
     ]
    }
   ],
   "source": [
    "rf_clf1 = RandomForestClassifier(n_estimators=100, max_depth=30,\n",
    "                                 min_samples_split=500, random_state=0)\n",
    "rf_clf1.fit(X_train , y_train)\n",
    "pred_rf1 = rf_clf1.predict(X_test)\n",
    "print('예측 정확도: {0:.4f}'.format(accuracy_score(y_test , pred_rf1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "ftr_importances_values = rf_clf1.feature_importances_\n",
    "ftr_importances = pd.Series(ftr_importances_values,index=X_train.columns  )\n",
    "ftr_top6 = ftr_importances.sort_values(ascending=False)[:6]\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title('Feature importances Top 6')\n",
    "sns.barplot(x=ftr_top6 , y = ftr_top6.index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stacking\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "X_train,X_test, y_train,y_test=train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_clf4=KNeighborsClassifier(n_neighbors=4)\n",
    "rf_clf4=RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "dt_clf4=DecisionTreeClassifier()\n",
    "ada_clf4=AdaBoostClassifier(n_estimators=100)\n",
    "\n",
    "#스태킹으로 만들어진 데이터 세트를 학습, 예측할 최종 모델\n",
    "lr_final=LogisticRegression(C=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(n_estimators=100)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_clf4.fit(X_train, y_train)\n",
    "rf_clf4.fit(X_train, y_train)\n",
    "dt_clf4.fit(X_train, y_train)\n",
    "ada_clf4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN 정확도: 0.8092\n",
      "RandomForest 정확도: 0.8149\n",
      "DecisionTree 정확도: 0.7720\n",
      "AdaBoost 정확도: 0.8323\n"
     ]
    }
   ],
   "source": [
    "knn_pred4=knn_clf4.predict(X_test)\n",
    "rf_pred4=rf_clf4.predict(X_test)\n",
    "dt_pred4=dt_clf4.predict(X_test)\n",
    "ada_pred4=ada_clf4.predict(X_test)\n",
    "\n",
    "print('KNN 정확도: {0:.4f}'.format(accuracy_score(y_test, knn_pred4)))\n",
    "print('RandomForest 정확도: {0:.4f}'.format(accuracy_score(y_test, rf_pred4)))\n",
    "print('DecisionTree 정확도: {0:.4f}'.format(accuracy_score(y_test, dt_pred4)))\n",
    "print('AdaBoost 정확도: {0:.4f}'.format(accuracy_score(y_test, ada_pred4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 196389)\n",
      "(196389, 4)\n"
     ]
    }
   ],
   "source": [
    "predict=np.array([knn_pred4, rf_pred4, dt_pred4, ada_pred4])\n",
    "print(predict.shape)\n",
    "\n",
    "predict=np.transpose(predict)\n",
    "print(predict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 메타모델의 예측 정확도: 0.8285\n"
     ]
    }
   ],
   "source": [
    "lr_final.fit(predict, y_test)\n",
    "final=lr_final.predict(predict)\n",
    "\n",
    "print('최종 메타모델의 예측 정확도: {0:.4f}'.format(accuracy_score(y_test, final)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [196389, 785553]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-e4455f3433f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlr_final\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlr_final\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'최종 메타모델의 예측 정확도: {0:.4f}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\deep\\datab\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1342\u001b[0m         X, y = self._validate_data(X, y, accept_sparse='csr', dtype=_dtype,\n\u001b[0;32m   1343\u001b[0m                                    \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"C\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1344\u001b[1;33m                                    accept_large_sparse=solver != 'liblinear')\n\u001b[0m\u001b[0;32m   1345\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\deep\\datab\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\deep\\datab\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\deep\\datab\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    810\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    811\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 812\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    813\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    814\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\deep\\datab\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 256\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [196389, 785553]"
     ]
    }
   ],
   "source": [
    "lr_final.fit(predict, y_train)\n",
    "final=lr_final.predict(predict)\n",
    "\n",
    "print('최종 메타모델의 예측 정확도: {0:.4f}'.format(accuracy_score(y_test, final)))\n",
    "\n",
    "#이 시점에서 oversampling(smote방법)해서 맞춰도 되는건지...->걍 y_test 로 하면 됨~!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest\n",
      "\n",
      "최적 하이퍼 파라미터:\n",
      " {'max_depth': 30, 'min_samples_split': 500, 'n_estimators': 100}\n",
      "최고 예측 정확도: 0.8348\n"
     ]
    }
   ],
   "source": [
    "print('RandomForest\\n')\n",
    "print('최적 하이퍼 파라미터:\\n', grid_cv.best_params_)\n",
    "print('최고 예측 정확도: {0:.4f}'.format(grid_cv.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Ridge회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.datasets import load_boston\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "\n",
    "\n",
    "bostonDF=pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "bostonDF['PRICE']=boston.target\n",
    "print('Boston 데이터 세트 크기:',bostonDF.shape)\n",
    "\n",
    "y_target=bostonDF['PRICE']\n",
    "X_data=bostonDF.drop(['PRICE'], axis=1, inplace=False)\n",
    "\n",
    "ridge=Ridge(alpha=10)\n",
    "neg_mse_scores=cross_val_score(ridge, X_data, y_target, scoring=\"neg_mean_squared_error\",cv=5)\n",
    "rmse_scores=np.sqrt(-1*neg_mse_scores)\n",
    "avg_rmse=np.mean(rmse_scores)\n",
    "print('5 folds 의 개별 Negative MSE scores: ', np.round(neg_mse_scores,3))\n",
    "print('5 folds 의 개별 RMSE scores: ', np.round(rmse_scores,3))\n",
    "print('5 folds 의 평균 RMSE :{0:.3f} '.format(avg_rmse))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
